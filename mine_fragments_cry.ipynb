{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"cry\"\n",
    "#delete_main_node(\"numbness\")\n",
    "add_main_node(main_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = '[word !=\"\\[\" & word!=\"\\(\"][lemma=\"cry\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = topic_concordancer.main(query,window=25,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"lose\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"lose\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"lose\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"lose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22boy%22%5D+%5B%5D+%5B%22name%22%5D+%5B%22was%22%5D+%5B%22Eli%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22little%22%5D+%5B%22girl%22%5D+%5B%22was%22%5D+%5B%22named%22%5D+%5B%22Dina%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22she%22%5D+%5B%22knew%22%5D+%5B%22she%22%5D+%5B%22lost%22%5D+%5B%22them%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22she%22%5D+%5B%22started%22%5D+%5B%22to%22%5D+%5B%22cry%22%5D+%5B%22terribly%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"The boy 's name was Eli , and the little girl was named Dina . And she knew she lost them . And she started to cry terribly . \", 'right': '', 'complete_match': \"The boy 's name was Eli , and the little girl was named Dina . And she knew she lost them . And she started to cry terribly . \", 'testimony_id': 'HVT-107', 'shelfmark': ['Fortunoff HVT-107'], 'token_start': 8039, 'token_end': 8068}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"The boy's name was Eli, and the little girl was named Dina. And she knew she lost them. And she started to cry terribly.\"\n",
    "fragment_1['label']=\"The boy's name was Eli, and the little girl was named Dina. And she knew she lost them. And she started to cry terribly.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Everybody%22%5D+%5B%22lost%22%5D+%5B%22someone%22%5D+%5B%22and%22%5D+%5B%22maybe%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22at%22%5D+%5B%22this%22%5D+%5B%22particular%22%5D+%5B%22time%22%5D+%5B%22easier%22%5D+%5B%22to%22%5D+%5B%22share%22%5D+%5B%22the%22%5D+%5B%22grief%22%5D+%5B%22because%22%5D+%5B%22everybody%22%5D+%5B%22cried%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Everybody lost someone and maybe it was at this particular time easier to share the grief because everybody cried . ', 'right': '', 'complete_match': 'Everybody lost someone and maybe it was at this particular time easier to share the grief because everybody cried . ', 'testimony_id': 'irn504795', 'shelfmark': ['USHMM RG-50.030*0300'], 'token_start': 6107, 'token_end': 6127}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"Everybody lost someone and maybe it was at this particular time easier to share the grief because everybody cried.\"\n",
    "fragment_2['label']=\"Everybody lost someone and maybe it was at this particular time easier to share the grief because everybody cried.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22she%22%5D+%5B%22was%22%5D+%5B%5D+%5B%22there%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22she%22%5D+%5B%22blame%22%5D+%5B%22right%22%5D+%5B%22now%22%5D+%5B%22in%22%5D+%5B%22five%22%5D+%5B%22minutes%22%5D+%5B%22I%22%5D+%5B%22lost%22%5D+%5B%22a%22%5D+%5B%22family%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22cries%22%5D+%5B%22all%22%5D+%5B%5D+%5B%22all%22%5D+%5B%22the%22%5D+%5B%22time%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And she was n't there , and she blame right now in five minutes I lost a family , and cries all , all the time . \", 'right': '', 'complete_match': \"And she was n't there , and she blame right now in five minutes I lost a family , and cries all , all the time . \", 'testimony_id': 'irn504850', 'shelfmark': ['USHMM RG-50.030*0357'], 'token_start': 25049, 'token_end': 25076}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And she wasn't there, and she blame right now in five minutes I lost a family, and cries all, all the time.\"\n",
    "fragment_3['label']=\"And she wasn't there, and she blame right now in five minutes I lost a family, and cries all, all the time.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22She%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%22not%22%5D+%5B%22one%22%5D+%5B%22night%22%5D+%5B%5D+%5B%22my%22%5D+%5B%22mother%22%5D+%5B%5D+%5B%22remembering%22%5D+%5B%22that%22%5D+%5B%22she%22%5D+%5B%22lost%22%5D+%5B%22her%22%5D+%5B%22husband%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'She was crying not one night , my mother , remembering that she lost her husband ', 'right': '', 'complete_match': 'She was crying not one night , my mother , remembering that she lost her husband ', 'testimony_id': 'irn509677', 'shelfmark': ['USHMM RG-50.030*0416'], 'token_start': 3335, 'token_end': 3351}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"She was crying not one night, my mother, remembering that she lost her husband\"\n",
    "fragment_4['label']= \"She was crying not one night, my mother, remembering that she lost her husband (..)\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22she%22%5D+%5B%22started%22%5D+%5B%22crying%22%5D+%5B%22to%22%5D+%5B%22him%22%5D+%5B%22that%22%5D+%5B%22she%22%5D+%5B%22had%22%5D+%5B%22lost%22%5D+%5B%22her%22%5D+%5B%22family%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And she started crying to him that she had lost her family . ', 'right': '', 'complete_match': 'And she started crying to him that she had lost her family . ', 'testimony_id': 'usc_shoah_4113', 'shelfmark': ['USC 4113'], 'token_start': 20577, 'token_end': 20590}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"And she started crying to him that she had lost her family.\"\n",
    "fragment_5['label']= \"And she started crying to him that she had lost her family.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"beg\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"beg\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"beg\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22my%22%5D+%5B%22father%22%5D+%5B%22started%22%5D+%5B%22crying%22%5D+%5B%22him%22%5D+%5B%5D+%5B%22begging%22%5D+%5B%22them%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And my father started crying him , begging them . ', 'right': '', 'complete_match': 'And my father started crying him , begging them . ', 'testimony_id': 'HVT-72', 'shelfmark': ['Fortunoff HVT-72'], 'token_start': 3026, 'token_end': 3036}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And my father started crying him, begging them.\"\n",
    "fragment_1['label']=\"And my father started crying him, begging them.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22they%22%5D+%5B%22said%22%5D+%5B%5D+%5B%22we%22%5D+%5B%5D+%5B%22going%22%5D+%5B%22to%22%5D+%5B%22kill%22%5D+%5B%22you%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22one%22%5D+%5B%22guy%22%5D+%5B%22was%22%5D+%5B%22standing%22%5D+%5B%22with%22%5D+%5B%22a%22%5D+%5B%22gun%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22crying%22%5D+%5B%22and%22%5D+%5B%22begging%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And they said , we 're going to kill you . And one guy was standing with a gun . And we were crying and begging . \", 'right': '', 'complete_match': \"And they said , we 're going to kill you . And one guy was standing with a gun . And we were crying and begging . \", 'testimony_id': 'usc_shoah_13213', 'shelfmark': ['USC 13213'], 'token_start': 10309, 'token_end': 10336}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"And they said, we're going to kill you. And one guy was standing with a gun. And we were crying and begging.\"\n",
    "fragment_2['label']=\"And they said, we're going to kill you. And one guy was standing with a gun. And we were crying and begging.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22So%22%5D+%5B%22we%22%5D+%5B%22all%22%5D+%5B%22started%22%5D+%5B%22to%22%5D+%5B%22cry%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22My%22%5D+%5B%22mother%22%5D+%5B%22is%22%5D+%5B%22on%22%5D+%5B%22her%22%5D+%5B%22knees%22%5D+%5B%5D+%5B%22begging%22%5D+%5B%5D+%5B%22The%22%5D+%5B%22kids%22%5D+%5B%22are%22%5D+%5B%22crying%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'So we all started to cry , you know ? My mother is on her knees , begging . The kids are crying . ', 'right': '', 'complete_match': 'So we all started to cry , you know ? My mother is on her knees , begging . The kids are crying . ', 'testimony_id': 'irn517612', 'shelfmark': ['USHMM RG-50.030*0498'], 'token_start': 24642, 'token_end': 24666}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"So we all started to cry, you know? My mother is on her knees, begging. The kids are crying.\"\n",
    "fragment_3['label']=\"So we all started to cry, you know? My mother is on her knees, begging. The kids are crying.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22they%22%5D+%5B%22picked%22%5D+%5B%22out%22%5D+%5B%22six%22%5D+%5B%22men%22%5D+%5B%22from%22%5D+%5B%22our%22%5D+%5B%22ranks%22%5D+%5B%22from%22%5D+%5B%22the%22%5D+%5B%22work%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22crying%22%5D+%5B%22and%22%5D+%5B%22begging%22%5D+%5B%22for%22%5D+%5B%22their%22%5D+%5B%22life%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'they picked out six men from our ranks from the work , and they were crying and begging for their life . ', 'right': '', 'complete_match': 'they picked out six men from our ranks from the work , and they were crying and begging for their life . ', 'testimony_id': 'irn504760', 'shelfmark': ['USHMM RG-50.030*0276'], 'token_start': 6925, 'token_end': 6947}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"they picked out six men from our ranks from the work, and they were crying and begging for their life.\"\n",
    "fragment_4['label']= \"(..) they picked out six men from our ranks from the work, and they were crying and begging for their life.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"day\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"day\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"day\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"day and night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%22because%22%5D+%5B%22I%22%5D+%5B%22saw%22%5D+%5B%22myself%22%5D+%5B%22finish%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I was crying day and night because I saw myself finish ', 'right': '', 'complete_match': 'I was crying day and night because I saw myself finish ', 'testimony_id': 'usc_shoah_13096', 'shelfmark': ['USC 13096'], 'token_start': 3528, 'token_end': 3539}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"I was crying day and night because I saw myself finish\"\n",
    "fragment_1['label']=\"(..) I was crying day and night because I saw myself finish (..)\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22All%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%22she%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%22why%22%5D+%5B%22she%22%5D+%5B%22left%22%5D+%5B%22them%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'All day and night , day and night she was crying why she left them . ', 'right': '', 'complete_match': 'All day and night , day and night she was crying why she left them . ', 'testimony_id': 'HVT-156', 'shelfmark': ['Fortunoff HVT-156'], 'token_start': 8756, 'token_end': 8772}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"All day and night, day and night she was crying why she left them.\"\n",
    "fragment_2['label']=\"All day and night, day and night she was crying why she left them.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22just%22%5D+%5B%22cried%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%5D+%5B%22wh%22%5D+%5B%5D%7B0%2C3%7D+%5B%22where%22%5D+%5B%22my%22%5D+%5B%22son%22%5D+%5B%22is%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%5D+%5B%22sure%22%5D+%5B%22if%22%5D+%5B%22he%22%5D+%5B%5D+%5B%22alive%22%5D+%5B%22or%22%5D+%5B%22not%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"We just cried day and night . wh -- where my son is . I was n't sure if he 's alive or not . \", 'right': '', 'complete_match': \"We just cried day and night . wh -- where my son is . I was n't sure if he 's alive or not . \", 'testimony_id': 'HVT-34', 'shelfmark': ['Fortunoff HVT-34'], 'token_start': 4417, 'token_end': 4442}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"We just cried day and night. wh-- where my son is. I wasn't sure if he's alive or not.\"\n",
    "fragment_3['label']=\"We just cried day and night. wh-- where my son is. I wasn't sure if he's alive or not.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22got%22%5D+%5B%22my%22%5D+%5B%22period%22%5D+%5B%2210%22%5D+%5B%22days%22%5D+%5B%22before%22%5D+%5B%22I%22%5D+%5B%22should%22%5D+%5B%22have%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22then%22%5D+%5B%22did%22%5D+%5B%22not%22%5D+%5B%22have%22%5D+%5B%22it%22%5D+%5B%22anymore%22%5D+%5B%22for%22%5D+%5B%22two%22%5D+%5B%22years%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22I%22%5D+%5B%22cried%22%5D+%5B%22for%22%5D+%5B%22two%22%5D+%5B%22weeks%22%5D+%5B%5D+%5B%22constantly%22%5D+%5B%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I got my period 10 days before I should have . And then did not have it anymore for two years . And I cried for two weeks , constantly , day and night . ', 'right': '', 'complete_match': 'I got my period 10 days before I should have . And then did not have it anymore for two years . And I cried for two weeks , constantly , day and night . ', 'testimony_id': 'usc_shoah_935', 'shelfmark': ['USC 935'], 'token_start': 24105, 'token_end': 24140}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"I got my period 10 days before I should have. And then did not have it anymore for two years. And I cried for two weeks, constantly, day and night.\"\n",
    "fragment_4['label']= \"I got my period 10 days before I should have. And then did not have it anymore for two years. And I cried for two weeks, constantly, day and night.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%5D+%5B%22Little%22%5D+%5B%22bugs%22%5D+%5B%22everywhere%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And I was crying , day and night . Little bugs everywhere ', 'right': '', 'complete_match': 'And I was crying , day and night . Little bugs everywhere ', 'testimony_id': 'usc_shoah_26888', 'shelfmark': ['USC 26888'], 'token_start': 23714, 'token_end': 23726}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"And I was crying, day and night. Little bugs everywhere\"\n",
    "fragment_5['label']= \"And I was crying, day and night. Little bugs everywhere\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"cry\",\"God\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"cry\"][]{0,25}[lemma=\"God\"])|([lemma=\"God\"][]{0,25}[lemma=\"cry\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"God\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22cries%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22screams%22%5D+%5B%22to%22%5D+%5B%22God%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22um%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22mothers%22%5D+%5B%22walked%22%5D+%5B%22around%22%5D+%5B%22with%22%5D+%5B%22the%22%5D+%5B%22pillows%22%5D+%5B%5D+%5B%22with%22%5D+%5B%22the%22%5D+%5B%22blankets%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22children%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The cries , the screams to God , the um , the mothers walked around with the pillows , with the blankets of the children ', 'right': '', 'complete_match': 'The cries , the screams to God , the um , the mothers walked around with the pillows , with the blankets of the children ', 'testimony_id': 'irn505572', 'shelfmark': ['USHMM RG-50.042*0019'], 'token_start': 4282, 'token_end': 4307}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"The cries, the screams to God, the um, the mothers walked around with the pillows, with the blankets of the children\"\n",
    "fragment_1['label']=\"The cries, the screams to God, the um, the mothers walked around with the pillows, with the blankets of the children\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22knew%22%5D+%5B%22that%22%5D+%5B%5D%7B0%2C50%7D+%5B%22those%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%22those%22%5D+%5B%22praying%22%5D+%5B%5D+%5B%22praying%22%5D+%5B%22and%22%5D+%5B%22scream%22%5D+%5B%22to%22%5D+%5B%22God%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They knew that ... those crying , those praying , praying and scream to God . ', 'right': '', 'complete_match': 'They knew that ... those crying , those praying , praying and scream to God . ', 'testimony_id': 'irn504592', 'shelfmark': ['USHMM RG-50.030*0098'], 'token_start': 2938, 'token_end': 2954}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"They knew that...those crying, those praying, praying and scream to God.\"\n",
    "fragment_2['label']=\"They knew that...those crying, those praying, praying and scream to God.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22remember%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22the%22%5D+%5B%22first%22%5D+%5B%22time%22%5D+%5B%22in%22%5D+%5B%22my%22%5D+%5B%22life%22%5D+%5B%22I%22%5D+%5B%22seen%22%5D+%5B%22him%22%5D+%5B%22cry%22%5D+%5B%22and%22%5D+%5B%22talk%22%5D+%5B%22to%22%5D+%5B%22God%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I remember it was the first time in my life I seen him cry and talk to God . ', 'right': '', 'complete_match': 'I remember it was the first time in my life I seen him cry and talk to God . ', 'testimony_id': 'irn508686', 'shelfmark': ['USHMM RG-50.462*0062'], 'token_start': 17692, 'token_end': 17711}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"I remember it was the first time in my life I seen him cry and talk to God.\"\n",
    "fragment_3['label']=\"I remember it was the first time in my life I seen him cry and talk to God.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22There%22%5D+%5B%22was%22%5D+%5B%22this%22%5D+%5B%22guy%22%5D+%5B%5D+%5B%22he%22%5D+%5B%22was%22%5D+%5B%22screaming%22%5D+%5B%22and%22%5D+%5B%22crying%22%5D+%5B%22and%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'There was this guy , he was screaming and crying and ', 'right': '', 'complete_match': 'There was this guy , he was screaming and crying and ', 'testimony_id': 'usc_shoah_2391', 'shelfmark': ['USC 2391'], 'token_start': 9879, 'token_end': 9890}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \" There was this guy, he was screaming and crying and\"\n",
    "fragment_4['label']= \" There was this guy, he was screaming and crying and, ah, you know? God save me and all that.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22a%22%5D+%5B%22lot%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22people%22%5D+%5B%22was%22%5D+%5B%22injured%22%5D+%5B%5D+%5B%22crying%22%5D+%5B%5D+%5B%22So%22%5D+%5B%22what%22%5D+%5B%22are%22%5D+%5B%22you%22%5D+%5B%22going%22%5D+%5B%22to%22%5D+%5B%22do%22%5D+%5B%5D+%5B%22Crying%22%5D+%5B%5D+%5B%22Crying%22%5D+%5B%22to%22%5D+%5B%22God%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'a lot of the people was injured , crying . So what are you going to do ? Crying . Crying to God . ', 'right': '', 'complete_match': 'a lot of the people was injured , crying . So what are you going to do ? Crying . Crying to God . ', 'testimony_id': 'usc_shoah_3653', 'shelfmark': ['USC 3653'], 'token_start': 5084, 'token_end': 5108}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"a lot of the people was injured, crying. So what are you going to do? Crying. Crying to God.\"\n",
    "fragment_5['label']= \"(..) a lot of the people was injured, crying. So what are you going to do? Crying. Crying to God.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"pray\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"pray\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"pray\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"pray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22cried%22%5D+%5B%5D+%5B%22All%22%5D+%5B%22of%22%5D+%5B%22us%22%5D+%5B%22cried%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22then%22%5D+%5B%22this%22%5D+%5B%22night%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22als%22%5D+%5B%5D%7B0%2C3%7D+%5B%22made%22%5D+%5B%22a%22%5D+%5B%22minion%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22prayed%22%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22said%22%5D+%5B%22Kaddish%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We cried . All of us cried . And then this night , we als -- made a minion . We prayed and we said Kaddish . ', 'right': '', 'complete_match': 'We cried . All of us cried . And then this night , we als -- made a minion . We prayed and we said Kaddish . ', 'testimony_id': 'HVT-172', 'shelfmark': ['Fortunoff HVT-172'], 'token_start': 7472, 'token_end': 7499}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"We cried. All of us cried. And then this night, we als-- made a minion. We prayed and we said Kaddish.\"\n",
    "fragment_1['label']=\"We cried. All of us cried. (..) We prayed and we said Kaddish.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22There%22%5D+%5B%22was%22%5D+%5B%22only%22%5D+%5B%22one%22%5D+%5B%5D+%5B%22two%22%5D+%5B%22small%22%5D+%5B%22windows%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22top%22%5D+%5B%5D+%5B%22everything%22%5D+%5B%22else%22%5D+%5B%22was%22%5D+%5B%22closed%22%5D+%5B%5D+%5B%22They%22%5D+%5B%22were%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%22They%22%5D+%5B%22were%22%5D+%5B%22praying%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'There was only one , two small windows on the top , everything else was closed . They were crying . They were praying . ', 'right': '', 'complete_match': 'There was only one , two small windows on the top , everything else was closed . They were crying . They were praying . ', 'testimony_id': 'HVT-93', 'shelfmark': ['Fortunoff HVT-93'], 'token_start': 12348, 'token_end': 12373}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"There was only one, two small windows on the top, everything else was closed. They were crying. They were praying.\"\n",
    "fragment_2['label']=\" There was only one, two small windows on the top, everything else was closed. They were crying. They were praying.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22laid%22%5D+%5B%22down%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22bunk%22%5D+%5B%22and%22%5D+%5B%22cried%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22I%22%5D+%5B%22only%22%5D+%5B%22prayed%22%5D+%5B%22one%22%5D+%5B%22thing%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22prayed%22%5D+%5B%22now%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22prayed%22%5D+%5B%22to%22%5D+%5B%22God%22%5D+%5B%22to%22%5D+%5B%22take%22%5D+%5B%22my%22%5D+%5B%22life%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I laid down on the bunk and cried , you know . And I only prayed one thing . I prayed now -- I prayed to God to take my life . ', 'right': '', 'complete_match': 'I laid down on the bunk and cried , you know . And I only prayed one thing . I prayed now -- I prayed to God to take my life . ', 'testimony_id': 'usc_shoah_11797', 'shelfmark': ['USC 11797'], 'token_start': 27233, 'token_end': 27265}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"I laid down on the bunk and cried, you know. And I only prayed one thing. I prayed now-- I prayed to God to take my life.\"\n",
    "fragment_3['label']=\"I laid down on the bunk and cried, you know. And I only prayed one thing. (..) I prayed to God to take my life.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22remember%22%5D+%5B%22the%22%5D+%5B%22seder%22%5D+%5B%22table%22%5D+%5B%22was%22%5D+%5B%22nice%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22my%22%5D+%5B%22father%22%5D+%5B%22was%22%5D+%5B%22praying%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%22with%22%5D+%5B%22my%22%5D+%5B%22mother%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I remember the seder table was nice , and my father was praying , and we was crying with my mother ', 'right': '', 'complete_match': 'I remember the seder table was nice , and my father was praying , and we was crying with my mother ', 'testimony_id': 'irn510676', 'shelfmark': ['USHMM RG-50.156*0022'], 'token_start': 1287, 'token_end': 1308}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"I remember the seder table was nice, and my father was praying, and we was crying with my mother\"\n",
    "fragment_4['label']= \"(..)I remember the seder table was nice, and my father was praying, and we was crying with my mother.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22pray%22%5D+%5B%5D+%5B%22and%22%5D+%5B%5D%7B0%2C3%7D+%5B%22oh%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22cry%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22cry%22%5D+%5B%5D+%5B%22One%22%5D+%5B%22cry%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22other%22%5D+%5B%22starts%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And pray , and  oh , and cry . We cry . One cry , the other starts . ', 'right': '', 'complete_match': 'And pray , and  oh , and cry . We cry . One cry , the other starts . ', 'testimony_id': 'irn96024', 'shelfmark': ['USHMM RG-50.030*0790'], 'token_start': 22789, 'token_end': 22809}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"And pray, and  oh, and cry. We cry. One cry, the other starts.\"\n",
    "fragment_5['label']= \"And pray, and  oh, and cry. We cry. One cry, the other starts.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"separate\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"separate\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"separate\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"separation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Or%22%5D+%5B%22sometimes%22%5D+%5B%22the%22%5D+%5B%22even%22%5D+%5B%22mothers%22%5D+%5B%22with%22%5D+%5B%22children%22%5D+%5B%22were%22%5D+%5B%22separated%22%5D+%5B%22from%22%5D+%5B%22their%22%5D+%5B%22husbands%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22the%22%5D+%5B%22crying%22%5D+%5B%22and%22%5D+%5B%22despair%22%5D+%5B%22was%22%5D+%5B%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22just%22%5D+%5B%22devastating%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Or sometimes the even mothers with children were separated from their husbands . And the crying and despair was , it was just devastating . ', 'right': '', 'complete_match': 'Or sometimes the even mothers with children were separated from their husbands . And the crying and despair was , it was just devastating . ', 'testimony_id': 'irn511020', 'shelfmark': ['USHMM RG-50.471*0003'], 'token_start': 4278, 'token_end': 4303}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"Or sometimes the even mothers with children were separated from their husbands. And the crying and despair was, it was just devastating.\"\n",
    "fragment_1['label']=\"Or sometimes the even mothers with children were separated from their husbands. And the crying and despair was, it was just devastating.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22and%22%5D+%5B%22the%22%5D+%5B%22little%22%5D+%5B%22babies%22%5D+%5B%22and%22%5D+%5B%22even%22%5D+%5B%22grown%22%5D+%5B%22up%22%5D+%5B%22women%22%5D+%5B%22and%22%5D+%5B%22mothers%22%5D+%5B%22cried%22%5D+%5B%22as%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22separated%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'and the little babies and even grown up women and mothers cried as they were separated , ', 'right': '', 'complete_match': 'and the little babies and even grown up women and mothers cried as they were separated , ', 'testimony_id': 'irn515647', 'shelfmark': ['USHMM RG-50.462*0122'], 'token_start': 277, 'token_end': 294}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"and the little babies and even grown up women and mothers cried as they were separated,\"\n",
    "fragment_2['label']=\"(..) and the little babies and even grown up women and mothers cried as they were separated (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22this%22%5D+%5B%22is%22%5D+%5B%22also%22%5D+%5B%22where%22%5D+%5B%22I%22%5D+%5B%22%27ve%22%5D+%5B%22seen%22%5D+%5B%22mothers%22%5D+%5B%22with%22%5D+%5B%22children%22%5D+%5B%22being%22%5D+%5B%22separated%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22again%22%5D+%5B%22the%22%5D+%5B%22chaos%22%5D+%5B%22was%22%5D+%5B%22terrible%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22cries%22%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22lamenting%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And this is also where I 've seen mothers with children being separated . And again the chaos was terrible , the cries and the lamenting . \", 'right': '', 'complete_match': \"And this is also where I 've seen mothers with children being separated . And again the chaos was terrible , the cries and the lamenting . \", 'testimony_id': 'usc_shoah_12003', 'shelfmark': ['USC 12003'], 'token_start': 6880, 'token_end': 6907}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And this is also where I've seen mothers with children being separated. And again the chaos was terrible, the cries and the lamenting.\"\n",
    "fragment_3['label']=\"And this is also where I've seen mothers with children being separated. And again the chaos was terrible, the cries and the lamenting.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%5D%7B0%2C3%7D+%5B%22DRINKS%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%22because%22%5D+%5B%22now%22%5D+%5B%22the%22%5D+%5B%22last%22%5D+%5B%22person%22%5D+%5B%22that%22%5D+%5B%22I%22%5D+%5B%22had%22%5D+%5B%22was%22%5D+%5B%22taken%22%5D+%5B%22away%22%5D+%5B%22from%22%5D+%5B%22me%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And [ DRINKS ] I was crying because now the last person that I had was taken away from me . ', 'right': '', 'complete_match': 'And [ DRINKS ] I was crying because now the last person that I had was taken away from me . ', 'testimony_id': 'usc_shoah_8423', 'shelfmark': ['USC 8423'], 'token_start': 21260, 'token_end': 21281}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"And [DRINKS] I was crying because now the last person that I had was taken away from me.\"\n",
    "fragment_4['label']= \"And [DRINKS] I was crying because now the last person that I had was taken away from me.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22She%22%5D+%5B%22said%22%5D+%5B%22that%22%5D+%5B%22she%22%5D+%5B%22had%22%5D+%5B%22only%22%5D+%5B%22cried%22%5D+%5B%22once%22%5D+%5B%22before%22%5D+%5B%22and%22%5D+%5B%22actually%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22very%22%5D+%5B%22controlled%22%5D+%5B%22person%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22that%22%5D+%5B%22was%22%5D+%5B%22when%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22separated%22%5D+%5B%22from%22%5D+%5B%22the%22%5D+%5B%22children%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'She said that she had only cried once before and actually was a very controlled person . And that was when we were separated from the children . ', 'right': '', 'complete_match': 'She said that she had only cried once before and actually was a very controlled person . And that was when we were separated from the children . ', 'testimony_id': 'usc_shoah_7598', 'shelfmark': ['USC 7598'], 'token_start': 5630, 'token_end': 5658}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"She said that she had only cried once before and actually was a very controlled person. And that was when we were separated from the children.\"\n",
    "fragment_5['label']= \"(..)she had only cried once before (..). And that was when we were separated from the children.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"cry\",\"bread\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"cry\"][]{0,25}[lemma=\"bread\"])|([lemma=\"bread\"][]{0,25}[lemma=\"cry\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"bread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22what%22%5D+%5B%22was%22%5D+%5B%22left%22%5D+%5B%22of%22%5D+%5B%22that%22%5D+%5B%22loaf%22%5D+%5B%22of%22%5D+%5B%22bread%22%5D+%5B%5D+%5B%22chewing%22%5D+%5B%22on%22%5D+%5B%22it%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22crying%22%5D+%5B%22as%22%5D+%5B%22hard%22%5D+%5B%22as%22%5D+%5B%22he%22%5D+%5B%22could%22%5D+%5B%22cry%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'what was left of that loaf of bread , chewing on it , and crying as hard as he could cry . ', 'right': '', 'complete_match': 'what was left of that loaf of bread , chewing on it , and crying as hard as he could cry . ', 'testimony_id': 'usc_shoah_24814', 'shelfmark': ['USC 24814'], 'token_start': 14790, 'token_end': 14812}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"what was left of that loaf of bread, chewing on it, and crying as hard as he could cry.\"\n",
    "fragment_1['label']=\"(..) what was left of that loaf of bread, chewing on it, and crying as hard as he could cry.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22So%22%5D+%5B%22we%22%5D+%5B%22kept%22%5D+%5B%22tearing%22%5D+%5B%22the%22%5D+%5B%22loaves%22%5D+%5B%22of%22%5D+%5B%22bread%22%5D+%5B%22in%22%5D+%5B%22half%22%5D+%5B%22and%22%5D+%5B%22giving%22%5D+%5B%22one%22%5D+%5B%22to%22%5D+%5B%22each%22%5D+%5B%22person%22%5D+%5B%5D+%5B%22They%22%5D+%5B%22kept%22%5D+%5B%22cramming%22%5D+%5B%22it%22%5D+%5B%22in%22%5D+%5B%22their%22%5D+%5B%22mouths%22%5D+%5B%5D+%5B%22crying%22%5D+%5B%22and%22%5D+%5B%22crying%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'So we kept tearing the loaves of bread in half and giving one to each person . They kept cramming it in their mouths , crying and crying . ', 'right': '', 'complete_match': 'So we kept tearing the loaves of bread in half and giving one to each person . They kept cramming it in their mouths , crying and crying . ', 'testimony_id': 'usc_shoah_24814', 'shelfmark': ['USC 24814'], 'token_start': 12627, 'token_end': 12656}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"So we kept tearing the loaves of bread in half and giving one to each person. They kept cramming it in their mouths, crying and crying.\"\n",
    "fragment_2['label']=\"So we kept tearing the loaves of bread in half and giving one to each person. They kept cramming it in their mouths, crying and crying.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22what%22%5D+%5B%22I%22%5D+%5B%22would%22%5D+%5B%22do%22%5D+%5B%22is%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22would%22%5D+%5B%22hold%22%5D+%5B%22the%22%5D+%5B%22bread%22%5D+%5B%22for%22%5D+%5B%22my%22%5D+%5B%22sisters%22%5D+%5B%22and%22%5D+%5B%22myself%22%5D+%5B%22to%22%5D+%5B%22make%22%5D+%5B%22sure%22%5D+%5B%22that%22%5D+%5B%5D+%5B%22because%22%5D+%5B%22the%22%5D+%5B%22little%22%5D+%5B%22ones%22%5D+%5B%22would%22%5D+%5B%22eat%22%5D+%5B%22up%22%5D+%5B%22their%22%5D+%5B%22bread%22%5D+%5B%22right%22%5D+%5B%22away%22%5D+%5B%22and%22%5D+%5B%22then%22%5D+%5B%22they%22%5D+%5B%22would%22%5D+%5B%22cry%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22hungry%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And what I would do is , I would hold the bread for my sisters and myself to make sure that , because the little ones would eat up their bread right away and then they would cry they were hungry . ', 'right': '', 'complete_match': 'And what I would do is , I would hold the bread for my sisters and myself to make sure that , because the little ones would eat up their bread right away and then they would cry they were hungry . ', 'testimony_id': 'irn504849', 'shelfmark': ['USHMM RG-50.030*0356'], 'token_start': 17894, 'token_end': 17936}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And what I would do is, I would hold the bread for my sisters and myself to make sure that, because the little ones would eat up their bread right away and then they would cry they were hungry.\"\n",
    "fragment_3['label']=\"(..) the little ones would eat up their bread right away and then they would cry they were hungry.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22looked%22%5D+%5B%22around%22%5D+%5B%22and%22%5D+%5B%22people%22%5D+%5B%22were%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22street%22%5D+%5B%22covered%22%5D+%5B%22with%22%5D+%5B%22papers%22%5D+%5B%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22near%22%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22were%22%5D+%5B%22crying%22%5D+%5B%22for%22%5D+%5B%22bread%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I looked around and people were on the street covered with papers , bodies , near bodies , were crying for bread . ', 'right': '', 'complete_match': 'I looked around and people were on the street covered with papers , bodies , near bodies , were crying for bread . ', 'testimony_id': 'irn504581', 'shelfmark': ['USHMM RG-50.030*0086'], 'token_start': 1269, 'token_end': 1292}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"I looked around and people were on the street covered with papers, bodies, near bodies, were crying for bread.\"\n",
    "fragment_4['label']= \"I looked around and people were on the street covered with papers, bodies, near bodies, were crying for bread.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"shoot\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"shoot\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"shoot\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"shoot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22and%22%5D+%5B%22he%22%5D+%5B%22killed%22%5D+%5B%22the%22%5D+%5B%22baby%22%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22mother%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22spot%22%5D+%5B%5D+%5B%22Shot%22%5D+%5B%22them%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22spot%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'and he killed the baby and the mother on the spot . Shot them on the spot . ', 'right': '', 'complete_match': 'and he killed the baby and the mother on the spot . Shot them on the spot . ', 'testimony_id': 'irn504663', 'shelfmark': ['USHMM RG-50.030*0174'], 'token_start': 6296, 'token_end': 6314}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \" and he killed the baby and the mother on the spot. Shot them on the spot.\"\n",
    "fragment_1['label']=\"And the little baby was crying, and the German heard...heard the baby crying (..) Shot them on the spot.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22know%22%5D+%5B%22babies%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%22Somebody%22%5D+%5B%22picked%22%5D+%5B%22up%22%5D+%5B%22a%22%5D+%5B%22baby%22%5D+%5B%5D+%5B%22but%22%5D+%5B%22it%22%5D+%5B%5D+%5B%22shot%22%5D+%5B%22right%22%5D+%5B%22away%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"You know babies was crying . Somebody picked up a baby , but it 's shot right away . \", 'right': '', 'complete_match': \"You know babies was crying . Somebody picked up a baby , but it 's shot right away . \", 'testimony_id': 'irn504669', 'shelfmark': ['USHMM RG-50.030*0166'], 'token_start': 1192, 'token_end': 1211}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"You know babies was crying. Somebody picked up a baby, but it's shot right away.\"\n",
    "fragment_2['label']=\"You know babies was crying. Somebody picked up a baby, but it's shot right away.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22doctors%22%5D+%5B%22that%22%5D+%5B%22came%22%5D+%5B%22right%22%5D+%5B%22away%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22took%22%5D+%5B%22the%22%5D+%5B%22crying%22%5D+%5B%22people%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22took%22%5D+%5B%22guns%22%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22shoot%22%5D+%5B%22them%22%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22fell%22%5D+%5B%22in%22%5D+%5B%5D+%5B%22right%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22fire%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The doctors that came right away , they took the crying people , they took guns and they shoot them and they fell in , right on the fire . ', 'right': '', 'complete_match': 'The doctors that came right away , they took the crying people , they took guns and they shoot them and they fell in , right on the fire . ', 'testimony_id': 'irn504771', 'shelfmark': ['USHMM RG-50.030*0288'], 'token_start': 6596, 'token_end': 6626}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"The doctors that came right away, they took the crying people, they took guns and they shoot them and they fell in, right on the fire.\"\n",
    "fragment_3['label']=\"The doctors that came right away, they took the crying people, they took guns and they shoot them and they fell in(..)\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22when%22%5D+%5B%22the%22%5D+%5B%22mother%22%5D+%5B%22started%22%5D+%5B%22pleading%22%5D+%5B%22with%22%5D+%5B%22him%22%5D+%5B%22and%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%22he%22%5D+%5B%22shot%22%5D+%5B%22the%22%5D+%5B%22mother%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22spot%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'when the mother started pleading with him and crying , he shot the mother on the spot . ', 'right': '', 'complete_match': 'when the mother started pleading with him and crying , he shot the mother on the spot . ', 'testimony_id': 'irn504712', 'shelfmark': ['USHMM RG-50.030*0220'], 'token_start': 2844, 'token_end': 2862}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"when the mother started pleading with him and crying, he shot the mother on the spot.\"\n",
    "fragment_4['label']= \"(..) when the mother started pleading with him and crying, he shot the mother on the spot\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"pain\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"pain\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"pain\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"pain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22the%22%5D+%5B%22pain%22%5D+%5B%22was%22%5D+%5B%22just%22%5D+%5B%22tearing%22%5D+%5B%22my%22%5D+%5B%22heart%22%5D+%5B%5D+%5B%22As%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22sitting%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22worst%22%5D+%5B%22circumstances%22%5D+%5B%22and%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22all%22%5D+%5B%22of%22%5D+%5B%22a%22%5D+%5B%22sudden%22%5D+%5B%22I%22%5D+%5B%22could%22%5D+%5B%22give%22%5D+%5B%22up%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'the pain was just tearing my heart . As I was sitting in the worst circumstances and crying , and all of a sudden I could give up . ', 'right': '', 'complete_match': 'the pain was just tearing my heart . As I was sitting in the worst circumstances and crying , and all of a sudden I could give up . ', 'testimony_id': 'usc_shoah_10588', 'shelfmark': ['USC 10588'], 'token_start': 24836, 'token_end': 24865}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"the pain was just tearing my heart. As I was sitting in the worst circumstances and crying, and all of a sudden I could give up.\"\n",
    "fragment_1['label']=\"(..) the pain was just tearing my heart. As I was sitting in the worst circumstances and crying (..)\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22My%22%5D+%5B%22brother%22%5D+%5B%22started%22%5D+%5B%22to%22%5D+%5B%22cry%22%5D+%5B%22because%22%5D+%5B%22he%22%5D+%5B%22got%22%5D+%5B%22his%22%5D+%5B%22own%22%5D+%5B%22pain%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'My brother started to cry because he got his own pain . ', 'right': '', 'complete_match': 'My brother started to cry because he got his own pain . ', 'testimony_id': 'usc_shoah_2031', 'shelfmark': ['USC 2031'], 'token_start': 3288, 'token_end': 3300}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"My brother started to cry because he got his own pain.\"\n",
    "fragment_2['label']=\"My brother started to cry because he got his own pain.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22his%22%5D+%5B%22face%22%5D+%5B%22was%22%5D+%5B%22bloody%22%5D+%5B%22and%22%5D+%5B%22black%22%5D+%5B%22and%22%5D+%5B%22after%22%5D+%5B%22a%22%5D+%5B%22few%22%5D+%5B%22days%22%5D+%5B%22the%22%5D+%5B%22man%22%5D+%5B%22just%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22stop%22%5D+%5B%22crying%22%5D+%5B%22so%22%5D+%5B%5D+%5B%22uh%22%5D+%5B%22we%22%5D+%5B%22told%22%5D+%5B%22him%22%5D+%5B%22we%22%5D+%5B%22understand%22%5D+%5B%22he%22%5D+%5B%22must%22%5D+%5B%22be%22%5D+%5B%22in%22%5D+%5B%22terrible%22%5D+%5B%22pain%22%5D+%5B%22from%22%5D+%5B%22the%22%5D+%5B%22blows%22%5D+%5B%22he%22%5D+%5B%22got%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'his face was bloody and black and after a few days the man just could nt stop crying so , uh we told him we understand he must be in terrible pain from the blows he got . ', 'right': '', 'complete_match': 'his face was bloody and black and after a few days the man just could nt stop crying so , uh we told him we understand he must be in terrible pain from the blows he got . ', 'testimony_id': 'irn509118', 'shelfmark': ['USHMM RG-50.233*0036'], 'token_start': 581, 'token_end': 619}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \" his face was bloody and black and after a few days the man just couldnt stop crying so, uh we told him we understand he must be in terrible pain from the blows he got.\"\n",
    "fragment_3['label']=\"(..) his face was bloody and black and after a few days the man just couldnt stop crying so, uh we told him we understand he must be in terrible pain from the blows he got.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%22in%22%5D+%5B%22such%22%5D+%5B%22pain%22%5D+%5B%22that%22%5D+%5B%22I%22%5D+%5B%22would%22%5D+%5B%22just%22%5D+%5B%22start%22%5D+%5B%22crying%22%5D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22%27d%22%5D+%5B%22just%22%5D+%5B%22walk%22%5D+%5B%22out%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22room%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"I was in such pain that I would just start crying and I 'd just walk out of the room , \", 'right': '', 'complete_match': \"I was in such pain that I would just start crying and I 'd just walk out of the room , \", 'testimony_id': 'irn504568', 'shelfmark': ['USHMM RG-50.030*0072'], 'token_start': 6800, 'token_end': 6821}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \" I was in such pain that I would just start crying and I'd just walk out of the room,\"\n",
    "fragment_4['label']= \"(..) I was in such pain that I would just start crying and I'd just walk out of the room (..)\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"embrace\",\"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"embrace\"][]{0,25}[lemma=\"cry\"])|([lemma=\"cry\"][]{0,25}[lemma=\"embrace\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"embrace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22he%22%5D+%5B%22was%22%5D+%5B%22waiting%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22he%22%5D+%5B%22embraced%22%5D+%5B%22us%22%5D+%5B%22and%22%5D+%5B%22he%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%22and%22%5D+%5B%22he%22%5D+%5B%22took%22%5D+%5B%22us%22%5D+%5B%22back%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And he was waiting , and he embraced us and he was crying and he took us back . ', 'right': '', 'complete_match': 'And he was waiting , and he embraced us and he was crying and he took us back . ', 'testimony_id': 'usc_shoah_13690', 'shelfmark': ['USC 13690'], 'token_start': 9622, 'token_end': 9641}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And he was waiting, and he embraced us and he was crying and he took us back.\"\n",
    "fragment_1['label']=\"And he was waiting, and he embraced us and he was crying and he took us back.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22So%22%5D+%5B%22she%22%5D+%5B%22grabbed%22%5D+%5B%22her%22%5D+%5B%22and%22%5D+%5B%22embraced%22%5D+%5B%22her%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22she%22%5D+%5B%22started%22%5D+%5B%22to%22%5D+%5B%22cry%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'So she grabbed her and embraced her . And she started to cry , ', 'right': '', 'complete_match': 'So she grabbed her and embraced her . And she started to cry , ', 'testimony_id': 'usc_shoah_14190', 'shelfmark': ['USC 14190'], 'token_start': 13286, 'token_end': 13300}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"So she grabbed her and embraced her. And she started to cry,\"\n",
    "fragment_2['label']=\"So she grabbed her and embraced her. And she started to cry (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22He%22%5D+%5B%22look%22%5D+%5B%22at%22%5D+%5B%22me%22%5D+%5B%5D+%5B%22look%22%5D+%5B%22at%22%5D+%5B%22me%22%5D+%5B%5D+%5B%22he%22%5D+%5B%22start%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%5D%7B0%2C50%7D+%5B%22He%22%5D+%5B%22was%22%5D+%5B%22close%22%5D+%5B%22to%22%5D+%5B%22me%22%5D+%5B%5D+%5B%22He%22%5D+%5B%22put%22%5D+%5B%22his%22%5D+%5B%22arms%22%5D+%5B%22around%22%5D+%5B%22me%22%5D+%5B%5D+%5B%22He%22%5D+%5B%22embraced%22%5D+%5B%22me%22%5D+%5B%5D+%5B%22hugged%22%5D+%5B%22me%22%5D+%5B%5D+%5B%22kissed%22%5D+%5B%22me%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'He look at me , look at me , he start crying . ... He was close to me . He put his arms around me . He embraced me , hugged me , kissed me . ', 'right': '', 'complete_match': 'He look at me , look at me , he start crying . ... He was close to me . He put his arms around me . He embraced me , hugged me , kissed me . ', 'testimony_id': 'irn504790', 'shelfmark': ['USHMM RG-50.030*0294'], 'token_start': 24123, 'token_end': 24160}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"He look at me, look at me, he start crying. ... He was close to me. He put his arms around me. He embraced me, hugged me, kissed me.\"\n",
    "fragment_3['label']=\"He look at me, look at me, he start crying. (..) He put his arms around me. He embraced me, hugged me, kissed me.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22He%22%5D+%5B%22embraces%22%5D+%5B%22me%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22both%22%5D+%5B%22cry%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'He embraces me , and we both cry . ', 'right': '', 'complete_match': 'He embraces me , and we both cry . ', 'testimony_id': 'usc_shoah_268', 'shelfmark': ['USC 268'], 'token_start': 42331, 'token_end': 42340}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"He embraces me, and we both cry.\"\n",
    "fragment_4['label']= \"He embraces me, and we both cry.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
