{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"breathe\"\n",
    "delete_main_node(main_node)\n",
    "add_main_node(main_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '[lemma=\"breathe\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = topic_concordancer.main(query,window=25,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"breathe\",\"move\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"breathe\"][]{0,25}[lemma=\"move\"])|([lemma=\"move\"][]{0,25}[lemma=\"breathe\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"not to move\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22then%22%5D+%5B%22they%22%5D+%5B%22shut%22%5D+%5B%22the%22%5D+%5B%22trap%22%5D+%5B%22door%22%5D+%5B%5D+%5B%22told%22%5D+%5B%22us%22%5D+%5B%22not%22%5D+%5B%22to%22%5D+%5B%22move%22%5D+%5B%5D+%5B%22not%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22not%22%5D+%5B%22to%22%5D+%5B%22say%22%5D+%5B%22a%22%5D+%5B%22word%22%5D+%5B%5D+%5B%22not%22%5D+%5B%22to%22%5D+%5B%22sneeze%22%5D+%5B%5D+%5B%22Our%22%5D+%5B%22lives%22%5D+%5B%22depended%22%5D+%5B%22on%22%5D+%5B%22it%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And then they shut the trap door , told us not to move , not to breathe , not to say a word , not to sneeze . Our lives depended on it . ', 'right': '', 'complete_match': 'And then they shut the trap door , told us not to move , not to breathe , not to say a word , not to sneeze . Our lives depended on it . ', 'testimony_id': 'usc_shoah_14900', 'shelfmark': ['USC 14900'], 'token_start': 7140, 'token_end': 7174}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And then they shut the trap door, told us not to move, not to breathe, not to say a word, not to sneeze. Our lives depended on it.\"\n",
    "fragment_1['label']=\"(..) told us not to move, not to breathe, not to say a word, not to sneeze. Our lives depended on it.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22dare%22%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%22still%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22dare%22%5D+%5B%22move%22%5D+%5B%5D+%5B%22because%22%5D+%5B%22the%22%5D+%5B%22SS%22%5D+%5B%22woman%22%5D+%5B%22was%22%5D+%5B%22coming%22%5D+%5B%22along%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22she%22%5D+%5B%22was%22%5D+%5B%22picking%22%5D+%5B%22out%22%5D+%5B%22the%22%5D+%5B%22people%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"You did n't dare breathe . You were standing still . You did n't dare move , because the SS woman was coming along , and she was picking out the people . \", 'right': '', 'complete_match': \"You did n't dare breathe . You were standing still . You did n't dare move , because the SS woman was coming along , and she was picking out the people . \", 'testimony_id': 'HVT-18', 'shelfmark': ['Fortunoff HVT-18'], 'token_start': 8964, 'token_end': 8997}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"You didn't dare breathe. You were standing still. You didn't dare move, because the SS woman was coming along, and she was picking out the people.\"\n",
    "fragment_2['label']=\"You didn't dare breathe. You were standing still. You didn't dare move (..).\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22they%22%5D+%5B%22told%22%5D+%5B%22me%22%5D+%5B%22to%22%5D+%5B%22be%22%5D+%5B%22very%22%5D+%5B%22quiet%22%5D+%5B%22and%22%5D+%5B%22not%22%5D+%5B%22to%22%5D+%5B%22move%22%5D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22remember%22%5D+%5B%22feeling%22%5D+%5B%22that%22%5D+%5B%5D+%5B%22that%22%5D+%5B%22I%22%5D+%5B%22wa%22%5D+%5B%22suffocating%22%5D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22breathe%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"they told me to be very quiet and not to move and I remember feeling that , that I wa suffocating and I could n't breathe \", 'right': '', 'complete_match': \"they told me to be very quiet and not to move and I remember feeling that , that I wa suffocating and I could n't breathe \", 'testimony_id': 'irn511022', 'shelfmark': ['USHMM RG-50.471*0005'], 'token_start': 2012, 'token_end': 2038}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"they told me to be very quiet and not to move and I remember feeling that, that I wa suffocating and I couldn't breathe\"\n",
    "fragment_3['label']=\".(..)they told me to be very quiet and not to move and I remember feeling that, that I wa suffocating and I couldn't breathe(..).\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Whispering%22%5D+%5B%5D+%5B%22do%22%5D+%5B%5D+%5B%22move%22%5D+%5B%5D+%5B%22do%22%5D+%5B%5D+%5B%22cough%22%5D+%5B%5D+%5B%22do%22%5D+%5B%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22nothing%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Whispering , do n’t move , do n’t cough , do n’t breathe , nothing . ', 'right': '', 'complete_match': 'Whispering , do n’t move , do n’t cough , do n’t breathe , nothing . ', 'testimony_id': 'irn39788', 'shelfmark': ['USHMM RG-50.030*0541'], 'token_start': 7601, 'token_end': 7617}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"Whispering, don’t move, don’t cough, don’t breathe, nothing.\"\n",
    "fragment_4['label']= \"Whispering, don’t move, don’t cough, don’t breathe, nothing.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"afraid\",\"breathe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"afraid\"][]{0,10}[lemma=\"breathe\"])|([lemma=\"breathe\"][]{0,10}[lemma=\"afraid\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"afraid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22afraid%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22because%22%5D+%5B%22to%22%5D+%5B%22make%22%5D+%5B%22noise%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22would%22%5D+%5B%22hear%22%5D+%5B%22you%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"You could n't breathe . I was afraid I was to breathe , because to make noise , they would hear you . \", 'right': '', 'complete_match': \"You could n't breathe . I was afraid I was to breathe , because to make noise , they would hear you . \", 'testimony_id': 'HVT-72', 'shelfmark': ['Fortunoff HVT-72'], 'token_start': 7282, 'token_end': 7305}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"You couldn't breathe. I was afraid I was to breathe, because to make noise, they would hear you.\"\n",
    "fragment_1['label']=\"You couldn't breathe. I was afraid I was to breathe, because to make noise, they would hear you.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22were%22%5D+%5B%22afraid%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22hear%22%5D+%5B%22us%22%5D+%5B%22breathe%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We were afraid to breathe , they hear us breathe . ', 'right': '', 'complete_match': 'We were afraid to breathe , they hear us breathe . ', 'testimony_id': 'irn44160', 'shelfmark': ['USHMM RG-50.637*0003'], 'token_start': 4659, 'token_end': 4670}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"We were afraid to breathe, they hear us breathe.\"\n",
    "fragment_2['label']=\"We were afraid to breathe, they hear us breathe.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Oh%22%5D+%5B%5D+%5B%22yeah%22%5D+%5B%5D+%5B%22standing%22%5D+%5B%22with%22%5D+%5B%22the%22%5D+%5B%22guns%22%5D+%5B%22pointing%22%5D+%5B%22towards%22%5D+%5B%22you%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22were%22%5D+%5B%22afraid%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Oh , yeah , standing with the guns pointing towards you . You were afraid to breathe . ', 'right': '', 'complete_match': 'Oh , yeah , standing with the guns pointing towards you . You were afraid to breathe . ', 'testimony_id': 'usc_shoah_1491', 'shelfmark': ['USC 1491'], 'token_start': 5768, 'token_end': 5786}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"Oh, yeah, standing with the guns pointing towards you. You were afraid to breathe.\"\n",
    "fragment_3['label']=\"Oh, yeah, standing with the guns pointing towards you. You were afraid to breathe.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22under%22%5D+%5B%22that%22%5D+%5B%22bed%22%5D+%5B%5D+%5B%22lying%22%5D+%5B%22flat%22%5D+%5B%5D+%5B%22afraid%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%22even%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And I was under that bed , lying flat , afraid to breathe even . ', 'right': '', 'complete_match': 'And I was under that bed , lying flat , afraid to breathe even . ', 'testimony_id': 'usc_shoah_9590', 'shelfmark': ['USC 9590'], 'token_start': 8807, 'token_end': 8822}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"And I was under that bed, lying flat, afraid to breathe even.\"\n",
    "fragment_4['label']= \"And I was under that bed, lying flat, afraid to breathe even.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Because%22%5D+%5B%22of%22%5D+%5B%22fear%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22absolutely%22%5D+%5B%22silent%22%5D+%5B%5D+%5B%22almost%22%5D+%5B%22afraid%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%5D%7B0%2C3%7D+%5B%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Because of fear , we were absolutely silent , almost afraid to breathe , because he ', 'right': '', 'complete_match': 'Because of fear , we were absolutely silent , almost afraid to breathe , because he ', 'testimony_id': 'usc_shoah_8784', 'shelfmark': ['USC 8784'], 'token_start': 7959, 'token_end': 7975}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"Because of fear, we were absolutely silent, almost afraid to breathe (..).\"\n",
    "fragment_5['label']= \"Because of fear, we were absolutely silent, almost afraid to breathe, \"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"choke\",\"breathe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"choke\"][]{0,10}[lemma=\"breathe\"])|([lemma=\"breathe\"][]{0,10}[lemma=\"choke\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"choke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22she%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22take%22%5D+%5B%22it%22%5D+%5B%22out%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22baby%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22baby%22%5D+%5B%22choked%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And she could n't take it out , and the baby could n't breathe , and the baby choked . \", 'right': '', 'complete_match': \"And she could n't take it out , and the baby could n't breathe , and the baby choked . \", 'testimony_id': 'usc_shoah_25381', 'shelfmark': ['USC 25381'], 'token_start': 15683, 'token_end': 15703}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And she couldn't take it out, and the baby couldn't breathe, and the baby choked.\"\n",
    "fragment_1['label']=\"And she couldn't take it out, and the baby couldn't breathe, and the baby choked.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22she%22%5D+%5B%22choked%22%5D+%5B%22the%22%5D+%5B%22baby%22%5D+%5B%5D+%5B%22Got%22%5D+%5B%22choked%22%5D+%5B%5D+%5B%22Could%22%5D+%5B%5D+%5B%22breathe%22%5D+%5B%22because%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22a%22%5D+%5B%22long%22%5D+%5B%22time%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22forest%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And she choked the baby . Got choked . Could n't breathe because they were a long time in the forest . \", 'right': '', 'complete_match': \"And she choked the baby . Got choked . Could n't breathe because they were a long time in the forest . \", 'testimony_id': 'usc_shoah_25381', 'shelfmark': ['USC 25381'], 'token_start': 15652, 'token_end': 15674}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"And she choked the baby. Got choked. Couldn't breathe because they were a long time in the forest.\"\n",
    "fragment_2['label']=\"And she choked the baby. Got choked. Couldn't breathe because they were a long time in the forest.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22could%22%5D+%5B%22almost%22%5D+%5B%22choke%22%5D+%5B%5D+%5B%22breathing%22%5D+%5B%22that%22%5D+%5B%22air%22%5D+%5B%22there%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You could almost choke , breathing that air there . ', 'right': '', 'complete_match': 'You could almost choke , breathing that air there . ', 'testimony_id': 'irn504798', 'shelfmark': ['USHMM RG-50.030*0303'], 'token_start': 17107, 'token_end': 17117}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"You could almost choke, breathing that air there.\"\n",
    "fragment_3['label']=\"You could almost choke, breathing that air there.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22had%22%5D+%5B%22always%22%5D+%5B%22suffered%22%5D+%5B%22from%22%5D+%5B%22anxieties%22%5D+%5B%22and%22%5D+%5B%22sometimes%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22so%22%5D+%5B%22severe%22%5D+%5B%22I%22%5D+%5B%22had%22%5D+%5B%22the%22%5D+%5B%22feeling%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22choking%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22middle%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22night%22%5D+%5B%22and%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22breathe%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"I had always suffered from anxieties and sometimes they were so severe I had the feeling I was choking in the middle of the night and could n't breathe \", 'right': '', 'complete_match': \"I had always suffered from anxieties and sometimes they were so severe I had the feeling I was choking in the middle of the night and could n't breathe \", 'testimony_id': 'irn504920', 'shelfmark': ['USHMM RG-50.549.01*0013'], 'token_start': 12830, 'token_end': 12859}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"I had always suffered from anxieties and sometimes they were so severe I had the feeling I was choking in the middle of the night and couldn't breathe\"\n",
    "fragment_4['label']= \"I had always suffered from anxieties (..) I had the feeling I was choking in the middle of the night and couldn't breathe \"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"smell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22remember%22%5D+%5B%22we%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22The%22%5D+%5B%22smell%22%5D+%5B%22was%22%5D+%5B%22terrible%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"I remember we could n't breathe . The smell was terrible \", 'right': '', 'complete_match': \"I remember we could n't breathe . The smell was terrible \", 'testimony_id': 'irn505573', 'shelfmark': ['USHMM RG-50.042*0020'], 'token_start': 2741, 'token_end': 2752}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"I remember we couldn't breathe. The smell was terrible\"\n",
    "fragment_1['label']=\"I remember we couldn't breathe. The smell was terrible (..)\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22It%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22terrible%22%5D+%5B%22smell%22%5D+%5B%5D+%5B%22Months%22%5D+%5B%22and%22%5D+%5B%22months%22%5D+%5B%22we%22%5D+%5B%22have%22%5D+%5B%22to%22%5D+%5B%22smell%22%5D+%5B%5D%7B0%2C50%7D+%5B%22we%22%5D+%5B%22always%22%5D+%5B%22have%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%22it%22%5D+%5B%22in%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'It was a terrible smell . Months and months we have to smell ... we always have to breathe it in ', 'right': '', 'complete_match': 'It was a terrible smell . Months and months we have to smell ... we always have to breathe it in ', 'testimony_id': 'irn508637', 'shelfmark': ['USHMM RG-50.462*0016'], 'token_start': 27734, 'token_end': 27755}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"It was a terrible smell. Months and months we have to smell...we always have to breathe it in\"\n",
    "fragment_2['label']=\"It was a terrible smell. Months and months we have to smell...we always have to breathe it in (..).\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22were%22%5D+%5B%22eating%22%5D+%5B%22and%22%5D+%5B%22breathing%22%5D+%5B%22this%22%5D+%5B%5D%7B0%2C3%7D+%5B%22this%22%5D+%5B%5D%7B0%2C3%7D+%5B%22this%22%5D+%5B%22smell%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'were eating and breathing this -- this -- this smell ', 'right': '', 'complete_match': 'were eating and breathing this -- this -- this smell ', 'testimony_id': 'usc_shoah_7506', 'shelfmark': ['USC 7506'], 'token_start': 20797, 'token_end': 20807}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"were eating and breathing this-- this-- this smell\"\n",
    "fragment_3['label']=\"we were eating and breathing this smell\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22My%22%5D+%5B%22nostrils%22%5D+%5B%22fill%22%5D+%5B%22with%22%5D+%5B%22the%22%5D+%5B%22dank%22%5D+%5B%22smell%22%5D+%5B%22of%22%5D+%5B%22death%22%5D+%5B%5D+%5B%22but%22%5D+%5B%22I%22%5D+%5B%22have%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'My nostrils fill with the dank smell of death , but I have to breathe . ', 'right': '', 'complete_match': 'My nostrils fill with the dank smell of death , but I have to breathe . ', 'testimony_id': 'usc_shoah_322', 'shelfmark': ['USC 322'], 'token_start': 883, 'token_end': 899}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"My nostrils fill with the dank smell of death, but I have to breathe.\"\n",
    "fragment_4['label']= \"My nostrils fill with the dank smell of death, but I have to breathe.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22the%22%5D+%5B%22stench%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22burning%22%5D+%5B%22flesh%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22just%22%5D+%5B%22could%22%5D+%5B%22not%22%5D+%5B%22breathe%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'the stench , the smell of the burning flesh . I just could not breathe . ', 'right': '', 'complete_match': 'the stench , the smell of the burning flesh . I just could not breathe . ', 'testimony_id': 'usc_shoah_23730', 'shelfmark': ['USC 23730'], 'token_start': 9964, 'token_end': 9980}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \" the stench, the smell of the burning flesh. I just could not breathe.\"\n",
    "fragment_5['label']= \"(..)the stench, the smell of the burning flesh. I just could not breathe.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"breathe\",\"die\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"breathe\"][]{0,25}[lemma=\"die\"])|([lemma=\"die\"][]{0,25}[lemma=\"breathe\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"die\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22people%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22There%22%5D+%5B%5D+%5B%22a%22%5D+%5B%22lot%22%5D+%5B%22of%22%5D+%5B%22people%22%5D+%5B%22died%22%5D+%5B%22right%22%5D+%5B%22then%22%5D+%5B%22and%22%5D+%5B%22there%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"The people could n't breathe . There 's a lot of people died right then and there . \", 'right': '', 'complete_match': \"The people could n't breathe . There 's a lot of people died right then and there . \", 'testimony_id': 'usc_shoah_1775', 'shelfmark': ['USC 1775'], 'token_start': 4075, 'token_end': 4093}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \" The people couldn't breathe. There's a lot of people died right then and there.\"\n",
    "fragment_1['label']=\" The people couldn't breathe. There's a lot of people died right then and there. \"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22the%22%5D+%5B%22girls%22%5D+%5B%22were%22%5D+%5B%22dying%22%5D+%5B%22right%22%5D+%5B%22in%22%5D+%5B%22front%22%5D+%5B%22of%22%5D+%5B%22us%22%5D+%5B%5D+%5B%22And%22%5D+%5B%5D%7B0%2C3%7D+%5B%22and%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22so%22%5D+%5B%22heavy%22%5D+%5B%22to%22%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22in%22%5D+%5B%22that%22%5D+%5B%5D%7B0%2C3%7D+%5B%22cattle%22%5D+%5B%22car%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'the girls were dying right in front of us . And -- and it was so heavy to breathe , you know , in that closed-in cattle car . ', 'right': '', 'complete_match': 'the girls were dying right in front of us . And -- and it was so heavy to breathe , you know , in that closed-in cattle car . ', 'testimony_id': 'usc_shoah_3949', 'shelfmark': ['USC 3949'], 'token_start': 14579, 'token_end': 14608}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"the girls were dying right in front of us. And-- and it was so heavy to breathe, you know, in that closed-in cattle car.\"\n",
    "fragment_2['label']=\"(..) the girls were dying right in front of us. And-- and it was so heavy to breathe, you know, in that closed-in cattle car. \"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22my%22%5D+%5B%22father%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22He%22%5D+%5B%22was%22%5D+%5B%22dying%22%5D+%5B%22right%22%5D+%5B%22then%22%5D+%5B%22and%22%5D+%5B%22there%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"my father could n't breathe . He was dying right then and there . \", 'right': '', 'complete_match': \"my father could n't breathe . He was dying right then and there . \", 'testimony_id': 'usc_shoah_19111', 'shelfmark': ['USC 19111'], 'token_start': 17261, 'token_end': 17275}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"my father couldn't breathe. He was dying right then and there.\"\n",
    "fragment_3['label']=\"(..) my father couldn't breathe. He was dying right then and there.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22could%22%5D+%5B%22hardly%22%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22were%22%5D+%5B%22face%22%5D+%5B%22to%22%5D+%5B%22face%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22had%22%5D+%5B%22people%22%5D+%5B%22that%22%5D+%5B%22finally%22%5D+%5B%22passed%22%5D+%5B%22away%22%5D+%5B%5D+%5B%22died%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You could hardly breathe . You were face to face . We had people that finally passed away , died . ', 'right': '', 'complete_match': 'You could hardly breathe . You were face to face . We had people that finally passed away , died . ', 'testimony_id': 'usc_shoah_4284', 'shelfmark': ['USC 4284'], 'token_start': 16226, 'token_end': 16247}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"You could hardly breathe. You were face to face. We had people that finally passed away, died.\"\n",
    "fragment_4['label']= \"You could hardly breathe. You were face to face. We had people that finally passed away, died.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22even%22%5D+%5B%22breathe%22%5D+%5B%5D+%5B%22Quite%22%5D+%5B%22a%22%5D+%5B%22few%22%5D+%5B%22older%22%5D+%5B%22people%22%5D+%5B%22die%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"We could n't even breathe . Quite a few older people die . \", 'right': '', 'complete_match': \"We could n't even breathe . Quite a few older people die . \", 'testimony_id': 'usc_shoah_7160', 'shelfmark': ['USC 7160'], 'token_start': 1159, 'token_end': 1172}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"We couldn't even breathe. Quite a few older people die.\"\n",
    "fragment_5['label']= \"We couldn't even breathe. Quite a few older people die.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
