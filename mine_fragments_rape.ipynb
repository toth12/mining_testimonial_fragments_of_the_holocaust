{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain: rape**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"rape\"\n",
    "#delete_main_node(main_node)\n",
    "add_main_node(main_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '[lemma=\"rape\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = topic_concordancer.main(query,window=50,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"kill\",\"rape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"kill\"][]{0,50}[lemma=\"rape\"])|([lemma=\"rape\"][]{0,50}[lemma=\"kill\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"kill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Sometimes%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22raped%22%5D+%5B%22them%22%5D+%5B%5D+%5B%22They%22%5D+%5B%22killed%22%5D+%5B%22them%22%5D+%5B%22right%22%5D+%5B%22away%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Sometimes , they raped them . They killed them right away . ', 'right': '', 'complete_match': 'Sometimes , they raped them . They killed them right away . ', 'testimony_id': 'usc_shoah_2590', 'shelfmark': ['USC 2590'], 'token_start': 1782, 'token_end': 1794}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"Sometimes, they raped them. They killed them right away.\"\n",
    "fragment_1['label']=\"Sometimes, they raped them. They killed them right away.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22night%22%5D+%5B%22that%22%5D+%5B%22they%22%5D+%5B%22marched%22%5D+%5B%22into%22%5D+%5B%22Jasionowka%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22heard%22%5D+%5B%22rumors%22%5D+%5B%5D+%5B%22even%22%5D+%5B%22before%22%5D+%5B%5D+%5B%22that%22%5D+%5B%22wherever%22%5D+%5B%22they%22%5D+%5B%22marched%22%5D+%5B%22in%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22burned%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22killed%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22raped%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22did%22%5D+%5B%22horrible%22%5D+%5B%22things%22%5D+%5B%22to%22%5D+%5B%22the%22%5D+%5B%22Jewish%22%5D+%5B%22people%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The night that they marched into Jasionowka , we heard rumors , even before , that wherever they marched in , they burned , they killed , they raped , and they did horrible things to the Jewish people . ', 'right': '', 'complete_match': 'The night that they marched into Jasionowka , we heard rumors , even before , that wherever they marched in , they burned , they killed , they raped , and they did horrible things to the Jewish people . ', 'testimony_id': 'usc_shoah_7458', 'shelfmark': ['USC 7458'], 'token_start': 6791, 'token_end': 6831}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"The night that they marched into Jasionowka, we heard rumors, even before, that wherever they marched in, they burned, they killed, they raped, and they did horrible things to the Jewish people. \"\n",
    "fragment_2['label']=\"they burned, they killed, they raped,\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22grabbed%22%5D+%5B%22the%22%5D+%5B%22girl%22%5D+%5B%22and%22%5D+%5B%22raped%22%5D+%5B%22her%22%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22cry%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They grabbed the girl and raped her and they cry ', 'right': '', 'complete_match': 'They grabbed the girl and raped her and they cry ', 'testimony_id': 'irn504583', 'shelfmark': ['USHMM RG-50.030*0088'], 'token_start': 16020, 'token_end': 16030}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"They grabbed the girl and raped her and they cry\"\n",
    "fragment_3['label']=\"They grabbed the girl and raped her and they cry\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22Russian%22%5D+%5B%22took%22%5D+%5B%22her%22%5D+%5B%5D+%5B%22raped%22%5D+%5B%22her%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22killed%22%5D+%5B%22her%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The Russian took her , raped her , and killed her . ', 'right': '', 'complete_match': 'The Russian took her , raped her , and killed her . ', 'testimony_id': 'irn508651', 'shelfmark': ['USHMM RG-50.462*0031'], 'token_start': 38455, 'token_end': 38467}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"The Russian took her, raped her, and killed her.\"\n",
    "fragment_4['label']= \"The Russian took her, raped her, and killed her.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22an%22%5D+%5B%22aunt%22%5D+%5B%22was%22%5D+%5B%22raped%22%5D+%5B%22and%22%5D+%5B%22killed%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And an aunt was raped and killed . ', 'right': '', 'complete_match': 'And an aunt was raped and killed . ', 'testimony_id': 'irn509148', 'shelfmark': ['USHMM RG-50.233*0065'], 'token_start': 1503, 'token_end': 1511}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"And an aunt was raped and killed.\"\n",
    "fragment_5['label']= \"And an aunt was raped and killed.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"watch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22She%22%5D+%5B%22saw%22%5D+%5B%22her%22%5D+%5B%22mother%22%5D+%5B%22raped%22%5D+%5B%22to%22%5D+%5B%22death%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'She saw her mother raped to death ', 'right': '', 'complete_match': 'She saw her mother raped to death ', 'testimony_id': 'usc_shoah_14900', 'shelfmark': ['USC 14900'], 'token_start': 15674, 'token_end': 15681}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"She saw her mother raped to death\"\n",
    "fragment_1['label']=\"She saw her mother raped to death\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22I%22%5D+%5B%22watched%22%5D+%5B%22them%22%5D+%5B%22rape%22%5D+%5B%22the%22%5D+%5B%22women%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And I watched them rape the women . ', 'right': '', 'complete_match': 'And I watched them rape the women . ', 'testimony_id': 'usc_shoah_162', 'shelfmark': ['USC 162'], 'token_start': 7990, 'token_end': 7998}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"And I watched them rape the women.\"\n",
    "fragment_2['label']=\" And I watched them rape the women.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22to%22%5D+%5B%22see%22%5D+%5B%22those%22%5D+%5B%22young%22%5D+%5B%22women%22%5D+%5B%22raped%22%5D+%5B%22by%22%5D+%5B%22the%22%5D+%5B%22men%22%5D+%5B%22there%22%5D+%5B%22with%22%5D+%5B%22sticks%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22my%22%5D+%5B%22mother%22%5D+%5B%22was%22%5D+%5B%22near%22%5D+%5B%22me%22%5D+%5B%22and%22%5D+%5B%22she%22%5D+%5B%22took%22%5D+%5B%22her%22%5D+%5B%22hand%22%5D+%5B%22and%22%5D+%5B%22put%22%5D+%5B%22on%22%5D+%5B%22my%22%5D+%5B%22eyes%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22should%22%5D+%5B%5D+%5B%22see%22%5D+%5B%22for%22%5D+%5B%22the%22%5D+%5B%22first%22%5D+%5B%22time%22%5D+%5B%22sexual%22%5D+%5B%22intercourse%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And to see those young women raped by the men there with sticks , and my mother was near me and she took her hand and put on my eyes , I should n't see for the first time sexual intercourse . \", 'right': '', 'complete_match': \"And to see those young women raped by the men there with sticks , and my mother was near me and she took her hand and put on my eyes , I should n't see for the first time sexual intercourse . \", 'testimony_id': 'irn506760', 'shelfmark': ['USHMM RG-50.030*0197'], 'token_start': 6592, 'token_end': 6634}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And to see those young women raped by the men there with sticks, and my mother was near me and she took her hand and put on my eyes, I shouldn't see for the first time sexual intercourse.\"\n",
    "fragment_3['label']=\"(..)to see those young women raped by the men (..)\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22that%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22one%22%5D+%5B%5D+%5B%22she%22%5D+%5B%22was%22%5D+%5B%22raped%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"that 's the one , she was raped \", 'right': '', 'complete_match': \"that 's the one , she was raped \", 'testimony_id': 'usc_shoah_1222', 'shelfmark': ['USC 1222'], 'token_start': 2189, 'token_end': 2197}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"that's the one, she was raped\"\n",
    "fragment_4['label']= \" She saw, she-- that's the one, she was raped\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"shoot\",\"rape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"shoot\"][]{0,50}[lemma=\"rape\"])|([lemma=\"rape\"][]{0,50}[lemma=\"shoot\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"shoot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22probably%22%5D+%5B%22raped%22%5D+%5B%22them%22%5D+%5B%5D+%5B%22abused%22%5D+%5B%22them%22%5D+%5B%5D+%5B%22eventually%22%5D+%5B%22shot%22%5D+%5B%22them%22%5D+%5B%22because%22%5D+%5B%22nobody%22%5D+%5B%22survived%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They probably raped them , abused them , eventually shot them because nobody survived ', 'right': '', 'complete_match': 'They probably raped them , abused them , eventually shot them because nobody survived ', 'testimony_id': 'usc_shoah_10406', 'shelfmark': ['USC 10406'], 'token_start': 20350, 'token_end': 20364}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"They probably raped them, abused them, eventually shot them because nobody survived\"\n",
    "fragment_1['label']=\"They probably raped them, abused them, eventually shot them because nobody survived\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22picked%22%5D+%5B%22the%22%5D+%5B%22nice%22%5D+%5B%22looking%22%5D+%5B%22girls%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22raped%22%5D+%5B%22them%22%5D+%5B%22and%22%5D+%5B%22then%22%5D+%5B%22they%22%5D+%5B%22shot%22%5D+%5B%22them%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They picked the nice looking girls , they raped them and then they shot them . ', 'right': '', 'complete_match': 'They picked the nice looking girls , they raped them and then they shot them . ', 'testimony_id': 'irn510487', 'shelfmark': ['USHMM RG-50.322*0033'], 'token_start': 34868, 'token_end': 34884}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"They picked the nice looking girls, they raped them and then they shot them.\"\n",
    "fragment_2['label']=\"They picked the nice looking girls, they raped them and then they shot them.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22was%22%5D+%5B%22raped%22%5D+%5B%22and%22%5D+%5B%22shot%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22middle%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22street%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'was raped and shot in the middle of the street . ', 'right': '', 'complete_match': 'was raped and shot in the middle of the street . ', 'testimony_id': 'usc_shoah_11593', 'shelfmark': ['USC 11593'], 'token_start': 3721, 'token_end': 3732}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"was raped and shot in the middle of the street.\"\n",
    "fragment_3['label']=\"(..) name was Hannah Prusak, P-R-U-S-A-K-- was raped and shot in the middle of the street.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22know%22%5D+%5B%22she%22%5D+%5B%22was%22%5D+%5B%22raped%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22know%22%5D+%5B%22that%22%5D+%5B%22they%22%5D+%5B%22put%22%5D+%5B%22a%22%5D+%5B%22big%22%5D+%5B%22stick%22%5D+%5B%22through%22%5D+%5B%22her%22%5D+%5B%22genitals%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22know%22%5D+%5B%22that%22%5D+%5B%22they%22%5D+%5B%22tortured%22%5D+%5B%22her%22%5D+%5B%22before%22%5D+%5B%22they%22%5D+%5B%22shot%22%5D+%5B%22her%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I know she was raped . I know that they put a big stick through her genitals . I know that they tortured her before they shot her . ', 'right': '', 'complete_match': 'I know she was raped . I know that they put a big stick through her genitals . I know that they tortured her before they shot her . ', 'testimony_id': 'usc_shoah_5799', 'shelfmark': ['USC 5799'], 'token_start': 5010, 'token_end': 5039}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"I know she was raped. I know that they put a big stick through her genitals. I know that they tortured her before they shot her. \"\n",
    "fragment_4['label']= \"I know she was raped. (.. ) I know that they tortured her before they shot her.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. afraid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"afraid\",\"rape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"afraid\"][]{0,50}[lemma=\"rape\"])|([lemma=\"rape\"][]{0,50}[lemma=\"afraid\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"afraid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22did%22%5D+%5B%22not%22%5D+%5B%22know%22%5D+%5B%22what%22%5D+%5B%22rape%22%5D+%5B%22meant%22%5D+%5B%5D+%5B%22but%22%5D+%5B%22I%22%5D+%5B%22knew%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22something%22%5D+%5B%22that%22%5D+%5B%22women%22%5D+%5B%22were%22%5D+%5B%22afraid%22%5D+%5B%22of%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I did not know what rape meant , but I knew it was something that women were afraid of . ', 'right': '', 'complete_match': 'I did not know what rape meant , but I knew it was something that women were afraid of . ', 'testimony_id': 'HVT-123', 'shelfmark': ['Fortunoff HVT-123'], 'token_start': 12222, 'token_end': 12242}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"I did not know what rape meant, but I knew it was something that women were afraid of.\"\n",
    "fragment_1['label']=\"I did not know what rape meant, but I knew it was something that women were afraid of.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22that%22%5D+%5B%22they%22%5D+%5B%22would%22%5D+%5B%22come%22%5D+%5B%22and%22%5D+%5B%22rape%22%5D+%5B%22us%22%5D+%5B%5D+%5B%22or%22%5D+%5B%22whatever%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'you know , that they would come and rape us , or whatever . ', 'right': '', 'complete_match': 'you know , that they would come and rape us , or whatever . ', 'testimony_id': 'irn506747', 'shelfmark': ['USHMM RG-50.549.02*0020'], 'token_start': 6476, 'token_end': 6490}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"you know, that they would come and rape us, or whatever.\"\n",
    "fragment_2['label']=\"And these were soldiers and they were afraid of -- you know, that they would come and rape us, or whatever.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22were%22%5D+%5B%22afraid%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22going%22%5D+%5B%22to%22%5D+%5B%22rape%22%5D+%5B%22us%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We were afraid they were going to rape us . ', 'right': '', 'complete_match': 'We were afraid they were going to rape us . ', 'testimony_id': 'irn504676', 'shelfmark': ['USHMM RG-50.030*0176'], 'token_start': 15013, 'token_end': 15023}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"We were afraid they were going to rape us.\"\n",
    "fragment_3['label']=\"We were afraid they were going to rape us.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22were%22%5D+%5B%22afraid%22%5D+%5B%22for%22%5D+%5B%22raping%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We were afraid for raping . ', 'right': '', 'complete_match': 'We were afraid for raping . ', 'testimony_id': 'irn504842', 'shelfmark': ['USHMM RG-50.030*0348'], 'token_start': 18646, 'token_end': 18652}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"We were afraid for raping.\"\n",
    "fragment_4['label']= \"We were afraid for raping.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
