{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"smell\"\n",
    "delete_main_node(main_node)\n",
    "add_main_node(main_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = '[lemma=\"smell\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = topic_concordancer.main(query,window=15,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"body\",\"smell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"body\"][]{0,10}[lemma=\"smell\"])|([lemma=\"smell\"][]{0,10}[lemma=\"body\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"dead bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22That%22%5D+%5B%22was%22%5D+%5B%22supposed%22%5D+%5B%22to%22%5D+%5B%22be%22%5D+%5B%22food%22%5D+%5B%22but%22%5D+%5B%22they%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22feed%22%5D+%5B%22us%22%5D+%5B%22anymore%22%5D+%5B%22and%22%5D+%5B%22since%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22very%22%5D+%5B%22warm%22%5D+%5B%22spring%22%5D+%5B%22they%22%5D+%5B%22decomposed%22%5D+%5B%22and%22%5D+%5B%22smelled%22%5D+%5B%22so%22%5D+%5B%22horrible%22%5D+%5B%22and%22%5D+%5B%22with%22%5D+%5B%22the%22%5D+%5B%22rest%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22dead%22%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22stench%22%5D+%5B%22was%22%5D+%5B%22terrible%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22could%22%5D+%5B%22almost%22%5D+%5B%22choke%22%5D+%5B%5D+%5B%22breathing%22%5D+%5B%22that%22%5D+%5B%22air%22%5D+%5B%22there%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"That was supposed to be food but they did n't feed us anymore and since it was a very warm spring they decomposed and smelled so horrible and with the rest of the dead bodies , the stench was terrible . You could almost choke , breathing that air there . \", 'right': '', 'complete_match': \"That was supposed to be food but they did n't feed us anymore and since it was a very warm spring they decomposed and smelled so horrible and with the rest of the dead bodies , the stench was terrible . You could almost choke , breathing that air there . \", 'testimony_id': 'irn504798', 'shelfmark': ['USHMM RG-50.030*0303'], 'token_start': 17066, 'token_end': 17117}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"That was supposed to be food but they didn't feed us anymore and since it was a very warm spring they decomposed and smelled so horrible and with the rest of the dead bodies, the stench was terrible. You could almost choke, breathing that air there.\"\n",
    "fragment_1['label']=\"(..) smelled so horrible and with the rest of the dead bodies, the stench was terrible. You could almost choke, breathing that air there.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22the%22%5D+%5B%22meat%22%5D+%5B%22was%22%5D+%5B%22rotting%22%5D+%5B%22away%22%5D+%5B%22from%22%5D+%5B%22their%22%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22The%22%5D+%5B%22smell%22%5D+%5B%5D%7B0%2C50%7D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22horrific%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The the meat was rotting away from their bodies . The smell ... it was horrific . ', 'right': '', 'complete_match': 'The the meat was rotting away from their bodies . The smell ... it was horrific . ', 'testimony_id': 'irn504690', 'shelfmark': ['USHMM RG-50.030*0195'], 'token_start': 7165, 'token_end': 7182}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"The the meat was rotting away from their bodies. The smell...it was horrific.\"\n",
    "fragment_2['label']=\"The the meat was rotting away from their bodies. The smell...it was horrific.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Yeah%22%5D+%5B%5D+%5B%22well%22%5D+%5B%22I%22%5D+%5B%22smelled%22%5D+%5B%22dead%22%5D+%5B%22bodies%22%5D+%5B%22and%22%5D+%5B%22stench%22%5D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22mean%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22place%22%5D+%5B%22smelled%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Yeah , well I smelled dead bodies and stench and I mean , the place smelled . ', 'right': '', 'complete_match': 'Yeah , well I smelled dead bodies and stench and I mean , the place smelled . ', 'testimony_id': 'usc_shoah_13483', 'shelfmark': ['USC Shoah Foundation 13483'], 'token_start': 13846, 'token_end': 13863}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"Yeah, well I smelled dead bodies and stench and I mean, the place smelled.\"\n",
    "fragment_3['label']=\"Yeah, well I smelled dead bodies and stench and I mean, the place smelled.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22It%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22terrible%22%5D+%5B%22smell%22%5D+%5B%5D+%5B%22hair%22%5D+%5B%22and%22%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22could%22%5D+%5B%22smell%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22was%22%5D+%5B%22very%22%5D+%5B%22scary%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'It was a terrible smell , hair and bodies . You could smell . And was very scary . ', 'right': '', 'complete_match': 'It was a terrible smell , hair and bodies . You could smell . And was very scary . ', 'testimony_id': 'usc_shoah_15610', 'shelfmark': ['USC Shoah Foundation 15610'], 'token_start': 7753, 'token_end': 7772}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"It was a terrible smell, hair and bodies. You could smell. And was very scary.\"\n",
    "fragment_4['label']= \"It was a terrible smell, hair and bodies. You could smell. And was very scary.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22These%22%5D+%5B%22thousands%22%5D+%5B%22of%22%5D+%5B%22dead%22%5D+%5B%22bodies%22%5D+%5B%22piled%22%5D+%5B%22up%22%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22stink%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'These thousands of dead bodies piled up and the smell , the stink ', 'right': '', 'complete_match': 'These thousands of dead bodies piled up and the smell , the stink ', 'testimony_id': 'usc_shoah_942', 'shelfmark': ['USC Shoah Foundation 942'], 'token_start': 32193, 'token_end': 32206}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"These thousands of dead bodies piled up and the smell, the stink\"\n",
    "fragment_5['label']= \"These thousands of dead bodies piled up and the smell, the stink (..).\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"hair\",\"smell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"hair\"][]{0,4}[lemma=\"smell\"])|([lemma=\"smell\"][]{0,4}[lemma=\"hair\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=4)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"hair\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22It%22%5D+%5B%22smelled%22%5D+%5B%22like%22%5D+%5B%22burned%22%5D+%5B%22hair%22%5D+%5B%5D+%5B%22If%22%5D+%5B%22you%22%5D+%5B%22take%22%5D+%5B%22hair%22%5D+%5B%22and%22%5D+%5B%22burn%22%5D+%5B%22it%22%5D+%5B%5D+%5B%22that%22%5D+%5B%5D+%5B%22what%22%5D+%5B%22it%22%5D+%5B%22smelled%22%5D+%5B%22like%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'It smelled like burned hair . If you take hair and burn it , that ’s what it smelled like . ', 'right': '', 'complete_match': 'It smelled like burned hair . If you take hair and burn it , that ’s what it smelled like . ', 'testimony_id': 'irn509382', 'shelfmark': ['USHMM RG-50.544*0001'], 'token_start': 4422, 'token_end': 4443}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"It smelled like burned hair. If you take hair and burn it, that’s what it smelled like.\"\n",
    "fragment_1['label']=\"It smelled like burned hair. If you take hair and burn it, that’s what it smelled like.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22But%22%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%22was%22%5D+%5B%22terrible%22%5D+%5B%5D%7B0%2C3%7D+%5B%22together%22%5D+%5B%5D+%5B%22hair%22%5D+%5B%22smelling%22%5D+%5B%5D+%5B%22body%22%5D+%5B%22smelling%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'But the smell was terrible -- together , hair smelling , body smelling . ', 'right': '', 'complete_match': 'But the smell was terrible -- together , hair smelling , body smelling . ', 'testimony_id': 'usc_shoah_25835', 'shelfmark': ['USC Shoah Foundation 25835'], 'token_start': 11645, 'token_end': 11659}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"But the smell was terrible-- together, hair smelling, body smelling.\"\n",
    "fragment_2['label']=\"But the smell was terrible-- together, hair smelling, body smelling.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22this%22%5D+%5B%22is%22%5D+%5B%22a%22%5D+%5B%22crematorium%22%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22felt%22%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%22of%22%5D+%5B%22hair%22%5D+%5B%5D+%5B%22of%22%5D+%5B%22bones%22%5D+%5B%5D+%5B%22so%22%5D+%5B%22I%22%5D+%5B%22said%22%5D+%5B%22no%22%5D+%5B%5D+%5B%22This%22%5D+%5B%22is%22%5D+%5B%22impossible%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'this is a crematorium and we felt the smell of hair , of bones , so I said no . This is impossible . ', 'right': '', 'complete_match': 'this is a crematorium and we felt the smell of hair , of bones , so I said no . This is impossible . ', 'testimony_id': 'usc_shoah_766', 'shelfmark': ['USC Shoah Foundation 766'], 'token_start': 27554, 'token_end': 27578}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \" this is a crematorium and we felt the smell of hair, of bones, so I said no. This is impossible.\"\n",
    "fragment_4['label']= \"(..) this is a crematorium and we felt the smell of hair, of bones, so I said no. This is impossible.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22you%22%5D+%5B%22smell%22%5D+%5B%22the%22%5D+%5B%22hair%22%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22bone%22%5D+%5B%5D+%5B%22and%22%5D+%5B%5D%7B0%2C3%7D+%5B%22you%22%5D+%5B%5D%7B0%2C3%7D+%5B%22you%22%5D+%5B%22make%22%5D+%5B%5D%7B0%2C3%7D+%5B%22you%22%5D+%5B%22do%22%5D+%5B%5D+%5B%22know%22%5D+%5B%22what%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And you smell the hair and the bone , and -- you -- you make -- you do n't know what it was . \", 'right': '', 'complete_match': \"And you smell the hair and the bone , and -- you -- you make -- you do n't know what it was . \", 'testimony_id': 'usc_shoah_7684', 'shelfmark': ['USC Shoah Foundation 7684'], 'token_start': 6227, 'token_end': 6251}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"And you smell the hair and the bone, and-- you-- you make-- you don't know what it was.\"\n",
    "fragment_5['label']= \"And you smell the hair and the bone, and-- you-- you make-- you don't know what it was.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"gas\",\"smell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"gas\"][]{0,10}[lemma=\"smell\"])|([lemma=\"smell\"][]{0,10}[lemma=\"gas\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"gas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22all%22%5D+%5B%5D%7B0%2C3%7D+%5B%22we%22%5D+%5B%22all%22%5D+%5B%22smelled%22%5D+%5B%22the%22%5D+%5B%22gas%22%5D+%5B%5D+%5B%22Believe%22%5D+%5B%22it%22%5D+%5B%22or%22%5D+%5B%22not%22%5D+%5B%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22not%22%5D+%5B%22true%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And we were all -- we all smelled the gas . Believe it or not , it was not true . ', 'right': '', 'complete_match': 'And we were all -- we all smelled the gas . Believe it or not , it was not true . ', 'testimony_id': 'HVT-134', 'shelfmark': ['Fortunoff Archive HVT-134'], 'token_start': 1950, 'token_end': 1971}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And we were all-- we all smelled the gas. Believe it or not, it was not true.\"\n",
    "fragment_1['label']=\"And we were all-- we all smelled the gas. Believe it or not, it was not true.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22So%22%5D+%5B%22I%22%5D+%5B%22knew%22%5D+%5B%22that%22%5D+%5B%5D+%5B%22where%22%5D+%5B%22it%22%5D+%5B%22happened%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22could%22%5D+%5B%22still%22%5D+%5B%22smell%22%5D+%5B%22the%22%5D+%5B%22gas%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"So I knew that 's where it happened . I could still smell the gas . \", 'right': '', 'complete_match': \"So I knew that 's where it happened . I could still smell the gas . \", 'testimony_id': 'usc_shoah_26140', 'shelfmark': ['USC Shoah Foundation 26140'], 'token_start': 8882, 'token_end': 8898}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \" So I knew that's where it happened. I could still smell the gas.\"\n",
    "fragment_2['label']=\" So I knew that's where it happened. I could still smell the gas.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Day%22%5D+%5B%22by%22%5D+%5B%22day%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22suffered%22%5D+%5B%5D+%5B%22People%22%5D+%5B%22died%22%5D+%5B%5D+%5B%22The%22%5D+%5B%22gas%22%5D+%5B%22smell%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Day by day , we suffered . People died . The gas smell . ', 'right': '', 'complete_match': 'Day by day , we suffered . People died . The gas smell . ', 'testimony_id': 'usc_shoah_628', 'shelfmark': ['USC Shoah Foundation 628'], 'token_start': 19694, 'token_end': 19708}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"Day by day, we suffered. People died. The gas smell.\"\n",
    "fragment_3['label']=\" Day by day, we suffered. People died. The gas smell.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22scene%22%5D+%5B%22is%22%5D+%5B%22in%22%5D+%5B%22stony%22%5D+%5B%22bunker%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22last%22%5D+%5B%22plea%22%5D+%5B%22for%22%5D+%5B%22breath%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%22of%22%5D+%5B%22gas%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22eerie%22%5D+%5B%22silence%22%5D+%5B%5D+%5B%22dead%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The scene is in stony bunker , the last plea for breath , the smell of gas , the eerie silence , dead . ', 'right': '', 'complete_match': 'The scene is in stony bunker , the last plea for breath , the smell of gas , the eerie silence , dead . ', 'testimony_id': 'usc_shoah_20686', 'shelfmark': ['USC Shoah Foundation 20686'], 'token_start': 13697, 'token_end': 13721}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"The scene is in stony bunker, the last plea for breath, the smell of gas, the eerie silence, dead.\"\n",
    "fragment_4['label']= \"The scene is in stony bunker, the last plea for breath, the smell of gas, the eerie silence, dead.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"body\",\"smell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"body\"][]{0,10}[lemma=\"smell\"])|([lemma=\"smell\"][]{0,10}[lemma=\"body\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"burning bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22burning%22%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22They%22%5D+%5B%22gathered%22%5D+%5B%22all%22%5D+%5B%22the%22%5D+%5B%22Jews%22%5D+%5B%22in%22%5D+%5B%22a%22%5D+%5B%22barn%22%5D+%5B%22at%22%5D+%5B%22the%22%5D+%5B%22end%22%5D+%5B%22of%22%5D+%5B%22this%22%5D+%5B%22town%22%5D+%5B%22and%22%5D+%5B%22put%22%5D+%5B%22a%22%5D+%5B%22burning%22%5D+%5B%22fire%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And the smell of the burning bodies . They gathered all the Jews in a barn at the end of this town and put a burning fire . ', 'right': '', 'complete_match': 'And the smell of the burning bodies . They gathered all the Jews in a barn at the end of this town and put a burning fire . ', 'testimony_id': 'HVT-172', 'shelfmark': ['Fortunoff Archive HVT-172'], 'token_start': 6543, 'token_end': 6571}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And the smell of the burning bodies. They gathered all the Jews in a barn at the end of this town and put a burning fire.\"\n",
    "fragment_1['label']=\"And the smell of the burning bodies. They gathered all the Jews in a barn at the end of this town and put a burning fire.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22then%22%5D+%5B%22we%22%5D+%5B%22could%22%5D+%5B%22smell%22%5D+%5B%22the%22%5D+%5B%22burning%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22human%22%5D+%5B%22flesh%22%5D+%5B%22burning%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And then we could smell the burning of the bodies , the human flesh burning . ', 'right': '', 'complete_match': 'And then we could smell the burning of the bodies , the human flesh burning . ', 'testimony_id': 'irn504659', 'shelfmark': ['USHMM RG-50.030*0161'], 'token_start': 4631, 'token_end': 4647}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"And then we could smell the burning of the bodies, the human flesh burning.\"\n",
    "fragment_2['label']=\"And then we could smell the burning of the bodies, the human flesh burning.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Then%22%5D+%5B%22we%22%5D+%5B%22realized%22%5D+%5B%22the%22%5D+%5B%22dreadful%22%5D+%5B%22smell%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22knew%22%5D+%5B%22those%22%5D+%5B%22were%22%5D+%5B%22the%22%5D+%5B%22burned%22%5D+%5B%22bodies%22%5D+%5B%22that%22%5D+%5B%22we%22%5D+%5B%22smelled%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Then we realized the dreadful smell , and we knew those were the burned bodies that we smelled . ', 'right': '', 'complete_match': 'Then we realized the dreadful smell , and we knew those were the burned bodies that we smelled . ', 'testimony_id': 'usc_shoah_5496', 'shelfmark': ['USC Shoah Foundation 5496'], 'token_start': 5942, 'token_end': 5961}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"Then we realized the dreadful smell, and we knew those were the burned bodies that we smelled.\"\n",
    "fragment_3['label']=\"Then we realized the dreadful smell, and we knew those were the burned bodies that we smelled.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22could%22%5D+%5B%22smell%22%5D+%5B%22the%22%5D+%5B%22air%22%5D+%5B%22from%22%5D+%5B%22burnt%22%5D+%5B%22bodies%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You could smell the air from burnt bodies . ', 'right': '', 'complete_match': 'You could smell the air from burnt bodies . ', 'testimony_id': 'usc_shoah_8352', 'shelfmark': ['USC Shoah Foundation 8352'], 'token_start': 10063, 'token_end': 10072}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"You could smell the air from burnt bodies.\"\n",
    "fragment_4['label']= \"You could smell the air from burnt bodies.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22smelled%22%5D+%5B%22burning%22%5D+%5B%22bodies%22%5D+%5B%22nonstop%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22we%22%5D+%5B%22looked%22%5D+%5B%22at%22%5D+%5B%22the%22%5D+%5B%22tall%22%5D+%5B%22chimneys%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22there%22%5D+%5B%22was%22%5D+%5B%22smoke%22%5D+%5B%22coming%22%5D+%5B%22out%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We smelled burning bodies nonstop . And we looked at the tall chimneys , and there was smoke coming out . ', 'right': '', 'complete_match': 'We smelled burning bodies nonstop . And we looked at the tall chimneys , and there was smoke coming out . ', 'testimony_id': 'usc_shoah_13524', 'shelfmark': ['USC Shoah Foundation 13524'], 'token_start': 24871, 'token_end': 24892}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \" We smelled burning bodies nonstop. And we looked at the tall chimneys, and there was smoke coming out.\"\n",
    "fragment_5['label']= \" We smelled burning bodies nonstop. And we looked at the tall chimneys, and there was smoke coming out.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"smell\",\"toilet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"smell\"][]{0,10}[lemma=\"toilet\"])|([lemma=\"toilet\"][]{0,10}[lemma=\"smell\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"toilet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22naturally%22%5D+%5B%22everybody%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22use%22%5D+%5B%22that%22%5D+%5B%22toilet%22%5D+%5B%5D+%5B%22very%22%5D+%5B%22har%22%5D+%5B%5D%7B0%2C3%7D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%5D%7B0%2C3%7D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22terrible%22%5D+%5B%22smell%22%5D+%5B%5D+%5B%22terrible%22%5D+%5B%22smell%22%5D+%5B%22because%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22toilet%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'naturally everybody had to use that toilet , very har -- it was -- it was terrible smell , terrible smell because of the toilet ', 'right': '', 'complete_match': 'naturally everybody had to use that toilet , very har -- it was -- it was terrible smell , terrible smell because of the toilet ', 'testimony_id': 'irn509676', 'shelfmark': ['USHMM RG-50.030*0415'], 'token_start': 10173, 'token_end': 10198}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"naturally everybody had to use that toilet, very har -- it was -- it was terrible smell, terrible smell because of the toilet\"\n",
    "fragment_1['label']=\"(..) naturally everybody had to use that toilet, very har -- it was -- it was terrible smell, terrible smell because of the toilet (..).\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22put%22%5D+%5B%22a%22%5D+%5B%22few%22%5D+%5B%22dishes%22%5D+%5B%5D+%5B%22cans%22%5D+%5B%5D+%5B%22This%22%5D+%5B%22was%22%5D+%5B%22the%22%5D+%5B%22toilet%22%5D+%5B%5D+%5B%22The%22%5D+%5B%22terrible%22%5D+%5B%22smell%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They put a few dishes , cans . This was the toilet . The terrible smell . ', 'right': '', 'complete_match': 'They put a few dishes , cans . This was the toilet . The terrible smell . ', 'testimony_id': 'usc_shoah_27770', 'shelfmark': ['USC Shoah Foundation 27770'], 'token_start': 9154, 'token_end': 9171}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"They put a few dishes, cans. This was the toilet. The terrible smell.\"\n",
    "fragment_2['label']=\"They put a few dishes, cans. This was the toilet. The terrible smell.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22room%22%5D+%5B%22was%22%5D+%5B%22half%22%5D+%5B%22the%22%5D+%5B%22size%22%5D+%5B%22of%22%5D+%5B%22this%22%5D+%5B%22room%22%5D+%5B%22with%22%5D+%5B%22a%22%5D+%5B%22bucket%22%5D+%5B%22where%22%5D+%5B%22everybody%22%5D+%5B%22was%22%5D+%5B%22going%22%5D+%5B%22to%22%5D+%5B%22toilet%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22Smelling%22%5D+%5B%5D%7B0%2C3%7D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%22was%22%5D+%5B%22unbelievable%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The room was half the size of this room with a bucket where everybody was going to toilet , you know . Smelling -- the smell was unbelievable . ', 'right': '', 'complete_match': 'The room was half the size of this room with a bucket where everybody was going to toilet , you know . Smelling -- the smell was unbelievable . ', 'testimony_id': 'usc_shoah_5275', 'shelfmark': ['USC Shoah Foundation 5275'], 'token_start': 10483, 'token_end': 10512}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"The room was half the size of this room with a bucket where everybody was going to toilet, you know. Smelling-- the smell was unbelievable.\"\n",
    "fragment_3['label']=\"(..) everybody was going to toilet, you know. Smelling-- the smell was unbelievable.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22go%22%5D+%5B%5D%7B0%2C3%7D+%5B%22when%22%5D+%5B%22you%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22do%22%5D+%5B%22your%22%5D+%5B%5D%7B0%2C3%7D+%5B%22your%22%5D+%5B%22shit%22%5D+%5B%22like%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22toilet%22%5D+%5B%5D+%5B%22There%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22corner%22%5D+%5B%22there%22%5D+%5B%5D+%5B%22It%22%5D+%5B%22was%22%5D+%5B%22smelling%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You had to go -- when you had to do your -- your shit like on the toilet . There was a corner there . It was smelling . ', 'right': '', 'complete_match': 'You had to go -- when you had to do your -- your shit like on the toilet . There was a corner there . It was smelling . ', 'testimony_id': 'usc_shoah_628', 'shelfmark': ['USC Shoah Foundation 628'], 'token_start': 34834, 'token_end': 34863}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"You had to go-- when you had to do your-- your shit like on the toilet. There was a corner there. It was smelling.\"\n",
    "fragment_4['label']= \"(..) your shit like on the toilet. There was a corner there. It was smelling.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22In%22%5D+%5B%22one%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22huts%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22far%22%5D+%5B%22corner%22%5D+%5B%5D+%5B%22some%22%5D+%5B%22sort%22%5D+%5B%22of%22%5D+%5B%22toilet%22%5D+%5B%22which%22%5D+%5B%22smelled%22%5D+%5B%22bloody%22%5D+%5B%22horrible%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'In one of the huts in the far corner , some sort of toilet which smelled bloody horrible . ', 'right': '', 'complete_match': 'In one of the huts in the far corner , some sort of toilet which smelled bloody horrible . ', 'testimony_id': 'usc_shoah_13483', 'shelfmark': ['USC Shoah Foundation 13483'], 'token_start': 13390, 'token_end': 13409}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"In one of the huts in the far corner, some sort of toilet which smelled bloody horrible.\"\n",
    "fragment_5['label']= \"In one of the huts in the far corner, some sort of toilet which smelled bloody horrible.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"smell\",\"urine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"smell\"][]{0,10}[lemma=\"urine\"])|([lemma=\"urine\"][]{0,10}[lemma=\"smell\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"urine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22urine%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22people%22%5D+%5B%22crowded%22%5D+%5B%22in%22%5D+%5B%22pretty%22%5D+%5B%22nearly%22%5D+%5B%22standing%22%5D+%5B%22position%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22all%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And the smell , and and the urine , and people crowded in pretty nearly standing position , and all . ', 'right': '', 'complete_match': 'And the smell , and and the urine , and people crowded in pretty nearly standing position , and all . ', 'testimony_id': 'usc_shoah_7744', 'shelfmark': ['USC Shoah Foundation 7744'], 'token_start': 4992, 'token_end': 5013}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And the smell, and and the urine, and people crowded in pretty nearly standing position, and all.\"\n",
    "fragment_1['label']=\"And the smell, and and the urine, and people crowded in pretty nearly standing position, and all.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Because%22%5D+%5B%22the%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22sanitary%22%5D+%5B%22toilets%22%5D+%5B%22was%22%5D+%5B%22with%22%5D+%5B%22urine%22%5D+%5B%5D+%5B%22everything%22%5D+%5B%22was%22%5D+%5B%22running%22%5D+%5B%22around%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22smelling%22%5D+%5B%22all%22%5D+%5B%22around%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Because the , the sanitary toilets was with urine , everything was running around , and it was smelling all around . ', 'right': '', 'complete_match': 'Because the , the sanitary toilets was with urine , everything was running around , and it was smelling all around . ', 'testimony_id': 'HVT-157', 'shelfmark': ['Fortunoff Archive HVT-157'], 'token_start': 10461, 'token_end': 10483}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"Because the, the sanitary toilets was with urine, everything was running around, and it was smelling all around.\"\n",
    "fragment_2['label']=\"Because the, the sanitary toilets was with urine, everything was running around, and it was smelling all around.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22you%22%5D+%5B%22ended%22%5D+%5B%22up%22%5D+%5B%22getting%22%5D+%5B%22some%22%5D+%5B%22sprinkles%22%5D+%5B%22of%22%5D+%5B%22that%22%5D+%5B%22urine%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'you ended up getting some sprinkles of that urine ', 'right': '', 'complete_match': 'you ended up getting some sprinkles of that urine ', 'testimony_id': 'irn504453', 'shelfmark': ['USHMM RG-50.030*0021'], 'token_start': 11873, 'token_end': 11882}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"you ended up getting some sprinkles of that urine\"\n",
    "fragment_3['label']=\"(..)you ended up getting some sprinkles of that urine (..) and that urine had a smell and it impregnated what our clothes (..) \"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22that%22%5D+%5B%22trip%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22wagons%22%5D+%5B%5D+%5B%22again%22%5D+%5B%5D%7B0%2C3%7D+%5B%22urine%22%5D+%5B%5D+%5B%22feces%22%5D+%5B%5D+%5B%22smell%22%5D+%5B%5D+%5B%22odor%22%5D+%5B%5D+%5B%22sickness%22%5D+%5B%5D+%5B%22vomiting%22%5D+%5B%5D+%5B%22death%22%5D+%5B%22experienced%22%5D+%5B%22for%22%5D+%5B%22about%22%5D+%5B%22a%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22a%22%5D+%5B%22half%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And that trip in the wagons , again -- urine , feces , smell , odor , sickness , vomiting , death experienced for about a day and a half , ', 'right': '', 'complete_match': 'And that trip in the wagons , again -- urine , feces , smell , odor , sickness , vomiting , death experienced for about a day and a half , ', 'testimony_id': 'usc_shoah_19895', 'shelfmark': ['USC Shoah Foundation 19895'], 'token_start': 17844, 'token_end': 17875}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"And that trip in the wagons, again-- urine, feces, smell, odor, sickness, vomiting, death experienced for about a day and a half,\"\n",
    "fragment_4['label']= \"(..) urine, feces, smell, odor, sickness, vomiting, death experienced for about a day and a half (..)\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22these%22%5D+%5B%22were%22%5D+%5B%22all%22%5D+%5B%22pretty%22%5D+%5B%22modern%22%5D+%5B%22barrack%22%5D+%5B%22buildings%22%5D+%5B%5D+%5B%22reeked%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22odor%22%5D+%5B%22of%22%5D+%5B%22urine%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'these were all pretty modern barrack buildings , reeked of the odor of urine ', 'right': '', 'complete_match': 'these were all pretty modern barrack buildings , reeked of the odor of urine ', 'testimony_id': 'irn511053', 'shelfmark': ['USHMM RG-50.470*0008'], 'token_start': 1041, 'token_end': 1055}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"these were all pretty modern barrack buildings, reeked of the odor of urine\"\n",
    "fragment_5['label']= \"(..)these were all pretty modern barrack buildings, reeked of the odor of urine (..).\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"smoke\",\"smell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"smoke\"][]{0,15}[lemma=\"smell\"])|([lemma=\"smell\"][]{0,15}[lemma=\"smoke\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=15)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"smoke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22again%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22smelled%22%5D+%5B%22the%22%5D+%5B%22smoke%22%5D+%5B%22of%22%5D+%5B%22burning%22%5D+%5B%22flesh%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And again , we smelled the smoke of burning flesh day and night . ', 'right': '', 'complete_match': 'And again , we smelled the smoke of burning flesh day and night . ', 'testimony_id': 'HVT-61', 'shelfmark': ['Fortunoff Archive HVT-61'], 'token_start': 6518, 'token_end': 6532}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And again, we smelled the smoke of burning flesh day and night.\"\n",
    "fragment_1['label']=\"And again, we smelled the smoke of burning flesh day and night.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22could%22%5D+%5B%22see%22%5D+%5B%22the%22%5D+%5B%22chimneys%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22could%22%5D+%5B%22smell%22%5D+%5B%22the%22%5D+%5B%22smoke%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22knew%22%5D+%5B%22the%22%5D+%5B%22people%22%5D+%5B%22that%22%5D+%5B%22were%22%5D+%5B%22taken%22%5D+%5B%22over%22%5D+%5B%22there%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We could see the chimneys . We could smell the smoke . We knew the people that were taken over there . ', 'right': '', 'complete_match': 'We could see the chimneys . We could smell the smoke . We knew the people that were taken over there . ', 'testimony_id': 'irn504818', 'shelfmark': ['USHMM RG-50.030*0324'], 'token_start': 5805, 'token_end': 5827}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"We could see the chimneys. We could smell the smoke. We knew the people that were taken over there. \"\n",
    "fragment_2['label']=\"We could see the chimneys. We could smell the smoke. We knew the people that were taken over there. \"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22you%22%5D+%5B%22could%22%5D+%5B%22see%22%5D+%5B%22spitting%22%5D+%5B%22fire%22%5D+%5B%22from%22%5D+%5B%22the%22%5D+%5B%22chimneys%22%5D+%5B%5D+%5B%22real%22%5D+%5B%22tall%22%5D+%5B%22chimneys%22%5D+%5B%5D+%5B%22heavy%22%5D+%5B%22smoke%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22smell%22%5D+%5B%22was%22%5D+%5B%22awful%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'you could see spitting fire from the chimneys , real tall chimneys , heavy smoke , and the smell was awful . ', 'right': '', 'complete_match': 'you could see spitting fire from the chimneys , real tall chimneys , heavy smoke , and the smell was awful . ', 'testimony_id': 'irn506634', 'shelfmark': ['USHMM RG-50.106*0122'], 'token_start': 6600, 'token_end': 6622}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"you could see spitting fire from the chimneys, real tall chimneys, heavy smoke, and the smell was awful.\"\n",
    "fragment_3['label']=\"(..)you could see spitting fire from the chimneys, real tall chimneys, heavy smoke, and the smell was awful.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22can%22%5D+%5B%22see%22%5D+%5B%22the%22%5D+%5B%22smoke%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22can%22%5D+%5B%22see%22%5D+%5B%22this%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22can%22%5D+%5B%22smell%22%5D+%5B%22this%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22odor%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We can see the smoke , you know , we can see this , you can smell this , you know , odor , ', 'right': '', 'complete_match': 'We can see the smoke , you know , we can see this , you can smell this , you know , odor , ', 'testimony_id': 'irn509676', 'shelfmark': ['USHMM RG-50.030*0415'], 'token_start': 13496, 'token_end': 13520}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"We can see the smoke, you know, we can see this, you can smell this, you know, odor, \"\n",
    "fragment_4['label']= \"We can see the smoke, you know, we can see this, you can smell this, you know, odor (..).\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22saw%22%5D+%5B%22the%22%5D+%5B%22smoke%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22smelled%22%5D+%5B%22the%22%5D+%5B%22smoke%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We saw the smoke . We smelled the smoke . ', 'right': '', 'complete_match': 'We saw the smoke . We smelled the smoke . ', 'testimony_id': 'usc_shoah_323', 'shelfmark': ['USC Shoah Foundation 323'], 'token_start': 12112, 'token_end': 12122}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"We saw the smoke. We smelled the smoke.\"\n",
    "fragment_5['label']= \"We saw the smoke. We smelled the smoke.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
