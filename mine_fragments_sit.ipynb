{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"hope\"\n",
    "delete_main_node(main_node)\n",
    "add_main_node(main_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '[lemma=\"hope\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = topic_concordancer.main(query,window=15,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=16\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No hope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"hope\",\"stop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"hope\"][]{0,25}[lemma=\"stop\"])|([lemma=\"stop\"][]{0,25}[lemma=\"hope\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"no hope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22do%22%5D+%5B%5D+%5B%22hope%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22give%22%5D+%5B%22up%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22yet%22%5D+%5B%22you%22%5D+%5B%22think%22%5D+%5B%22of%22%5D+%5B%22tomorrow%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"You do n't hope , you give up , and yet you think of tomorrow . \", 'right': '', 'complete_match': \"You do n't hope , you give up , and yet you think of tomorrow . \", 'testimony_id': 'irn505577', 'shelfmark': ['USHMM RG-50.042*0024'], 'token_start': 12845, 'token_end': 12861}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"You don't hope, you give up, and yet you think of tomorrow.\"\n",
    "fragment_1['label']=\"You don't hope, you give up, and yet you think of tomorrow.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22In%22%5D+%5B%22the%22%5D+%5B%22meantime%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22do%22%5D+%5B%5D+%5B%22know%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22had%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'In the meantime , I do n’t know , we had ', 'right': '', 'complete_match': 'In the meantime , I do n’t know , we had ', 'testimony_id': 'irn509676', 'shelfmark': ['USHMM RG-50.030*0415'], 'token_start': 16812, 'token_end': 16823}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"In the meantime, I don’t know, we had\"\n",
    "fragment_2['label']=\"In the meantime, I don’t know, we had -- not some hope.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22hope%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22had%22%5D+%5B%22lived%22%5D+%5B%22by%22%5D+%5B%22hope%22%5D+%5B%22so%22%5D+%5B%22long%22%5D+%5B%22that%22%5D+%5B%22we%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22even%22%5D+%5B%22hope%22%5D+%5B%22anymore%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'hope , we had lived by hope so long that we did n’t even hope anymore . ', 'right': '', 'complete_match': 'hope , we had lived by hope so long that we did n’t even hope anymore . ', 'testimony_id': 'irn510468', 'shelfmark': ['USHMM RG-50.322*0014'], 'token_start': 59957, 'token_end': 59974}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"hope, we had lived by hope so long that we didn’t even hope anymore.\"\n",
    "fragment_3['label']=\"ur hope, we had lived by hope so long that we didn’t even hope anymore.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22There%22%5D+%5B%5D+%5B%22not%22%5D+%5B%22much%22%5D+%5B%22hope%22%5D+%5B%22left%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"There 's not much hope left . \", 'right': '', 'complete_match': \"There 's not much hope left . \", 'testimony_id': 'usc_shoah_17330', 'shelfmark': ['USC 17330'], 'token_start': 15990, 'token_end': 15997}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"There's not much hope left.\"\n",
    "fragment_4['label']= \"There's not much hope left.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22we%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22hope%22%5D+%5B%22too%22%5D+%5B%22much%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And we did n't hope too much . \", 'right': '', 'complete_match': \"And we did n't hope too much . \", 'testimony_id': 'usc_shoah_39', 'shelfmark': ['USC 39'], 'token_start': 4789, 'token_end': 4797}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"And we didn't hope too much.\"\n",
    "fragment_5['label']= \"And we didn't hope too much.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  see each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '([lemma=\"hope\"] []{0,2} [lemma=\"see\"|\"meet\"])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"hope\"][]{0,50}[lemma=\"stop\"])|([lemma=\"stop\"][]{0,50}[lemma=\"hope\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"to see\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22said%22%5D+%5B%22our%22%5D+%5B%5D%7B0%2C3%7D+%5B%22and%22%5D+%5B%22hoped%22%5D+%5B%22to%22%5D+%5B%22see%22%5D+%5B%22them%22%5D+%5B%22again%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We said our good-byes and hoped to see them again . ', 'right': '', 'complete_match': 'We said our good-byes and hoped to see them again . ', 'testimony_id': 'irn510474', 'shelfmark': ['USHMM RG-50.322*0020'], 'token_start': 26520, 'token_end': 26531}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"We said our good-byes and hoped to see them again.\"\n",
    "fragment_1['label']=\"We said our good-byes and hoped to see them again.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Anyway%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22left%22%5D+%5B%22that%22%5D+%5B%22bed%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22ran%22%5D+%5B%22out%22%5D+%5B%5D+%5B%22hoping%22%5D+%5B%22I%22%5D+%5B%22might%22%5D+%5B%22see%22%5D+%5B%22my%22%5D+%5B%22mother%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Anyway , I left that bed , and I ran out , hoping I might see my mother . ', 'right': '', 'complete_match': 'Anyway , I left that bed , and I ran out , hoping I might see my mother . ', 'testimony_id': 'irn510705', 'shelfmark': ['USHMM RG-50.156*0051'], 'token_start': 4166, 'token_end': 4185}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"Anyway, I left that bed, and I ran out, hoping I might see my mother.\"\n",
    "fragment_2['label']=\"Anyway, I left that bed, and I ran out, hoping I might see my mother.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22hope%22%5D+%5B%22of%22%5D+%5B%22seeing%22%5D+%5B%22my%22%5D+%5B%22family%22%5D+%5B%22again%22%5D+%5B%5D+%5B%22that%22%5D+%5B%22they%22%5D+%5B%22would%22%5D+%5B%22be%22%5D+%5B%22still%22%5D+%5B%22alive%22%5D+%5B%5D+%5B%22somehow%22%5D+%5B%22they%22%5D+%5B%22would%22%5D+%5B%22have%22%5D+%5B%22escaped%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The hope of seeing my family again , that they would be still alive , somehow they would have escaped . ', 'right': '', 'complete_match': 'The hope of seeing my family again , that they would be still alive , somehow they would have escaped . ', 'testimony_id': 'irn505558', 'shelfmark': ['USHMM RG-50.042*0004'], 'token_start': 16003, 'token_end': 16024}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"The hope of seeing my family again, that they would be still alive, somehow they would have escaped.\"\n",
    "fragment_3['label']=\"The hope of seeing my family again, that they would be still alive, somehow they would have escaped.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%22always%22%5D+%5B%22hoping%22%5D+%5B%22to%22%5D+%5B%22see%22%5D+%5B%22my%22%5D+%5B%22family%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I was always hoping to see my family . ', 'right': '', 'complete_match': 'I was always hoping to see my family . ', 'testimony_id': 'usc_shoah_5496', 'shelfmark': ['USC 5496'], 'token_start': 9198, 'token_end': 9207}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"I was always hoping to see my family.\"\n",
    "fragment_4['label']= \"I was always hoping to see my family.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22That%22%5D+%5B%22we%22%5D+%5B%22hope%22%5D+%5B%22we%22%5D+%5B%22see%22%5D+%5B%22each%22%5D+%5B%22other%22%5D+%5B%22again%22%5D+%5B%5D+%5B%22It%22%5D+%5B%22was%22%5D+%5B%22not%22%5D+%5B%22so%22%5D+%5B%22easy%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'That we hope we see each other again . It was not so easy . ', 'right': '', 'complete_match': 'That we hope we see each other again . It was not so easy . ', 'testimony_id': 'usc_shoah_23540', 'shelfmark': ['USC 23540'], 'token_start': 9939, 'token_end': 9954}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"That we hope we see each other again. It was not so easy.\"\n",
    "fragment_5['label']= \"That we hope we see each other again. It was not so easy.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  they are alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"they are alive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22just%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22Eli%22%5D+%5B%22would%22%5D+%5B%22be%22%5D+%5B%22alive%22%5D+%5B%22so%22%5D+%5B%22I%22%5D+%5B%22could%22%5D+%5B%22bring%22%5D+%5B%22him%22%5D+%5B%22here%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I just hoped that Eli would be alive so I could bring him here . ', 'right': '', 'complete_match': 'I just hoped that Eli would be alive so I could bring him here . ', 'testimony_id': 'irn504802', 'shelfmark': ['USHMM RG-50.030*0307'], 'token_start': 8720, 'token_end': 8735}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"I just hoped that Eli would be alive so I could bring him here.\"\n",
    "fragment_1['label']=\"I just hoped that Eli would be alive so I could bring him here.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22my%22%5D+%5B%22oldest%22%5D+%5B%22brother%22%5D+%5B%22remained%22%5D+%5B%22alive%22%5D+%5B%5D+%5B%22but%22%5D+%5B%22he%22%5D+%5B%22did%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"I hoped that my oldest brother remained alive , but he did n't \", 'right': '', 'complete_match': \"I hoped that my oldest brother remained alive , but he did n't \", 'testimony_id': 'HVT-18', 'shelfmark': ['Fortunoff HVT-18'], 'token_start': 13169, 'token_end': 13182}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"I hoped that my oldest brother remained alive, but he didn't\"\n",
    "fragment_2['label']=\" I hoped that my oldest brother remained alive, but he didn't\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Somebody%22%5D+%5B%22told%22%5D+%5B%22me%22%5D+%5B%22that%22%5D+%5B%22it%22%5D+%5B%5D+%5B%22not%22%5D+%5B%22time%22%5D+%5B%22to%22%5D+%5B%22tell%22%5D+%5B%22the%22%5D+%5B%22particulars%22%5D+%5B%5D+%5B%22but%22%5D+%5B%22I%22%5D+%5B%22still%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22they%22%5D+%5B%22are%22%5D+%5B%22alive%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"Somebody told me that it 's not time to tell the particulars , but I still hoped that they are alive . \", 'right': '', 'complete_match': \"Somebody told me that it 's not time to tell the particulars , but I still hoped that they are alive . \", 'testimony_id': 'irn504724', 'shelfmark': ['USHMM RG-50.030*0235'], 'token_start': 888, 'token_end': 910}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"Somebody told me that it's not time to tell the particulars, but I still hoped that they are alive.\"\n",
    "fragment_3['label']=\"Somebody told me that it's not time to tell the particulars, but I still hoped that they are alive.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22they%22%5D+%5B%22return%22%5D+%5B%22after%22%5D+%5B%22the%22%5D+%5B%22war%22%5D+%5B%22to%22%5D+%5B%22Lithuania%22%5D+%5B%5D+%5B%22to%22%5D+%5B%22Wilna%22%5D+%5B%22because%22%5D+%5B%22I%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22somebody%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22family%22%5D+%5B%22will%22%5D+%5B%22stay%22%5D+%5B%22alive%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And they return after the war to Lithuania , to Wilna because I hoped that somebody of the family will stay alive ', 'right': '', 'complete_match': 'And they return after the war to Lithuania , to Wilna because I hoped that somebody of the family will stay alive ', 'testimony_id': 'irn507289', 'shelfmark': ['USHMM RG-50.030*0400'], 'token_start': 30847, 'token_end': 30869}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"And they return after the war to Lithuania, to Wilna because I hoped that somebody of the family will stay alive\"\n",
    "fragment_4['label']= \"(..) I hoped that somebody of the family will stay alive (..)\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22I%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22my%22%5D+%5B%22son%22%5D+%5B%22is%22%5D+%5B%22alive%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And I hoped that my son is alive . ', 'right': '', 'complete_match': 'And I hoped that my son is alive . ', 'testimony_id': 'usc_shoah_11641', 'shelfmark': ['USC 11641'], 'token_start': 16062, 'token_end': 16071}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"And I hoped that my son is alive.\"\n",
    "fragment_5['label']= \"And I hoped that my son is alive.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  come back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"come back\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22well%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22always%22%5D+%5B%22hoping%22%5D+%5B%22that%22%5D+%5B%22he%22%5D+%5B%5D+%5B%22coming%22%5D+%5B%22back%22%5D+%5B%5D+%5B%22because%22%5D+%5B%22that%22%5D+%5B%5D+%5B%22what%22%5D+%5B%22my%22%5D+%5B%22mother%22%5D+%5B%22said%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"well , we were always hoping that he 's coming back , because that 's what my mother said \", 'right': '', 'complete_match': \"well , we were always hoping that he 's coming back , because that 's what my mother said \", 'testimony_id': 'usc_shoah_1160', 'shelfmark': ['USC 1160'], 'token_start': 3532, 'token_end': 3551}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"well, we were always hoping that he's coming back, because that's what my mother said\"\n",
    "fragment_3['label']=\"(..) well, we were always hoping that he's coming back, because that's what my mother said (..)\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%22hoping%22%5D+%5B%22my%22%5D+%5B%22mother%22%5D+%5B%22maybe%22%5D+%5B%22come%22%5D+%5B%22back%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I was hoping my mother maybe come back . ', 'right': '', 'complete_match': 'I was hoping my mother maybe come back . ', 'testimony_id': 'usc_shoah_12810', 'shelfmark': ['USC 12810'], 'token_start': 16646, 'token_end': 16655}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \" I was hoping my mother maybe come back.\"\n",
    "fragment_4['label']= \" I was hoping my mother maybe come back.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22my%22%5D+%5B%22mother%22%5D+%5B%22was%22%5D+%5B%22always%22%5D+%5B%22fighting%22%5D+%5B%22to%22%5D+%5B%22survive%22%5D+%5B%22and%22%5D+%5B%22hoping%22%5D+%5B%22that%22%5D+%5B%5D+%5B%22by%22%5D+%5B%22some%22%5D+%5B%22miracle%22%5D+%5B%5D+%5B%22she%22%5D+%5B%22will%22%5D+%5B%22come%22%5D+%5B%22back%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'my mother was always fighting to survive and hoping that , by some miracle , she will come back . ', 'right': '', 'complete_match': 'my mother was always fighting to survive and hoping that , by some miracle , she will come back . ', 'testimony_id': 'usc_shoah_15962', 'shelfmark': ['USC 15962'], 'token_start': 4142, 'token_end': 4162}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \" my mother was always fighting to survive and hoping that, by some miracle, she will come back.\"\n",
    "fragment_5['label']= \"(..) my mother was always fighting to survive and hoping that, by some miracle, she will come back.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"pray\",\"hope\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"pray\"][]{0,25}[lemma=\"hope\"])|([lemma=\"hope\"][]{0,25}[lemma=\"pray\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"pray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22That%22%5D+%5B%5D+%5B%22what%22%5D+%5B%22I%22%5D+%5B%22prayed%22%5D+%5B%22for%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22so%22%5D+%5B%22I%22%5D+%5B%22never%22%5D+%5B%22lost%22%5D+%5B%22hope%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'That ’s what I prayed for . And so I never lost hope . ', 'right': '', 'complete_match': 'That ’s what I prayed for . And so I never lost hope . ', 'testimony_id': 'irn35973', 'shelfmark': ['USHMM RG-50.106*0173'], 'token_start': 26657, 'token_end': 26671}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"That’s what I prayed for. And so I never lost hope.\"\n",
    "fragment_1['label']=\"That’s what I prayed for. And so I never lost hope.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22my%22%5D+%5B%22father%22%5D+%5B%22still%22%5D+%5B%22prayed%22%5D+%5B%22and%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22God%22%5D+%5B%22will%22%5D+%5B%22help%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'my father still prayed and hoped that God will help . ', 'right': '', 'complete_match': 'my father still prayed and hoped that God will help . ', 'testimony_id': 'HVT-125', 'shelfmark': ['Fortunoff HVT-125'], 'token_start': 6647, 'token_end': 6658}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"my father still prayed and hoped that God will help.\"\n",
    "fragment_2['label']=\"(..) my father still prayed and hoped that God will help.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22But%22%5D+%5B%22we%22%5D+%5B%22prayed%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22they%22%5D+%5B%22would%22%5D+%5B%22show%22%5D+%5B%22up%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'But we prayed , and we hoped that they would show up . ', 'right': '', 'complete_match': 'But we prayed , and we hoped that they would show up . ', 'testimony_id': 'HVT-131', 'shelfmark': ['Fortunoff HVT-131'], 'token_start': 4003, 'token_end': 4016}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"But we prayed, and we hoped that they would show up.\"\n",
    "fragment_3['label']=\"But we prayed, and we hoped that they would show up.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Everybody%22%5D+%5B%22prayed%22%5D+%5B%22without%22%5D+%5B%22hope%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Everybody prayed without hope . ', 'right': '', 'complete_match': 'Everybody prayed without hope . ', 'testimony_id': 'irn518937', 'shelfmark': ['USHMM RG-50.030*0515'], 'token_start': 14232, 'token_end': 14237}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"Everybody prayed without hope.\"\n",
    "fragment_4['label']= \"Everybody prayed without hope.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22prayed%22%5D+%5B%22to%22%5D+%5B%22God%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22hope%22%5D+%5B%22I%22%5D+%5B%22%27m%22%5D+%5B%22not%22%5D+%5B%22going%22%5D+%5B%22to%22%5D+%5B%22be%22%5D+%5B%22next%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"I prayed to God , I hope I 'm not going to be next , \", 'right': '', 'complete_match': \"I prayed to God , I hope I 'm not going to be next , \", 'testimony_id': 'usc_shoah_15193', 'shelfmark': ['USC 15193'], 'token_start': 7696, 'token_end': 7711}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \" I prayed to God, I hope I'm not going to be next,\"\n",
    "fragment_5['label']= \" I prayed to God, I hope I'm not going to be next (..)\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Cry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"cry\",\"hope\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"cry\"][]{0,10}[lemma=\"hope\"])|([lemma=\"hope\"][]{0,10}[lemma=\"cry\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=10)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"cry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22she%22%5D+%5B%22had%22%5D+%5B%22tears%22%5D+%5B%5D+%5B%22crying%22%5D+%5B%5D+%5B%22hoping%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And she had tears , crying , hoping . ', 'right': '', 'complete_match': 'And she had tears , crying , hoping . ', 'testimony_id': 'usc_shoah_7455', 'shelfmark': ['USC 7455'], 'token_start': 21056, 'token_end': 21065}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And she had tears, crying, hoping.\"\n",
    "fragment_1['label']=\"And she had tears, crying, hoping.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22said%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22hope%22%5D+%5B%22mother%22%5D+%5B%22is%22%5D+%5B%22not%22%5D+%5B%22cold%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22were%22%5D+%5B%22both%22%5D+%5B%22crying%22%5D+%5B%22and%22%5D+%5B%22saying%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I said , I hope mother is not cold . We were both crying and saying , ', 'right': '', 'complete_match': 'I said , I hope mother is not cold . We were both crying and saying , ', 'testimony_id': 'usc_shoah_1354', 'shelfmark': ['USC 1354'], 'token_start': 7812, 'token_end': 7829}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \" I said, I hope mother is not cold. We were both crying and saying,\"\n",
    "fragment_2['label']=\"(..) I hope mother is not cold. We were both crying (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22she%22%5D+%5B%22started%22%5D+%5B%22to%22%5D+%5B%22cry%22%5D+%5B%5D+%5B%22She%22%5D+%5B%22said%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22am%22%5D+%5B%22young%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22hope%22%5D+%5B%22my%22%5D+%5B%5D+%5B%22my%22%5D+%5B%22husband%22%5D+%5B%22will%22%5D+%5B%22make%22%5D+%5B%22it%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And she started to cry . She said , I am young . I hope my , my husband will make it . ', 'right': '', 'complete_match': 'And she started to cry . She said , I am young . I hope my , my husband will make it . ', 'testimony_id': 'usc_shoah_747', 'shelfmark': ['USC 747'], 'token_start': 15273, 'token_end': 15296}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And she started to cry. She said, I am young. I hope my, my husband will make it.\"\n",
    "fragment_3['label']=\"And she started to cry. She said, I am young. I hope my, my husband will make it.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22she%22%5D+%5B%22had%22%5D+%5B%22tears%22%5D+%5B%5D+%5B%22crying%22%5D+%5B%5D+%5B%22hoping%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And she had tears , crying , hoping . ', 'right': '', 'complete_match': 'And she had tears , crying , hoping . ', 'testimony_id': 'usc_shoah_7455', 'shelfmark': ['USC 7455'], 'token_start': 21056, 'token_end': 21065}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"And she had tears, crying, hoping.\"\n",
    "fragment_4['label']= \"And she had tears, crying, hoping.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22crying%22%5D+%5B%5D+%5B%22putting%22%5D+%5B%22myself%22%5D+%5B%22to%22%5D+%5B%22sleep%22%5D+%5B%22with%22%5D+%5B%22the%22%5D+%5B%22hope%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22always%22%5D+%5B%22saying%22%5D+%5B%5D+%5B%22maybe%22%5D+%5B%22my%22%5D+%5B%22mother%22%5D+%5B%5D%7B0%2C3%7D+%5B%22maybe%22%5D+%5B%22she%22%5D+%5B%5D+%5B%22sick%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And I was crying , putting myself to sleep with the hope -- I was always saying , maybe my mother -- maybe she 's sick . \", 'right': '', 'complete_match': \"And I was crying , putting myself to sleep with the hope -- I was always saying , maybe my mother -- maybe she 's sick . \", 'testimony_id': 'usc_shoah_19982', 'shelfmark': ['USC 19982'], 'token_start': 10782, 'token_end': 10809}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \" And I was crying, putting myself to sleep with the hope-- I was always saying, maybe my mother-- maybe she's sick.\"\n",
    "fragment_5['label']= \"I was crying, putting myself to sleep with the hope-- I was always saying, maybe my mother-- maybe she's sick.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  die "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"die\",\"hope\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"die\"][]{0,25}[lemma=\"hope\"])|([lemma=\"hope\"][]{0,25}[lemma=\"die\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"to die\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22screamed%22%5D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22said%22%5D+%5B%22I%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22care%22%5D+%5B%22if%22%5D+%5B%22I%22%5D+%5B%22died%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22hope%22%5D+%5B%22we%22%5D+%5B%22all%22%5D+%5B%22die%22%5D+%5B%22today%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I screamed and I said I did n’t care if I died , and I hope we all die today , ', 'right': '', 'complete_match': 'I screamed and I said I did n’t care if I died , and I hope we all die today , ', 'testimony_id': 'irn39792', 'shelfmark': ['USHMM RG-50.030*0543'], 'token_start': 11135, 'token_end': 11156}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"I screamed and I said I didn’t care if I died, and I hope we all die today, \"\n",
    "fragment_1['label']=\"(..) I screamed and I said I didn’t care if I died, and I hope we all die today (..)\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22that%22%5D+%5B%22hope%22%5D+%5B%22that%22%5D+%5B%22somebody%22%5D+%5B%22will%22%5D+%5B%22come%22%5D+%5B%22and%22%5D+%5B%22kill%22%5D+%5B%22us%22%5D+%5B%5D+%5B%22maybe%22%5D+%5B%22that%22%5D+%5B%22kept%22%5D+%5B%22me%22%5D+%5B%22alive%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'that hope that somebody will come and kill us , maybe that kept me alive ', 'right': '', 'complete_match': 'that hope that somebody will come and kill us , maybe that kept me alive ', 'testimony_id': 'irn506715', 'shelfmark': ['USHMM RG-50.549.02*0058'], 'token_start': 1247, 'token_end': 1262}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"that hope that somebody will come and kill us, maybe that kept me alive\"\n",
    "fragment_2['label']=\"(..)that hope that somebody will come and kill us, maybe that kept me alive (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22I%22%5D+%5B%22just%22%5D+%5B%22hope%22%5D+%5B%22that%22%5D+%5B%22she%22%5D+%5B%22died%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22way%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And I just hope that she died on the way . ', 'right': '', 'complete_match': 'And I just hope that she died on the way . ', 'testimony_id': 'usc_shoah_21013', 'shelfmark': ['USC 21013'], 'token_start': 10479, 'token_end': 10490}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And I just hope that she died on the way.\"\n",
    "fragment_3['label']=\"And I just hope that she died on the way.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22hope%22%5D+%5B%22you%22%5D+%5B%22die%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22always%22%5D+%5B%22hoping%22%5D+%5B%22I%22%5D+%5B%22%27d%22%5D+%5B%22die%22%5D+%5B%22fast%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"You hope you die . I was always hoping I 'd die fast , you know . \", 'right': '', 'complete_match': \"You hope you die . I was always hoping I 'd die fast , you know . \", 'testimony_id': 'usc_shoah_543', 'shelfmark': ['USC 543'], 'token_start': 13848, 'token_end': 13865}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \" You hope you die. I was always hoping I'd die fast, you know.\"\n",
    "fragment_4['label']= \" You hope you die. I was always hoping I'd die fast, you know.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22hope%22%5D+%5B%22that%22%5D+%5B%22my%22%5D+%5B%22grandmother%22%5D+%5B%22died%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I hope that my grandmother died ', 'right': '', 'complete_match': 'I hope that my grandmother died ', 'testimony_id': 'usc_shoah_7094', 'shelfmark': ['USC 7094'], 'token_start': 29255, 'token_end': 29261}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"I hope that my grandmother died\"\n",
    "fragment_5['label']= \"I hope that my grandmother died (..) I hope she died on the train.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  Hope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"hope\",\"together\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"hope\"][]{0,50}[lemma=\"together\"])|([lemma=\"together\"][]{0,50}[lemma=\"hope\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"stay together\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22we%22%5D+%5B%22hoped%22%5D+%5B%22that%22%5D+%5B%22we%22%5D+%5B%22could%22%5D+%5B%22stay%22%5D+%5B%22together%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And we hoped that we could stay together . ', 'right': '', 'complete_match': 'And we hoped that we could stay together . ', 'testimony_id': 'usc_shoah_543', 'shelfmark': ['USC 543'], 'token_start': 9238, 'token_end': 9247}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And we hoped that we could stay together.\"\n",
    "fragment_1['label']=\"And we hoped that we could stay together.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%22just%22%5D+%5B%22hoping%22%5D+%5B%22that%22%5D+%5B%22I%22%5D+%5B%22can%22%5D+%5B%22stay%22%5D+%5B%22together%22%5D+%5B%22with%22%5D+%5B%22my%22%5D+%5B%22mother%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I was just hoping that I can stay together with my mother . ', 'right': '', 'complete_match': 'I was just hoping that I can stay together with my mother . ', 'testimony_id': 'usc_shoah_8775', 'shelfmark': ['USC 8775'], 'token_start': 8874, 'token_end': 8887}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"I was just hoping that I can stay together with my mother.\"\n",
    "fragment_2['label']=\"I was just hoping that I can stay together with my mother.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22to%22%5D+%5B%22put%22%5D+%5B%22her%22%5D+%5B%22arms%22%5D+%5B%22around%22%5D+%5B%22and%22%5D+%5B%22embrace%22%5D+%5B%22us%22%5D+%5B%22all%22%5D+%5B%5D+%5B%22It%22%5D+%5B%5D+%5B%22like%22%5D+%5B%22the%22%5D+%5B%22saying%22%5D+%5B%22Yiddish%22%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%22YIDDISH%22%5D+%5B%5D%7B0%2C3%7D+%5B%5D+%5B%22like%22%5D+%5B%22cuddle%22%5D+%5B%22up%22%5D+%5B%22all%22%5D+%5B%22to%22%5D+%5B%22the%22%5D+%5B%22parents%22%5D+%5B%22and%22%5D+%5B%22just%22%5D+%5B%22hoping%22%5D+%5B%22to%22%5D+%5B%22stay%22%5D+%5B%22together%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"to put her arms around and embrace us all . It 's like the saying Yiddish , [ YIDDISH ] , like cuddle up all to the parents and just hoping to stay together . \", 'right': '', 'complete_match': \"to put her arms around and embrace us all . It 's like the saying Yiddish , [ YIDDISH ] , like cuddle up all to the parents and just hoping to stay together . \", 'testimony_id': 'usc_shoah_10588', 'shelfmark': ['USC 10588'], 'token_start': 22472, 'token_end': 22507}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"to put her arms around and embrace us all. It's like the saying Yiddish, [YIDDISH], like cuddle up all to the parents and just hoping to stay together.\"\n",
    "fragment_3['label']=\"(..)my mother was trying (.. )to put her arms around and embrace us all (..) just hoping to stay together.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22So%22%5D+%5B%22the%22%5D+%5B%22only%22%5D+%5B%22thing%22%5D+%5B%22really%22%5D+%5B%22what%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22hoping%22%5D+%5B%22for%22%5D+%5B%22and%22%5D+%5B%22what%22%5D+%5B%22it%22%5D+%5B%22matters%22%5D+%5B%22that%22%5D+%5B%22the%22%5D+%5B%22families%22%5D+%5B%22just%22%5D+%5B%22to%22%5D+%5B%22remain%22%5D+%5B%22together%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'So the only thing really what we were hoping for and what it matters that the families just to remain together . ', 'right': '', 'complete_match': 'So the only thing really what we were hoping for and what it matters that the families just to remain together . ', 'testimony_id': 'usc_shoah_39', 'shelfmark': ['USC 39'], 'token_start': 3550, 'token_end': 3572}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"So the only thing really what we were hoping for and what it matters that the families just to remain together.\"\n",
    "fragment_4['label']= \"(..)what we were hoping for and what it matters that the families just to remain together.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid node exists cannot be added\n"
     ]
    }
   ],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
