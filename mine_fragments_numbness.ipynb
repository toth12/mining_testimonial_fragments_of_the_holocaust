{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain:** numbness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"numbness\"\n",
    "#delete_main_node(\"numbness\")\n",
    "add_main_node('numbness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '[lemma=\"numb\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = topic_concordancer.main(query,window=50,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = ['kill','numb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"kill\"][]{0,50}[lemma=\"numb\"])|([lemma=\"numb\"][]{0,50}[lemma=\"kill\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = 'kill'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%5D%7B0%2C3%7D+%5B%22PAUSES%22%5D+%5B%22FOR%22%5D+%5B%223%22%5D+%5B%22SECONDS%22%5D+%5B%5D%7B0%2C3%7D+%5B%22Then%22%5D+%5B%22they%22%5D+%5B%22said%22%5D+%5B%5D+%5B%22you%22%5D+%5B%5D+%5B%22out%22%5D+%5B%22of%22%5D+%5B%22luck%22%5D+%5B%22because%22%5D+%5B%22we%22%5D+%5B%5D+%5B%22going%22%5D+%5B%22to%22%5D+%5B%22kill%22%5D+%5B%22you%22%5D+%5B%22all%22%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%22PAUSES%22%5D+%5B%22FOR%22%5D+%5B%224%22%5D+%5B%22SECONDS%22%5D+%5B%5D%7B0%2C3%7D+%5B%22We%22%5D+%5B%5D%7B0%2C3%7D+%5B%22PAUSES%22%5D+%5B%22FOR%22%5D+%5B%224%22%5D+%5B%22SECONDS%22%5D+%5B%5D%7B0%2C3%7D+%5B%22were%22%5D+%5B%22numb%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"men . [ PAUSES FOR 3 SECONDS ] Then they said , you 're out of luck because we 're going to kill you all . [ PAUSES FOR 4 SECONDS ] We [ PAUSES FOR 4 SECONDS ] were numb . \", 'right': '', 'complete_match': \"men . [ PAUSES FOR 3 SECONDS ] Then they said , you 're out of luck because we 're going to kill you all . [ PAUSES FOR 4 SECONDS ] We [ PAUSES FOR 4 SECONDS ] were numb . \", 'testimony_id': 'usc_shoah_27347', 'shelfmark': ['USC 27347'], 'token_start': 10944, 'token_end': 10986}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"[PAUSES FOR 3 SECONDS] Then they said, you're out of luck because we're going to kill you all. [PAUSES FOR 4 SECONDS] We [PAUSES FOR 4 SECONDS] were numb.\"\n",
    "fragment_1['label']=\"Then they said, you're out of luck because we're going to kill you all. We were numb.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22To%22%5D+%5B%22see%22%5D+%5B%22another%22%5D+%5B%5D+%5B%22Jews%22%5D+%5B%22come%22%5D+%5B%22and%22%5D+%5B%22be%22%5D+%5B%22killed%22%5D+%5B%5D+%5B%22another%22%5D+%5B%5D+%5B%22be%22%5D+%5B%22killed%22%5D+%5B%5D+%5B%22That%22%5D+%5B%22was%22%5D+%5B%22not%22%5D+%5B%5D%7B0%2C50%7D+%5B%22that%22%5D+%5B%22we%22%5D+%5B%22wanted%22%5D+%5B%22to%22%5D+%5B%22see%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%5D+%5B%22Then%22%5D+%5B%22after%22%5D+%5B%22awhile%22%5D+%5B%22you%22%5D+%5B%22become%22%5D+%5B%22so%22%5D+%5B%22numb%22%5D+%5B%22that%22%5D+%5B%22you%22%5D+%5B%22just%22%5D+%5B%5D%7B0%2C50%7D+%5B%22you%22%5D+%5B%22do%22%5D+%5B%5D+%5B%22react%22%5D+%5B%5D+%5B%22you%22%5D+%5B%5D%7B0%2C50%7D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"To see another 10,000 Jews come and be killed , another 20,000 be killed ? That was not ... that we wanted to see . You know . We had to . Then after awhile you become so numb that you just ... you do n't react , you ... you know ? \", 'right': '', 'complete_match': \"To see another 10,000 Jews come and be killed , another 20,000 be killed ? That was not ... that we wanted to see . You know . We had to . Then after awhile you become so numb that you just ... you do n't react , you ... you know ? \", 'testimony_id': 'irn504680', 'shelfmark': ['USHMM RG-50.030*0184'], 'token_start': 9900, 'token_end': 9953}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"To see another 10,000 Jews come and be killed, another 20,000 be killed? That was not...that we wanted to see. You know. We had to. Then after awhile you become so numb that you just...you don't react, you...you know?\"\n",
    "fragment_2['label']=\"To see another 10,000 Jews come and be killed (..) Then after awhile you become so numb (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22so%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%5D+%5B%22Cathy%22%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%22every%22%5D+%5B%2210%22%5D+%5B%22people%22%5D+%5B%22get%22%5D+%5B%22killed%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And we were so numb , [ ? Cathy ? ] every 10 people get killed . ', 'right': '', 'complete_match': 'And we were so numb , [ ? Cathy ? ] every 10 people get killed . ', 'testimony_id': 'usc_shoah_25287', 'shelfmark': ['USC 25287'], 'token_start': 16040, 'token_end': 16057}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = 'And we were so numb, [? Cathy ?] every 10 people get killed.'\n",
    "fragment_3['label']=\"And we were so numb, (..) every 10 people get killed.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22from%22%5D+%5B%22people%22%5D+%5B%22being%22%5D+%5B%22wounded%22%5D+%5B%5D+%5B%22from%22%5D+%5B%22people%22%5D+%5B%22being%22%5D+%5B%22killed%22%5D+%5B%5D+%5B%22from%22%5D+%5B%22cries%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22finally%22%5D+%5B%5D+%5B%22everything%22%5D+%5B%22subsided%22%5D+%5B%5D+%5B%22But%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22alive%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22did%22%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22even%22%5D+%5B%22think%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22numb%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"from people being wounded , from people being killed , from cries . And finally , everything subsided . But I was alive . I did n't -- I did n't even think . I was numb . \", 'right': '', 'complete_match': \"from people being wounded , from people being killed , from cries . And finally , everything subsided . But I was alive . I did n't -- I did n't even think . I was numb . \", 'testimony_id': 'usc_shoah_2590', 'shelfmark': ['USC 2590'], 'token_start': 6362, 'token_end': 6400}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"from people being wounded, from people being killed, from cries. And finally, everything subsided. But I was alive. I didn't -- I didn't even think. I was numb.\"\n",
    "fragment_4['label']= \"I heard screams and-- from-- from-- from-- from people being wounded, from people being killed, from cries (..) I was numb\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = 'shock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '[lemma=\"shock\"]([]{0,25}[lemma=\"numb\"])|[lemma=\"numb\"]([]{0,25}[lemma=\"shock\"])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = 'shock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%22in%22%5D+%5B%22complete%22%5D+%5B%22shock%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22nothing%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I was in complete shock . I was numb , nothing . ', 'right': '', 'complete_match': 'I was in complete shock . I was numb , nothing . ', 'testimony_id': 'HVT-108', 'shelfmark': ['Fortunoff HVT-108'], 'token_start': 4794, 'token_end': 4806}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = 'I was in complete shock. I was numb, nothing.'\n",
    "fragment_1['label']='I was in complete shock. I was numb, nothing.'\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22were%22%5D+%5B%22so%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22almost%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22shock%22%5D+%5B%22hypnotized%22%5D+%5B%22us%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We were so numb , we were almost , the shock hypnotized us , ', 'right': '', 'complete_match': 'We were so numb , we were almost , the shock hypnotized us , ', 'testimony_id': 'irn504925', 'shelfmark': ['USHMM RG-50.549.01*0024'], 'token_start': 5647, 'token_end': 5661}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = 'We were so numb, we were almost, the shock hypnotized us,'\n",
    "fragment_2['label']='We were so numb, we were almost, the shock hypnotized us (..)'\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22are%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22You%22%5D+%5B%5D+%5B%22shocked%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"You are numb . You 're shocked . \", 'right': '', 'complete_match': \"You are numb . You 're shocked . \", 'testimony_id': 'usc_shoah_10358', 'shelfmark': ['USC 10358'], 'token_start': 3799, 'token_end': 3807}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"You are numb. You're shocked.\"\n",
    "fragment_3['label']=\"You are numb. You're shocked\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%5D%7B0%2C3%7D+%5B%22PAUSES%22%5D+%5B%22FOR%22%5D+%5B%224%22%5D+%5B%22SECONDS%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22numb%22%5D+%5B%22when%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22there%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22%27ll%22%5D+%5B%22be%22%5D+%5B%22very%22%5D+%5B%22honest%22%5D+%5B%22with%22%5D+%5B%22you%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22not%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22somewhat%22%5D+%5B%22in%22%5D+%5B%22a%22%5D+%5B%22state%22%5D+%5B%22of%22%5D+%5B%22shock%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And [ PAUSES FOR 4 SECONDS ] I was numb when I was there . I 'll be very honest with you . I was not -- I was somewhat in a state of shock . \", 'right': '', 'complete_match': \"And [ PAUSES FOR 4 SECONDS ] I was numb when I was there . I 'll be very honest with you . I was not -- I was somewhat in a state of shock . \", 'testimony_id': 'usc_shoah_24163', 'shelfmark': ['USC 24163'], 'token_start': 22536, 'token_end': 22572}\n"
     ]
    }
   ],
   "source": [
    "fragment_ = {}\n",
    "fragment_4['original_sentence'] = \"And [PAUSES FOR 4 SECONDS] I was numb when I was there.  I'll be very honest with you. I was not-- I was somewhat in a state of shock.\"\n",
    "fragment_4['label']=\"I was numb when I was there. (..) I was somewhat in a state of shock.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%2215%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22shocked%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I was 15 . I was shocked . ', 'right': '', 'complete_match': 'I was 15 . I was shocked . ', 'testimony_id': 'usc_shoah_24470', 'shelfmark': ['USC 24470'], 'token_start': 7698, 'token_end': 7706}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = 'I was 15. I was shocked.'\n",
    "fragment_5['label']='I was a completely-- I guess I was-- I was 15. I was shocked. I was, uh, numb.'\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Dead inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_node = \"numbness\"\n",
    "domain_term = 'shock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = ['lose','numb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"lose\"][]{0,50}[lemma=\"numb\"])|([lemma=\"numb\"][]{0,50}[lemma=\"lose\"])\n"
     ]
    }
   ],
   "source": [
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments['main_node'] = main_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments']= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22By%22%5D+%5B%22the%22%5D+%5B%22time%22%5D+%5B%22the%22%5D+%5B%22Nazis%22%5D+%5B%22took%22%5D+%5B%22us%22%5D+%5B%22into%22%5D+%5B%22the%22%5D+%5B%22concentration%22%5D+%5B%22camp%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22so%22%5D+%5B%22numb%22%5D+%5B%22inside%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22so%22%5D+%5B%22dead%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22not%22%5D+%5B%22able%22%5D+%5B%22to%22%5D+%5B%22feel%22%5D+%5B%22anything%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'By the time the Nazis took us into the concentration camp I was so numb inside , I was so dead , I was not able to feel anything . ', 'right': '', 'complete_match': 'By the time the Nazis took us into the concentration camp I was so numb inside , I was so dead , I was not able to feel anything . ', 'testimony_id': 'irn504792', 'shelfmark': ['USHMM RG-50.030*0296'], 'token_start': 2032, 'token_end': 2062}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = 'By the time the Nazis took us into the concentration camp I was so numb inside, I was so dead, I was not able to feel anything.'\n",
    "fragment_1['label']='(..) I was so numb inside, I was so dead (..)'\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22were%22%5D+%5B%22so%22%5D+%5B%22numb%22%5D+%5B%22that%22%5D+%5B%22everything%22%5D+%5B%22that%22%5D+%5B%22you%22%5D+%5B%22saw%22%5D+%5B%22around%22%5D+%5B%22you%22%5D+%5B%5D+%5B%22that%22%5D+%5B%22you%22%5D+%5B%5D+%5B%22your%22%5D+%5B%22feelings%22%5D+%5B%22were%22%5D+%5B%22dead%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You were so numb that everything that you saw around you , that you , your feelings were dead . ', 'right': '', 'complete_match': 'You were so numb that everything that you saw around you , that you , your feelings were dead . ', 'testimony_id': 'irn505576', 'shelfmark': ['USHMM RG-50.042*0023'], 'token_start': 8257, 'token_end': 8277}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = 'You were so numb that everything that you saw around you, that you, your feelings were dead.'\n",
    "fragment_2['label']='You were so numb that everything that you saw around you, that you, your feelings were dead.'\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Uh%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22had%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22moving%22%5D+%5B%22sometimes%22%5D+%5B%22uh%22%5D+%5B%5D+%5B%22fifty%22%5D+%5B%22or%22%5D+%5B%22sixty%22%5D+%5B%22miles%22%5D+%5B%22a%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22working%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22night%22%5D+%5B%22and%22%5D+%5B%22uh%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22just%22%5D+%5B%22uh%22%5D+%5B%5D+%5B%22uh%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22just%22%5D+%5B%22dead%22%5D+%5B%22on%22%5D+%5B%22our%22%5D+%5B%22feet%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22uh%22%5D+%5B%5D+%5B%22one%22%5D+%5B%22of%22%5D+%5B%22the%22%5D+%5B%22problems%22%5D+%5B%22that%22%5D+%5B%22we%22%5D+%5B%22had%22%5D+%5B%22in%22%5D+%5B%22relation%22%5D+%5B%22to%22%5D+%5B%22this%22%5D+%5B%22type%22%5D+%5B%22of%22%5D+%5B%22recollection%22%5D+%5B%22is%22%5D+%5B%22that%22%5D+%5B%22uh%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22numb%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Uh , we had , we were moving sometimes uh , fifty or sixty miles a day and working day and night and uh , we were just uh , uh , we were just dead on our feet , and uh , one of the problems that we had in relation to this type of recollection is that uh , we were numb . ', 'right': '', 'complete_match': 'Uh , we had , we were moving sometimes uh , fifty or sixty miles a day and working day and night and uh , we were just uh , uh , we were just dead on our feet , and uh , one of the problems that we had in relation to this type of recollection is that uh , we were numb . ', 'testimony_id': 'irn504594', 'shelfmark': ['USHMM RG-50.030*0100'], 'token_start': 7137, 'token_end': 7202}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = 'Uh, we had, we were moving sometimes uh, fifty or sixty miles a day and working day and night and uh, we were just uh, uh, we were just dead on our feet, and uh, one of the problems that we had in relation to this type of recollection is that uh, we were numb.'\n",
    "fragment_3['label']='we were just dead on our feet, and uh, one of the problems that we had in relation to this type of recollection is that uh, we were numb.'\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Your%22%5D+%5B%22heart%22%5D+%5B%5D+%5B%22everything%22%5D+%5B%5D+%5B%22your%22%5D+%5B%22whole%22%5D+%5B%22body%22%5D+%5B%22start%22%5D+%5B%22getting%22%5D+%5B%22already%22%5D+%5B%22like%22%5D+%5B%22numb%22%5D+%5B%22and%22%5D+%5B%22dead%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Your heart , everything , your whole body start getting already like numb and dead . ', 'right': '', 'complete_match': 'Your heart , everything , your whole body start getting already like numb and dead . ', 'testimony_id': 'irn510703', 'shelfmark': ['USHMM RG-50.156*0049'], 'token_start': 1038, 'token_end': 1054}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = 'Your heart, everything, your whole body start getting already like numb and dead.'\n",
    "fragment_4['label']=\"Your heart, everything, your whole body start getting already like numb and dead.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mid node exists cannot be added\n"
     ]
    }
   ],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  Lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas =['lose','numb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = create_contextual_query(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"lose\"][]{0,50}[lemma=\"numb\"])|([lemma=\"numb\"][]{0,50}[lemma=\"lose\"])\n"
     ]
    }
   ],
   "source": [
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = 'lose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments['main_node'] = main_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments']= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22saw%22%5D+%5B%22parents%22%5D+%5B%22who%22%5D+%5B%22lost%22%5D+%5B%22their%22%5D+%5B%22children%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22saw%22%5D+%5B%22husbands%22%5D+%5B%22who%22%5D+%5B%22lost%22%5D+%5B%22their%22%5D+%5B%22wives%22%5D+%5B%22and%22%5D+%5B%22vise%22%5D+%5B%22versa%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22numbed%22%5D+%5B%5D+%5B%22actually%22%5D+%5B%5D+%5B%22to%22%5D+%5B%5D%7B0%2C3%7D+%5B%22they%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22complain%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"I saw parents who lost their children . I saw husbands who lost their wives and vise versa , and they were numbed , actually , to -- they did n't complain . \", 'right': '', 'complete_match': \"I saw parents who lost their children . I saw husbands who lost their wives and vise versa , and they were numbed , actually , to -- they did n't complain . \", 'testimony_id': 'HVT-44', 'shelfmark': ['Fortunoff HVT-44'], 'token_start': 7520, 'token_end': 7553}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"I saw parents who lost their children. I saw husbands who lost their wives and vise versa, and they were numbed, actually, to-- they didn't complain.\"\n",
    "fragment_1['label']=\"I saw parents who lost their children. I saw husbands who lost their wives and vise versa, and they were numbed (..)\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%222%3A3%3A18%22%5D+%5B%22The%22%5D+%5B%22most%22%5D+%5B%22tragic%22%5D+%5B%22kind%22%5D+%5B%22of%22%5D+%5B%22family%22%5D+%5B%22is%22%5D+%5B%22the%22%5D+%5B%22numb%22%5D+%5B%22family%22%5D+%5B%22who%22%5D+%5B%22are%22%5D+%5B%22survivors%22%5D+%5B%22who%22%5D+%5B%22usually%22%5D+%5B%22lost%22%5D+%5B%22both%22%5D+%5B%22their%22%5D+%5B%22parents%22%5D+%5B%22and%22%5D+%5B%22their%22%5D+%5B%22children%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': '2:3:18 The most tragic kind of family is the numb family who are survivors who usually lost both their parents and their children . ', 'right': '', 'complete_match': '2:3:18 The most tragic kind of family is the numb family who are survivors who usually lost both their parents and their children . ', 'testimony_id': 'irn514120', 'shelfmark': ['USHMM RG-50.243*0007'], 'token_start': 1326, 'token_end': 1350}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"2:3:18 The most tragic kind of family is the numb family who are survivors who usually lost both their parents and their children.\"\n",
    "fragment_2['label']=\"(..) the numb family who are survivors who usually lost both their parents and their children.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22still%22%5D+%5B%22was%22%5D+%5B%22despising%22%5D+%5B%5D%7B0%2C50%7D+%5B%22but%22%5D+%5B%22I%22%5D+%5B%22had%22%5D+%5B%22become%22%5D+%5B%22somehow%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22knew%22%5D+%5B%22I%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22change%22%5D+%5B%22things%22%5D+%5B%5D%7B0%2C50%7D+%5B%22all%22%5D+%5B%22these%22%5D+%5B%22people%22%5D+%5B%22I%22%5D+%5B%22have%22%5D+%5B%22lost%22%5D+%5B%5D+%5B%22all%22%5D+%5B%22these%22%5D+%5B%22victims%22%5D+%5B%22I%22%5D+%5B%22had%22%5D+%5B%22seen%22%5D+%5B%5D+%5B%22all%22%5D+%5B%22these%22%5D+%5B%22corpses%22%5D+%5B%22I%22%5D+%5B%22had%22%5D+%5B%22seen%22%5D+%5B%22lying%22%5D+%5B%22around%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22by%22%5D+%5B%22the%22%5D+%5B%22way%22%5D+%5B%22I%22%5D+%5B%22lost%22%5D+%5B%22also%22%5D+%5B%22then%22%5D+%5B%22within%22%5D+%5B%22a%22%5D+%5B%22short%22%5D+%5B%22time%22%5D+%5B%5D+%5B%22two%22%5D+%5B%22of%22%5D+%5B%22my%22%5D+%5B%22close%22%5D+%5B%22friends%22%5D+%5B%22be%22%5D+%5B%5D%7B0%2C50%7D+%5B%22because%22%5D+%5B%22they%22%5D+%5B%22they%22%5D+%5B%22could%22%5D+%5B%5D%7B0%2C50%7D+%5B%22one%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22man%22%5D+%5B%22who%22%5D+%5B%22was%22%5D+%5B%22highly%22%5D+%5B%22idealistic%22%5D+%5B%22and%22%5D+%5B%22he%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22take%22%5D+%5B%22the%22%5D+%5B%22misery%22%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22the%22%5D+%5B%22this%22%5D+%5B%22this%22%5D+%5B%22this%22%5D+%5B%22this%22%5D+%5B%22height%22%5D+%5B%22of%22%5D+%5B%22inhumanity%22%5D+%5B%5D+%5B%22so%22%5D+%5B%22he%22%5D+%5B%22he%22%5D+%5B%22uh%22%5D+%5B%22said%22%5D+%5B%22enough%22%5D+%5B%22is%22%5D+%5B%22enough%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"I still was despising ... but I had become somehow numb . I knew I could n't change things ... all these people I have lost , all these victims I had seen , all these corpses I had seen lying around , and by the way I lost also then within a short time , two of my close friends be ... because they they could ... one was a man who was highly idealistic and he could n't take the misery and the the this this this this height of inhumanity , so he he uh said enough is enough . \", 'right': '', 'complete_match': \"I still was despising ... but I had become somehow numb . I knew I could n't change things ... all these people I have lost , all these victims I had seen , all these corpses I had seen lying around , and by the way I lost also then within a short time , two of my close friends be ... because they they could ... one was a man who was highly idealistic and he could n't take the misery and the the this this this this height of inhumanity , so he he uh said enough is enough . \", 'testimony_id': 'irn506769', 'shelfmark': ['USHMM RG-50.030*0257'], 'token_start': 35602, 'token_end': 35705}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"I still was despising...but I had become somehow numb. I knew I couldn't change things...all these people I have lost, all these victims I had seen, all these corpses I had seen lying around, and by the way I lost also then within a short time, two of my close friends be...because they they could...one was a man who was highly idealistic and he couldn't take the misery and the the this this this this height of inhumanity, so he he uh said enough is enough.\"\n",
    "fragment_3['label']=\"I had become somehow numb. I knew I couldn't change things...all these people I have lost\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22MR%22%5D+%5B%22%3A%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22so%22%5D+%5B%22numb%22%5D+%5B%22that%22%5D+%5B%22I%22%5D+%5B%22do%22%5D+%5B%5D+%5B%22even%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22all%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22lost%22%5D+%5B%22everybody%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"MR : I was so numb that I do n't even know . I was all numb . I lost everybody . \", 'right': '', 'complete_match': \"MR : I was so numb that I do n't even know . I was all numb . I lost everybody . \", 'testimony_id': 'usc_shoah_198', 'shelfmark': ['USC 198'], 'token_start': 8130, 'token_end': 8152}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"MR: I was so numb that I don't even know. I was all numb. I lost everybody.\"\n",
    "fragment_4['label']=\"I was all numb. I lost everybody.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  No feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas =['feeling','numb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = create_contextual_query(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"feeling\"][]{0,50}[lemma=\"numb\"])|([lemma=\"numb\"][]{0,50}[lemma=\"feeling\"])\n"
     ]
    }
   ],
   "source": [
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = 'no feeling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments['main_node'] = main_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments']= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22were%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22The%22%5D+%5B%22five%22%5D+%5B%22years%22%5D+%5B%22there%22%5D+%5B%22were%22%5D+%5B%22no%22%5D+%5B%22feelings%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We were numb . The five years there were no feelings . ', 'right': '', 'complete_match': 'We were numb . The five years there were no feelings . ', 'testimony_id': 'HVT-81', 'shelfmark': ['Fortunoff HVT-81'], 'token_start': 8935, 'token_end': 8947}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"We were numb. The five years there were no feelings.\"\n",
    "fragment_1['label']=\"We were numb. The five years there were no feelings.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22had%22%5D+%5B%22no%22%5D+%5B%22feeling%22%5D+%5B%22to%22%5D+%5B%22even%22%5D+%5B%22think%22%5D+%5B%22how%22%5D+%5B%22I%22%5D+%5B%22would%22%5D+%5B%22feel%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22so%22%5D+%5B%22I%22%5D+%5B%22%27m%22%5D+%5B%22just%22%5D+%5B%22like%22%5D+%5B%22a%22%5D+%5B%22machine%22%5D+%5B%5D+%5B%22numb%22%5D+%5B%22machine%22%5D+%5B%5D+%5B%22going%22%5D+%5B%22through%22%5D+%5B%22the%22%5D+%5B%22mechanical%22%5D+%5B%22motions%22%5D+%5B%22of%22%5D+%5B%22something%22%5D+%5B%22that%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22forced%22%5D+%5B%22into%22%5D+%5B%22doing%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"They had no feeling to even think how I would feel . And so I 'm just like a machine , numb machine , going through the mechanical motions of something that I was forced into doing . \", 'right': '', 'complete_match': \"They had no feeling to even think how I would feel . And so I 'm just like a machine , numb machine , going through the mechanical motions of something that I was forced into doing . \", 'testimony_id': 'irn504449', 'shelfmark': ['USHMM RG-50.030*0020'], 'token_start': 14670, 'token_end': 14708}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"They had no feeling to even think how I would feel. And so I'm just like a machine, numb machine, going through the mechanical motions of something that I was forced into doing.\"\n",
    "fragment_2['label']=\"They had no feeling to even think how I would feel. And so I'm just like a machine, numb machine (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22But%22%5D+%5B%22you%22%5D+%5B%22become%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22You%22%5D+%5B%5D%7B0%2C50%7D+%5B%22you%22%5D+%5B%5D+%5B%22not%22%5D+%5B%22really%22%5D+%5B%22sensitive%22%5D+%5B%22to%22%5D+%5B%22feelings%22%5D+%5B%22any%22%5D+%5B%22more%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"But you become numb , you know . You ... you 're not really sensitive to feelings any more . \", 'right': '', 'complete_match': \"But you become numb , you know . You ... you 're not really sensitive to feelings any more . \", 'testimony_id': 'irn504449', 'shelfmark': ['USHMM RG-50.030*0020'], 'token_start': 15269, 'token_end': 15289}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"But you become numb, you know. You...you're not really sensitive to feelings any more.\"\n",
    "fragment_3['label']=\"But you become numb, you know. You...you're not really sensitive to feelings any more.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22were%22%5D+%5B%22no%22%5D+%5B%22feelings%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22were%22%5D+%5B%22completely%22%5D+%5B%22numb%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The were no feelings . You were completely numb . ', 'right': '', 'complete_match': 'The were no feelings . You were completely numb . ', 'testimony_id': 'HVT-36', 'shelfmark': ['Fortunoff HVT-36'], 'token_start': 5363, 'token_end': 5373}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"The were no feelings. You were completely numb.\"\n",
    "fragment_4['label']= \"The were no feelings. You were completely numb.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22It%22%5D+%5B%22was%22%5D+%5B%22all%22%5D+%5B%22numb%22%5D+%5B%22and%22%5D+%5B%22just%22%5D+%5B%5D%7B0%2C3%7D+%5B%22could%22%5D+%5B%5D+%5B%22have%22%5D+%5B%22any%22%5D+%5B%22feeling%22%5D+%5B%5D+%5B%22it%22%5D+%5B%22felt%22%5D+%5B%22like%22%5D+%5B%22just%22%5D+%5B%22you%22%5D+%5B%5D%7B0%2C3%7D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%22how%22%5D+%5B%22your%22%5D+%5B%22leg%22%5D+%5B%5D%7B0%2C3%7D+%5B%22how%22%5D+%5B%22something%22%5D+%5B%22goes%22%5D+%5B%22to%22%5D+%5B%22sleep%22%5D+%5B%22when%22%5D+%5B%22you%22%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%22indecipherable%22%5D+%5B%5D%7B0%2C3%7D+%5B%22that%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22way%22%5D+%5B%22it%22%5D+%5B%22felt%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'It was all numb and just  could nt have any feeling , it felt like just you  you know how your leg  how something goes to sleep when you re [ indecipherable ] that s the way it felt . ', 'right': '', 'complete_match': 'It was all numb and just  could nt have any feeling , it felt like just you  you know how your leg  how something goes to sleep when you re [ indecipherable ] that s the way it felt . ', 'testimony_id': 'irn55166', 'shelfmark': ['USHMM RG-50.030*0691'], 'token_start': 17163, 'token_end': 17206}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"It was all numb and just  couldnt have any feeling, it felt like just you  you know how your leg  how something goes to sleep when youre [indecipherable] thats the way it felt.\"\n",
    "fragment_5['label']= \"It was all numb and just  couldnt have any feeling\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  No cry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas =['cry','numb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = create_contextual_query(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"cry\"][]{0,50}[lemma=\"numb\"])|([lemma=\"numb\"][]{0,50}[lemma=\"cry\"])\n"
     ]
    }
   ],
   "source": [
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = 'no cry'\n",
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments']= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22never%22%5D+%5B%22cried%22%5D+%5B%5D+%5B%22You%22%5D+%5B%22so%22%5D+%5B%5D%7B0%2C50%7D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22so%22%5D+%5B%22numb%22%5D+%5B%5D%7B0%2C50%7D+%5B%22it%22%5D+%5B%5D+%5B%5D%7B0%2C50%7D+%5B%22it%22%5D+%5B%5D+%5B%22very%22%5D+%5B%22hard%22%5D+%5B%22to%22%5D+%5B%22explain%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"You never cried . You so ... it was so numb ... it 's ... it 's very hard to explain . \", 'right': '', 'complete_match': \"You never cried . You so ... it was so numb ... it 's ... it 's very hard to explain . \", 'testimony_id': 'irn504680', 'shelfmark': ['USHMM RG-50.030*0184'], 'token_start': 12235, 'token_end': 12257}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"You never cried. You so...it was so numb...it's...it's very hard to explain.\"\n",
    "fragment_1['label']=\"You never cried. You so...it was so numb...it's...it's very hard to explain.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22That%22%5D+%5B%22was%22%5D+%5B%5D%7B0%2C3%7D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22We%22%5D+%5B%22could%22%5D+%5B%5D+%5B%5D%7B0%2C3%7D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%5D+%5B%22a%22%5D+%5B%22question%22%5D+%5B%5D%7B0%2C3%7D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%5D+%5B%22crying%22%5D+%5B%22but%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%5D%7B0%2C3%7D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22like%22%5D+%5B%22num%22%5D+%5B%5D%7B0%2C3%7D+%5B%22just%22%5D+%5B%22pieces%22%5D+%5B%22of%22%5D+%5B%22would%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"That was -- we were numb . We could n't -- it was n't a question -- we were n't crying but we were -- we were like num -- just pieces of would . \", 'right': '', 'complete_match': \"That was -- we were numb . We could n't -- it was n't a question -- we were n't crying but we were -- we were like num -- just pieces of would . \", 'testimony_id': 'irn511029', 'shelfmark': ['USHMM RG-50.471*0011'], 'token_start': 9405, 'token_end': 9440}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"That was--we were numb. We couldn't--it wasn't a question--we weren't crying but we were--we were like num--just pieces of would.\"\n",
    "fragment_2['label']=\"(..)we were numb. We couldn't--it wasn't a question--we weren't crying (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22But%22%5D+%5B%22I%22%5D+%5B%5D%7B0%2C3%7D+%5B%22at%22%5D+%5B%22that%22%5D+%5B%22time%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22like%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22felt%22%5D+%5B%22like%22%5D+%5B%22I%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22even%22%5D+%5B%22cry%22%5D+%5B%22anymore%22%5D+%5B%5D+%5B%22Just%22%5D+%5B%22could%22%5D+%5B%5D+%5B%5D+%5B%22I%22%5D+%5B%22mean%22%5D+%5B%5D+%5B%22there%22%5D+%5B%22just%22%5D+%5B%5D%7B0%2C3%7D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22numb%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"But I -- at that time , I was like -- I felt like I , I was -- I could n't even cry anymore . Just could n't . I mean , there just -- I was numb . \", 'right': '', 'complete_match': \"But I -- at that time , I was like -- I felt like I , I was -- I could n't even cry anymore . Just could n't . I mean , there just -- I was numb . \", 'testimony_id': 'usc_shoah_22892', 'shelfmark': ['USC 22892'], 'token_start': 8452, 'token_end': 8492}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"But I-- at that time, I was like-- I felt like I, I was-- I couldn't even cry anymore. Just couldn't. I mean, there just-- I was numb.\"\n",
    "fragment_3['label']=\"I couldn't even cry anymore. Just couldn't. I mean, there just-- I was numb.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22after%22%5D+%5B%22about%22%5D+%5B%22four%22%5D+%5B%22hours%22%5D+%5B%5D%7B0%2C3%7D+%5B%22and%22%5D+%5B%22I%22%5D+%5B%22probably%22%5D+%5B%22was%22%5D+%5B%22numb%22%5D+%5B%22%3B%22%5D+%5B%22I%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22cry%22%5D+%5B%22or%22%5D+%5B%22say%22%5D+%5B%5D%7B0%2C3%7D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"And after about four hours -- and I probably was numb ; I could n't cry or say [ \", 'right': '', 'complete_match': \"And after about four hours -- and I probably was numb ; I could n't cry or say [ \", 'testimony_id': 'usc_shoah_6845', 'shelfmark': ['USC 6845'], 'token_start': 6497, 'token_end': 6516}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"And after about four hours-- and I probably was numb; I couldn't cry or say [?\"\n",
    "fragment_4['label']=\"I probably was numb; I couldn't cry\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22I%22%5D+%5B%22was%22%5D+%5B%22numb%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22express%22%5D+%5B%22any%22%5D+%5B%22emotions%22%5D+%5B%22or%22%5D+%5B%22anything%22%5D+%5B%22like%22%5D+%5B%22that%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22did%22%5D+%5B%5D+%5B%22cry%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'I was numb . I did nt express any emotions or anything like that , I did nt cry . ', 'right': '', 'complete_match': 'I was numb . I did nt express any emotions or anything like that , I did nt cry . ', 'testimony_id': 'irn507294', 'shelfmark': ['USHMM RG-50.030*0405'], 'token_start': 29197, 'token_end': 29217}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"I was numb. I didnt express any emotions or anything like that, I didnt cry.\"\n",
    "fragment_5['label']=\"I was numb. I didnt express any emotions or anything like that, I didnt cry.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
