{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"sit\"\n",
    "#delete_main_node(main_node)\n",
    "add_main_node(main_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = '[lemma=\"sit\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = topic_concordancer.main(query,window=25,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.233*\"sit\" + 0.089*\"seconds\" + 0.056*\"hour\" + 0.039*\"stop\" + 0.032*\"move\" + 0.029*\"point\" + 0.027*\"half\" + 0.026*\"end\" + 0.026*\"week\" + 0.023*\"horse\"\n",
      "\n",
      "\n",
      "1\n",
      "0.149*\"talk\" + 0.095*\"thing\" + 0.078*\"happen\" + 0.077*\"hear\" + 0.055*\"listen\" + 0.052*\"story\" + 0.049*\"life\" + 0.041*\"talk_about\" + 0.024*\"one_day\" + 0.023*\"question\"\n",
      "\n",
      "\n",
      "2\n",
      "0.555*\"do_not\" + 0.108*\"give\" + 0.035*\"bread\" + 0.034*\"truck\" + 0.029*\"understand\" + 0.022*\"word\" + 0.021*\"piece_of\" + 0.014*\"how_long\" + 0.009*\"care\" + 0.009*\"food\"\n",
      "\n",
      "\n",
      "3\n",
      "0.133*\"my_mother\" + 0.125*\"my_father\" + 0.051*\"my_sister\" + 0.046*\"my_brother\" + 0.044*\"hand\" + 0.044*\"mother\" + 0.032*\"father\" + 0.032*\"hold\" + 0.025*\"come_home\" + 0.023*\"brother\"\n",
      "\n",
      "\n",
      "4\n",
      "0.142*\"man\" + 0.127*\"sit\" + 0.119*\"child\" + 0.097*\"woman\" + 0.025*\"beautiful\" + 0.024*\"synagogue\" + 0.016*\"wear\" + 0.016*\"shoe\" + 0.015*\"downstairs\" + 0.015*\"explain\"\n",
      "\n",
      "\n",
      "5\n",
      "0.269*\"sit\" + 0.141*\"back\" + 0.061*\"find\" + 0.042*\"seat\" + 0.034*\"front\" + 0.025*\"afraid\" + 0.022*\"wood\" + 0.018*\"tree\" + 0.018*\"throw\" + 0.016*\"forest\"\n",
      "\n",
      "\n",
      "6\n",
      "0.087*\"sit\" + 0.074*\"jewish\" + 0.068*\"girl\" + 0.062*\"school\" + 0.043*\"kid\" + 0.035*\"year\" + 0.031*\"boy\" + 0.029*\"class\" + 0.028*\"learn\" + 0.025*\"teacher\"\n",
      "\n",
      "\n",
      "7\n",
      "0.342*\"people\" + 0.057*\"sit\" + 0.057*\"a_lot\" + 0.045*\"die\" + 0.029*\"person\" + 0.027*\"group\" + 0.025*\"dead\" + 0.025*\"forget\" + 0.022*\"survive\" + 0.019*\"people_who\"\n",
      "\n",
      "\n",
      "8\n",
      "0.190*\"could_not\" + 0.110*\"place\" + 0.052*\"sleep\" + 0.047*\"stand\" + 0.043*\"stay\" + 0.037*\"water\" + 0.023*\"each_other\" + 0.022*\"barrack\" + 0.021*\"push\" + 0.021*\"move\"\n",
      "\n",
      "\n",
      "9\n",
      "0.088*\"sit\" + 0.063*\"guy\" + 0.057*\"camp\" + 0.040*\"put\" + 0.039*\"wagon\" + 0.037*\"over_there\" + 0.034*\"soldier\" + 0.030*\"foot\" + 0.028*\"ss\" + 0.027*\"guard\"\n",
      "\n",
      "\n",
      "10\n",
      "0.194*\"sit\" + 0.088*\"german\" + 0.047*\"kill\" + 0.037*\"office\" + 0.035*\"meet\" + 0.023*\"let_'s\" + 0.023*\"drink\" + 0.021*\"Mr.\" + 0.019*\"end_of\" + 0.018*\"Russians\"\n",
      "\n",
      "\n",
      "11\n",
      "0.152*\"make\" + 0.097*\"sit\" + 0.087*\"big\" + 0.055*\"watch\" + 0.040*\"try_to\" + 0.039*\"play\" + 0.023*\"ground\" + 0.020*\"clothes\" + 0.018*\"buy\" + 0.018*\"change\"\n",
      "\n",
      "\n",
      "12\n",
      "0.429*\"sit_down\" + 0.096*\"start\" + 0.045*\"write\" + 0.025*\"able_to\" + 0.023*\"long\" + 0.018*\"step\" + 0.017*\"finally\" + 0.014*\"letter\" + 0.014*\"minute\" + 0.014*\"death\"\n",
      "\n",
      "\n",
      "13\n",
      "0.113*\"sit\" + 0.067*\"chair\" + 0.065*\"door\" + 0.062*\"window\" + 0.056*\"open\" + 0.045*\"read\" + 0.044*\"front_of\" + 0.039*\"speak\" + 0.037*\"close\" + 0.034*\"book\"\n",
      "\n",
      "\n",
      "14\n",
      "0.151*\"train\" + 0.084*\"sit\" + 0.057*\"run\" + 0.053*\"car\" + 0.036*\"head\" + 0.035*\"on_top\" + 0.034*\"town\" + 0.028*\"shoot\" + 0.025*\"start\" + 0.024*\"arrive\"\n",
      "\n",
      "\n",
      "15\n",
      "0.087*\"leave\" + 0.065*\"sit_next\" + 0.063*\"picture\" + 0.059*\"side\" + 0.058*\"family\" + 0.027*\"left\" + 0.027*\"my_husband\" + 0.026*\"wife\" + 0.024*\"my_wife\" + 0.022*\"live\"\n",
      "\n",
      "\n",
      "16\n",
      "0.110*\"walk\" + 0.108*\"house\" + 0.093*\"sit\" + 0.053*\"food\" + 0.045*\"look_at\" + 0.032*\"little_bit\" + 0.031*\"street\" + 0.029*\"polish\" + 0.019*\"pass\" + 0.017*\"road\"\n",
      "\n",
      "\n",
      "17\n",
      "0.203*\"sit\" + 0.076*\"cry\" + 0.057*\"feel\" + 0.029*\"kind_of\" + 0.027*\"what_happen\" + 0.026*\"Germany\" + 0.021*\"drive\" + 0.018*\"Israel\" + 0.018*\"find_out\" + 0.016*\"bad\"\n",
      "\n",
      "\n",
      "18\n",
      "0.132*\"room\" + 0.118*\"sit\" + 0.081*\"put\" + 0.065*\"floor\" + 0.045*\"bed\" + 0.043*\"stand\" + 0.034*\"corner\" + 0.029*\"stand_up\" + 0.027*\"wall\" + 0.026*\"kitchen\"\n",
      "\n",
      "\n",
      "19\n",
      "0.192*\"time\" + 0.149*\"sit\" + 0.079*\"bench\" + 0.059*\"of_course\" + 0.054*\"Jews\" + 0.029*\"hide\" + 0.027*\"inside\" + 0.026*\"jew\" + 0.022*\"not_allow\" + 0.021*\"park\"\n",
      "\n",
      "\n",
      "20\n",
      "0.163*\"sit\" + 0.136*\"work\" + 0.070*\"wait\" + 0.065*\"do_not\" + 0.052*\"war\" + 0.042*\"come_back\" + 0.031*\"give\" + 0.023*\"money\" + 0.023*\"job\" + 0.019*\"suppose\"\n",
      "\n",
      "\n",
      "21\n",
      "0.199*\"sit\" + 0.046*\"Germans\" + 0.037*\"go_back\" + 0.037*\"ghetto\" + 0.026*\"nice\" + 0.025*\"city\" + 0.020*\"dress\" + 0.020*\"go_through\" + 0.019*\"Poland\" + 0.017*\"part_of\"\n",
      "\n",
      "\n",
      "22\n",
      "0.250*\"remember\" + 0.138*\"table\" + 0.064*\"sit_around\" + 0.043*\"sort_of\" + 0.033*\"sit\" + 0.031*\"thing\" + 0.024*\"must_have\" + 0.024*\"my_parent\" + 0.015*\"meal\" + 0.012*\"dining_room\"\n",
      "\n",
      "\n",
      "23\n",
      "0.162*\"day\" + 0.105*\"eat\" + 0.092*\"night\" + 0.048*\"bring\" + 0.048*\"morning\" + 0.034*\"evening\" + 0.033*\"at_night\" + 0.025*\"dark\" + 0.021*\"till\" + 0.020*\"fact\"\n",
      "\n",
      "\n",
      "24\n",
      "0.153*\"sit\" + 0.068*\"home\" + 0.066*\"friend\" + 0.058*\"call\" + 0.041*\"time\" + 0.040*\"good\" + 0.035*\"live\" + 0.032*\"send\" + 0.016*\"fall\" + 0.016*\"bomb\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"sit\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"sit\"][]{0,25}[lemma=\"truck\"])|([lemma=\"truck\"][]{0,25}[lemma=\"sit\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"truck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22put%22%5D+%5B%22us%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22truck%22%5D+%5B%5D+%5B%22If%22%5D+%5B%22you%22%5D+%5B%22sit%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22straight%22%5D+%5B%22up%22%5D+%5B%22your%22%5D+%5B%22feet%22%5D+%5B%22straight%22%5D+%5B%22and%22%5D+%5B%22on%22%5D+%5B%22your%22%5D+%5B%22feet%22%5D+%5B%22sit%22%5D+%5B%22another%22%5D+%5B%22person%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They put us on the truck . If you sit , you straight up your feet straight and on your feet sit another person . ', 'right': '', 'complete_match': 'They put us on the truck . If you sit , you straight up your feet straight and on your feet sit another person . ', 'testimony_id': 'irn509173', 'shelfmark': ['USHMM RG-50.233*0090'], 'token_start': 6456, 'token_end': 6481}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"They put us on the truck. If you sit, you straight up your feet straight and on your feet sit another person.\"\n",
    "fragment_1['label']=\"They put us on the truck. If you sit, you straight up your feet straight and on your feet sit another person.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22we%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22sit%22%5D+%5B%22still%22%5D+%5B%22there%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22in%22%5D+%5B%22these%22%5D+%5B%22trucks%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22no%22%5D+%5B%5D%7B0%2C3%7D+%5B%22no%22%5D+%5B%22breathing%22%5D+%5B%22or%22%5D+%5B%22anything%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And we had to sit still there , you know , in these trucks , you know , and no -- no breathing or anything . ', 'right': '', 'complete_match': 'And we had to sit still there , you know , in these trucks , you know , and no -- no breathing or anything . ', 'testimony_id': 'usc_shoah_5371', 'shelfmark': ['USC 5371'], 'token_start': 20908, 'token_end': 20934}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \" And we had to sit still there, you know, in these trucks, you know, and no-- no breathing or anything.\"\n",
    "fragment_2['label']=\" And we had to sit still there, you know, in these trucks, you know, and no-- no breathing or anything.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Some%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22sit%22%5D+%5B%22down%22%5D+%5B%5D+%5B%22others%22%5D+%5B%22could%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"Some could n't sit down , others could . \", 'right': '', 'complete_match': \"Some could n't sit down , others could . \", 'testimony_id': 'usc_shoah_4187', 'shelfmark': ['USC 4187'], 'token_start': 9494, 'token_end': 9503}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"Some couldn't sit down, others could.\"\n",
    "fragment_3['label']=\"There were, I would say, 70 to 80 people to-- to a-- a-- a cattle truck. Some couldn't sit down, others could.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Anyhow%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22following%22%5D+%5B%22day%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22load%22%5D+%5B%22us%22%5D+%5B%22up%22%5D+%5B%22on%22%5D+%5B%22trucks%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22going%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22do%22%5D+%5B%5D+%5B%22know%22%5D+%5B%22where%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"Anyhow , the following day , they load us up on trucks . And we were going , we do n't know where . \", 'right': '', 'complete_match': \"Anyhow , the following day , they load us up on trucks . And we were going , we do n't know where . \", 'testimony_id': 'usc_shoah_20084', 'shelfmark': ['USC 20084'], 'token_start': 8402, 'token_end': 8426}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"Anyhow, the following day, they load us up on trucks. And we were going, we don't know where. \"\n",
    "fragment_4['label']= \"Anyhow, the following day, they load us up on trucks. And we were going, we don't know where. \"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22know%22%5D+%5B%5D+%5B%22if%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22week%22%5D+%5B%22or%22%5D+%5B%22two%22%5D+%5B%22weeks%22%5D+%5B%5D+%5B%22to%22%5D+%5B%22sit%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22cattle%22%5D+%5B%22trucks%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You know , if it was a week or two weeks , to sit in the cattle trucks . ', 'right': '', 'complete_match': 'You know , if it was a week or two weeks , to sit in the cattle trucks . ', 'testimony_id': 'usc_shoah_13524', 'shelfmark': ['USC 13524'], 'token_start': 25195, 'token_end': 25214}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"You know, if it was a week or two weeks, to sit in the cattle trucks.\"\n",
    "fragment_5['label']= \"You know, if it was a week or two weeks, to sit in the cattle trucks.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"sit\",\"dead\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"sit\"][]{0,4}[lemma=\"dead\"])|([lemma=\"dead\"][]{0,4}[lemma=\"sit\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=4)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"on the dead\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22the%22%5D+%5B%22irony%22%5D+%5B%22of%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22when%22%5D+%5B%22one%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22like%22%5D+%5B%22a%22%5D+%5B%22lunch%22%5D+%5B%22time%22%5D+%5B%5D+%5B%22we%22%5D+%5B%22sit%22%5D+%5B%22on%22%5D+%5B%22a%22%5D+%5B%22dead%22%5D+%5B%22body%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And the irony of it was when one it was like a lunch time , we sit on a dead body . ', 'right': '', 'complete_match': 'And the irony of it was when one it was like a lunch time , we sit on a dead body . ', 'testimony_id': 'irn504542', 'shelfmark': ['USHMM RG-50.030*0040'], 'token_start': 10912, 'token_end': 10934}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And the irony of it was when one it was like a lunch time, we sit on a dead body.\"\n",
    "fragment_1['label']=\"And the irony of it was when one it was like a lunch time, we sit on a dead body.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Used%22%5D+%5B%22to%22%5D+%5B%22huddle%22%5D+%5B%22together%22%5D+%5B%22to%22%5D+%5B%22keep%22%5D+%5B%22warm%22%5D+%5B%5D+%5B%22or%22%5D+%5B%22we%22%5D+%5B%22sat%22%5D+%5B%22down%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22dead%22%5D+%5B%22people%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Used to huddle together to keep warm , or we sat down on the dead people . ', 'right': '', 'complete_match': 'Used to huddle together to keep warm , or we sat down on the dead people . ', 'testimony_id': 'irn510728', 'shelfmark': ['USHMM RG-50.154*0008'], 'token_start': 10540, 'token_end': 10557}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"Used to huddle together to keep warm, or we sat down on the dead people.\"\n",
    "fragment_2['label']=\"Used to huddle together to keep warm, or we sat down on the dead people.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22It%22%5D+%5B%22took%22%5D+%5B%22me%22%5D+%5B%22many%22%5D+%5B%22years%22%5D+%5B%22to%22%5D+%5B%22understand%22%5D+%5B%22that%22%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22sitting%22%5D+%5B%22surrounded%22%5D+%5B%22by%22%5D+%5B%22dead%22%5D+%5B%22bodies%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22was%22%5D+%5B%22sitting%22%5D+%5B%22on%22%5D+%5B%22dead%22%5D+%5B%22bodies%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'It took me many years to understand that I was sitting surrounded by dead bodies . I was sitting on dead bodies . ', 'right': '', 'complete_match': 'It took me many years to understand that I was sitting surrounded by dead bodies . I was sitting on dead bodies . ', 'testimony_id': 'usc_shoah_19518', 'shelfmark': ['USC 19518'], 'token_start': 19858, 'token_end': 19881}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"It took me many years to understand that I was sitting surrounded by dead bodies. I was sitting on dead bodies.\"\n",
    "fragment_3['label']=\"It took me many years to understand that I was sitting surrounded by dead bodies. I was sitting on dead bodies.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22In%22%5D+%5B%22these%22%5D+%5B%22train%22%5D+%5B%22rides%22%5D+%5B%5D+%5B%22I%22%5D+%5B%22%27d%22%5D+%5B%22be%22%5D+%5B%22sitting%22%5D+%5B%22on%22%5D+%5B%22top%22%5D+%5B%22of%22%5D+%5B%22dead%22%5D+%5B%22people%22%5D+%5B%22who%22%5D+%5B%22died%22%5D+%5B%22of%22%5D+%5B%22typhus%22%5D+%5B%5D+%5B%22tuberculosis%22%5D+%5B%5D+%5B%22or%22%5D+%5B%22other%22%5D+%5B%22serious%22%5D+%5B%22ailments%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"In these train rides , I 'd be sitting on top of dead people who died of typhus , tuberculosis , or other serious ailments \", 'right': '', 'complete_match': \"In these train rides , I 'd be sitting on top of dead people who died of typhus , tuberculosis , or other serious ailments \", 'testimony_id': 'usc_shoah_25639', 'shelfmark': ['USC 25639'], 'token_start': 30345, 'token_end': 30370}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"In these train rides, I'd be sitting on top of dead people who died of typhus, tuberculosis, or other serious ailments\"\n",
    "fragment_5['label']= \"In these train rides, I'd be sitting on top of dead people who died of typhus, tuberculosis, or other serious ailments\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"sit\",\"die\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"sit\"][]{0,3}[lemma=\"die\"])|([lemma=\"die\"][]{0,3}[lemma=\"sit\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=3)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"die\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22People%22%5D+%5B%22died%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22sat%22%5D+%5B%22down%22%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22could%22%5D+%5B%5D+%5B%22get%22%5D+%5B%22up%22%5D+%5B%22anymore%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'People died , they sat down and they could n’t get up anymore . ', 'right': '', 'complete_match': 'People died , they sat down and they could n’t get up anymore . ', 'testimony_id': 'irn508670', 'shelfmark': ['USHMM RG-50.462*0050'], 'token_start': 13479, 'token_end': 13493}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"People died, they sat down and they couldn’t get up anymore.\"\n",
    "fragment_1['label']=\"People died, they sat down and they couldn’t get up anymore.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22He%22%5D+%5B%22just%22%5D+%5B%22sat%22%5D+%5B%22down%22%5D+%5B%5D+%5B%22he%22%5D+%5B%22leaned%22%5D+%5B%22against%22%5D+%5B%22the%22%5D+%5B%22wall%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22he%22%5D+%5B%22died%22%5D+%5B%22of%22%5D+%5B%22malnutrition%22%5D+%5B%22and%22%5D+%5B%22also%22%5D+%5B%22dysentery%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'He just sat down , he leaned against the wall , and he died of malnutrition and also dysentery . ', 'right': '', 'complete_match': 'He just sat down , he leaned against the wall , and he died of malnutrition and also dysentery . ', 'testimony_id': 'usc_shoah_14463', 'shelfmark': ['USC 14463'], 'token_start': 34438, 'token_end': 34458}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"He just sat down, he leaned against the wall, and he died of malnutrition and also dysentery.\"\n",
    "fragment_2['label']=\"He just sat down, he leaned against the wall, and he died of malnutrition and also dysentery.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22the%22%5D+%5B%22man%22%5D+%5B%22that%22%5D+%5B%22was%22%5D+%5B%22sitting%22%5D+%5B%22under%22%5D+%5B%22the%22%5D+%5B%22tree%22%5D+%5B%5D+%5B%22he%22%5D+%5B%22looked%22%5D+%5B%22so%22%5D+%5B%22real%22%5D+%5B%22and%22%5D+%5B%22so%22%5D+%5B%22alive%22%5D+%5B%22and%22%5D+%5B%22he%22%5D+%5B%22was%22%5D+%5B%22dead%22%5D+%5B%5D+%5B%22Maybe%22%5D+%5B%5D+%5B%22he%22%5D+%5B%22just%22%5D+%5B%22sat%22%5D+%5B%22down%22%5D+%5B%22to%22%5D+%5B%22die%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'the man that was sitting under the tree , he looked so real and so alive and he was dead . Maybe , he just sat down to die . ', 'right': '', 'complete_match': 'the man that was sitting under the tree , he looked so real and so alive and he was dead . Maybe , he just sat down to die . ', 'testimony_id': 'irn508479', 'shelfmark': ['USHMM RG-50.030*0411'], 'token_start': 54805, 'token_end': 54835}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"the man that was sitting under the tree, he looked so real and so alive and he was dead. Maybe, he just sat down to die.\"\n",
    "fragment_4['label']= \"(..) the man that was sitting under the tree, he looked so real and so alive and he was dead. Maybe, he just sat down to die.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22could%22%5D+%5B%22just%22%5D+%5B%22sit%22%5D+%5B%22down%22%5D+%5B%22and%22%5D+%5B%22become%22%5D+%5B%22a%22%5D+%5B%22muselmann%22%5D+%5B%22and%22%5D+%5B%22you%22%5D+%5B%22just%22%5D+%5B%22die%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You could just sit down and become a muselmann and you just die . ', 'right': '', 'complete_match': 'You could just sit down and become a muselmann and you just die . ', 'testimony_id': 'usc_shoah_1581', 'shelfmark': ['USC 1581'], 'token_start': 18089, 'token_end': 18103}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"You could just sit down and become a muselmann and you just die.\"\n",
    "fragment_5['label']= \"You could just sit down and become a muselmann and you just die.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"sit\",\"shoot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"sit\"][]{0,50}[lemma=\"shoot\"])|([lemma=\"shoot\"][]{0,50}[lemma=\"sit\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=50)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"shoot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22you%22%5D+%5B%22sat%22%5D+%5B%22down%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22shot%22%5D+%5B%22you%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And you sat down , and they shot you ? ', 'right': '', 'complete_match': 'And you sat down , and they shot you ? ', 'testimony_id': 'usc_shoah_16', 'shelfmark': ['USC 16'], 'token_start': 8697, 'token_end': 8707}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And you sat down, and they shot you?\"\n",
    "fragment_1['label']=\"And you sat down, and they shot you?\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22whoever%22%5D+%5B%22sits%22%5D+%5B%22down%22%5D+%5B%22or%22%5D+%5B%22slows%22%5D+%5B%22down%22%5D+%5B%22will%22%5D+%5B%22shoot%22%5D+%5B%22and%22%5D+%5B%22all%22%5D+%5B%22these%22%5D+%5B%22things%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'whoever sits down or slows down will shoot and all these things . ', 'right': '', 'complete_match': 'whoever sits down or slows down will shoot and all these things . ', 'testimony_id': 'usc_shoah_10162', 'shelfmark': ['USC 10162'], 'token_start': 15525, 'token_end': 15538}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"whoever sits down or slows down will shoot and all these things.\"\n",
    "fragment_2['label']=\"(..) whoever sits down or slows down will shoot and all these things.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22everybody%22%5D+%5B%22who%22%5D+%5B%22sit%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22road%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22get%22%5D+%5B%22shot%22%5D+%5B%5D+%5B%22So%22%5D+%5B%22you%22%5D+%5B%22were%22%5D+%5B%22practically%22%5D+%5B%22walking%22%5D+%5B%22between%22%5D+%5B%22dead%22%5D+%5B%22people%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And everybody who sit on the road , they get shot . So you were practically walking between dead people . ', 'right': '', 'complete_match': 'And everybody who sit on the road , they get shot . So you were practically walking between dead people . ', 'testimony_id': 'usc_shoah_543', 'shelfmark': ['USC 543'], 'token_start': 17966, 'token_end': 17987}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And everybody who sit on the road, they get shot. So you were practically walking between dead people.\"\n",
    "fragment_3['label']=\"And everybody who sit on the road, they get shot. So you were practically walking between dead people.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22People%22%5D+%5B%22who%22%5D+%5B%22were%22%5D+%5B%22sitting%22%5D+%5B%5D+%5B%22who%22%5D+%5B%22were%22%5D+%5B%22too%22%5D+%5B%22weak%22%5D+%5B%22to%22%5D+%5B%22get%22%5D+%5B%22up%22%5D+%5B%22were%22%5D+%5B%22shot%22%5D+%5B%22immediately%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'People who were sitting , who were too weak to get up were shot immediately . ', 'right': '', 'complete_match': 'People who were sitting , who were too weak to get up were shot immediately . ', 'testimony_id': 'irn516732', 'shelfmark': ['USHMM RG-50.030*0493'], 'token_start': 35179, 'token_end': 35195}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"People who were sitting, who were too weak to get up were shot immediately.\"\n",
    "fragment_4['label']= \"People who were sitting, who were too weak to get up were shot immediately.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22If%22%5D+%5B%22you%22%5D+%5B%22sat%22%5D+%5B%22down%22%5D+%5B%5D+%5B%22they%22%5D+%5B%22shot%22%5D+%5B%22you%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22spot%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'If you sat down , they shot you on the spot . ', 'right': '', 'complete_match': 'If you sat down , they shot you on the spot . ', 'testimony_id': 'usc_shoah_27', 'shelfmark': ['USC 27'], 'token_start': 11696, 'token_end': 11708}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"If you sat down, they shot you on the spot.\"\n",
    "fragment_5['label']= \"If you sat down, they shot you on the spot.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
