{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining testimonial fragments of the Holocaust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experience domain:** stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_topic_model_concordance as topic_concordancer\n",
    "from utils import blacklab, db, text\n",
    "mongo = db.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_query(lemmas,context_length=50):\n",
    "    permutations = itertools.permutations(lemmas,len(lemmas))\n",
    "    final_result = []\n",
    "    for element in list(permutations):\n",
    "        temp_result = []\n",
    "        for el in element:\n",
    "            temp_result.append('[lemma=\"'+el+'\"]')\n",
    "        temp_result = '('+('[]{0,'+str(context_length)+'}').join(temp_result)+')'\n",
    "        final_result.append(temp_result)\n",
    "    final_result = '|'.join(final_result)\n",
    "    return final_result\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import blacklab, db, text\n",
    "import requests\n",
    "import json\n",
    "def find_sentence_id(label):\n",
    "    props = {'annotators': 'tokenize'}\n",
    "\n",
    "    # set the encoding of the annotator\n",
    "    requests.encoding = 'utf-8'\n",
    "    # make a request\n",
    "    r = requests.post('http://localhost:9000/', params={'properties':\n",
    "                      json.dumps(props)},\n",
    "                      data=label.encode('utf-8'))\n",
    "    result = json.loads(r.text, encoding='utf-8')\n",
    "    query = []\n",
    "    for i, token in enumerate(result['tokens']):\n",
    "\n",
    "        if ('...'in token['word'] and ((i == 0) or\n",
    "           i == len(result['tokens']) - 1)):\n",
    "            continue\n",
    "        elif ('...'in token['word']):\n",
    "            query.append('[]{0,50}')\n",
    "        elif ('-'in token['word']):\n",
    "            query.append('[]{0,3}')\n",
    "        elif (\"n't\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'re\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"?\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\".\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\"'s\"in token['word']):\n",
    "            query.append('[]')\n",
    "        elif (\",\"in token['word']):\n",
    "            query.append('[]')\n",
    "        else:\n",
    "            query.append('[\"' + token['word'] + '\"]')\n",
    "\n",
    "    query = ' '.join(query)\n",
    "    try:\n",
    "        sentence = blacklab.search_blacklab(query, window=0,\n",
    "                                            lemma=False,\n",
    "                                            include_match=True)\n",
    "        token_end = sentence[0]['token_end']\n",
    "        token_start = sentence[0]['token_start']\n",
    "        print (sentence[0])\n",
    "        mongo = db.get_db()\n",
    "        results = mongo.tokens.find({'testimony_id':\n",
    "                                    sentence[0]['testimony_id']},\n",
    "                                    {'_id': 0})\n",
    "        tokens = list(results)[0]['tokens']\n",
    "        sentenceStart = tokens[token_start]['sentence_index']\n",
    "        sentenceEnd = tokens[token_end]['sentence_index']\n",
    "        originalsentence = sentence[0]['complete_match']\n",
    "        return (sentenceStart,sentenceEnd,sentence[0]['testimony_id'])\n",
    "    except:\n",
    "        print(\"The following query returned a null result\")\n",
    "        print(query)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_node(label):\n",
    "    \"\"\"Generate a root node for a tree structure.\"\"\"\n",
    "    testimony_id = random.randint(1, 20)\n",
    "    node = {}\n",
    "    node['label'] = label\n",
    "    fragment = {'label': label,\n",
    "                'essay_id': random.randint(1, 20),\n",
    "                'tree': get_node(testimony_id, node, is_parent=True)}\n",
    "    fragment['tree']['label'] = label\n",
    "\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(testimony_id, node, is_parent=False):\n",
    "    \"\"\"Generate a parent or leaf node for a tree structure.\"\"\"\n",
    "    if is_parent:\n",
    "        return {\n",
    "            'label': node['label'],\n",
    "            'testimony_id': random.randint(1, 20),\n",
    "            'media_index': random.randint(1, 20),\n",
    "            'media_offset': random.randint(1, 20),\n",
    "            'start_sentence_index': random.randint(1, 20),\n",
    "            'end_sentence_index': random.randint(1, 20),\n",
    "            'children': [], }\n",
    "    else:\n",
    "        return {'label': node['label'],\n",
    "                'testimony_id': node['testimony_id'],\n",
    "                'media_index': float(node['media_index']),\n",
    "                'media_offset': float(node['media_offset']),\n",
    "                'start_sentence_index': float(node['start_sentence_index']),\n",
    "                'end_sentence_index': float(node['end_sentence_index']),\n",
    "                'children': [], }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_main_node_exist(node):\n",
    "    results = mongo.fragments.find({'label':node},{'_id': 0})\n",
    "    if len(results[0])==0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_main_node(label):\n",
    "    mongo.fragments.insert(create_parent_node(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_main_node(label):\n",
    "    mongo.fragments.delete_one({'label':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_testimonial_fragments(fragments):\n",
    "    if check_if_main_node_exist(fragments['main_node']):\n",
    "        results = mongo.fragments.find({'label':fragments['main_node']},{'_id':0})[0]\n",
    "        mid_nodes = [element['label'] for element in results['tree']['children']]\n",
    "        if fragments['mid_node'] in mid_nodes:\n",
    "            print (\"mid node exists cannot be added\")\n",
    "        else:\n",
    "            \n",
    "            mid_node = get_node('r',{'label':fragments['mid_node']},is_parent=True)\n",
    "            for fragment in fragments['fragments']:\n",
    "                leaf = get_node(fragment['testimony_id'],fragment)\n",
    "                mid_node['children'].append(leaf)\n",
    "            results['tree']['children'].append(mid_node)\n",
    "            mongo.fragments.replace_one({'label':fragments['main_node']},results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the main node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "main_node = \"stand\"\n",
    "#delete_main_node(\"numbness\")\n",
    "add_main_node(main_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '[lemma=\"stand\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = topic_concordancer.main(query,window=25,topicn=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the key topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i,element in enumerate(result['topic_documents']):\n",
    "    print (i)\n",
    "    topic_words =  element['topic_words'][1]\n",
    "    print (topic_words)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=5\n",
    "\n",
    "for text in result['topic_documents'][i]['texts'][0:25]:\n",
    "    print (text['matched_text_words'])\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testimonial fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  For hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '[lemma=\"stand\"] []{0,15} [\"hours\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"for hours\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22can%22%5D+%5B%22stand%22%5D+%5B%22one%22%5D+%5B%22hour%22%5D+%5B%5D+%5B%22two%22%5D+%5B%22hours%22%5D+%5B%5D+%5B%22three%22%5D+%5B%22hours%22%5D+%5B%5D+%5B%22four%22%5D+%5B%22hours%22%5D+%5B%5D+%5B%22five%22%5D+%5B%22hours%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You can stand one hour , two hours , three hours , four hours , five hours . ', 'right': '', 'complete_match': 'You can stand one hour , two hours , three hours , four hours , five hours . ', 'testimony_id': 'HVT-149', 'shelfmark': ['Fortunoff HVT-149'], 'token_start': 12994, 'token_end': 13012}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"You can stand one hour, two hours, three hours, four hours, five hours.\"\n",
    "fragment_1['label']=\"You can stand one hour, two hours, three hours, four hours, five hours.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22you%22%5D+%5B%22stood%22%5D+%5B%22for%22%5D+%5B%22six%22%5D+%5B%22hours%22%5D+%5B%5D+%5B%22eight%22%5D+%5B%22hours%22%5D+%5B%5D+%5B%2210%22%5D+%5B%22hours%22%5D+%5B%22a%22%5D+%5B%22day%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'you stood for six hours , eight hours , 10 hours a day ', 'right': '', 'complete_match': 'you stood for six hours , eight hours , 10 hours a day ', 'testimony_id': 'irn35788', 'shelfmark': ['USHMM RG-50.030*0523'], 'token_start': 4622, 'token_end': 4635}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"you stood for six hours, eight hours, 10 hours a day\"\n",
    "fragment_2['label']=\"(..)you stood for six hours, eight hours, 10 hours a day (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22just%22%5D+%5B%22standing%22%5D+%5B%22there%22%5D+%5B%22for%22%5D+%5B%22hours%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And we were just standing there for hours . ', 'right': '', 'complete_match': 'And we were just standing there for hours . ', 'testimony_id': 'HVT-125', 'shelfmark': ['Fortunoff HVT-125'], 'token_start': 10986, 'token_end': 10995}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And we were just standing there for hours.\"\n",
    "fragment_3['label']=\"And we were just standing there for hours.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22routine%22%5D+%5B%22began%22%5D+%5B%22of%22%5D+%5B%22being%22%5D+%5B%22awakened%22%5D+%5B%22at%22%5D+%5B%225%3A00%22%5D+%5B%22AM%22%5D+%5B%22and%22%5D+%5B%22pushed%22%5D+%5B%22out%22%5D+%5B%22into%22%5D+%5B%22the%22%5D+%5B%22cold%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22standing%22%5D+%5B%22there%22%5D+%5B%22for%22%5D+%5B%22hours%22%5D+%5B%22until%22%5D+%5B%22they%22%5D+%5B%22counted%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'routine began of being awakened at 5:00 AM and pushed out into the cold , and standing there for hours until they counted . ', 'right': '', 'complete_match': 'routine began of being awakened at 5:00 AM and pushed out into the cold , and standing there for hours until they counted . ', 'testimony_id': 'HVT-65', 'shelfmark': ['Fortunoff HVT-65'], 'token_start': 15464, 'token_end': 15488}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"routine began of being awakened at 5:00 AM and pushed out into the cold, and standing there for hours until they counted.\"\n",
    "fragment_4['label']= \"(..)routine began of being awakened at 5:00 AM and pushed out into the cold, and standing there for hours until they counted.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22You%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22stand%22%5D+%5B%22in%22%5D+%5B%22a%22%5D+%5B%22appell%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22morning%22%5D+%5B%22for%22%5D+%5B%222%22%5D+%5B%22hours%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'You had to stand in a appell in the morning for 2 hours . ', 'right': '', 'complete_match': 'You had to stand in a appell in the morning for 2 hours . ', 'testimony_id': 'irn504639', 'shelfmark': ['USHMM RG-50.030*0145'], 'token_start': 11441, 'token_end': 11455}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"You had to stand in a appell in the morning for 2 hours.\"\n",
    "fragment_5['label']= \"You had to stand in a appell in the morning for 2 hours.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Cold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"stand\",\"cold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"stand\"][]{0,25}[lemma=\"cold\"])|([lemma=\"cold\"][]{0,25}[lemma=\"stand\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"in cold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22he%22%5D+%5B%22asked%22%5D+%5B%22she%22%5D+%5B%22should%22%5D+%5B%22sing%22%5D+%5B%22again%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22the%22%5D+%5B%22whole%22%5D+%5B%22block%22%5D+%5B%5D+%5B%22the%22%5D+%5B%22whole%22%5D+%5B%22group%22%5D+%5B%22was%22%5D+%5B%22standing%22%5D+%5B%22on%22%5D+%5B%22the%22%5D+%5B%22floor%22%5D+%5B%5D+%5B%22It%22%5D+%5B%22was%22%5D+%5B%22cold%22%5D+%5B%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22already%22%5D+%5B%22October%22%5D+%5B%5D+%5B%22November%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And he asked she should sing again , and the whole block , the whole group was standing on the floor . It was cold , it was already October , November . ', 'right': '', 'complete_match': 'And he asked she should sing again , and the whole block , the whole group was standing on the floor . It was cold , it was already October , November . ', 'testimony_id': 'irn504759', 'shelfmark': ['USHMM RG-50.030*0275'], 'token_start': 4910, 'token_end': 4943}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And he asked she should sing again, and the whole block, the whole group was standing on the floor. It was cold, it was already October, November.\"\n",
    "fragment_1['label']=\"(..) the whole block, the whole group was standing on the floor. It was cold, it was already October, November.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22It%22%5D+%5B%22was%22%5D+%5B%22awfully%22%5D+%5B%22cold%22%5D+%5B%5D+%5B%22very%22%5D+%5B%22cold%22%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22stood%22%5D+%5B%22probably%22%5D+%5B%22until%22%5D+%5B%22two%22%5D+%5B%22or%22%5D+%5B%22three%22%5D+%5B%22o%27clock%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22morning%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"It was awfully cold , very cold and we stood probably until two or three o'clock in the morning \", 'right': '', 'complete_match': \"It was awfully cold , very cold and we stood probably until two or three o'clock in the morning \", 'testimony_id': 'irn504802', 'shelfmark': ['USHMM RG-50.030*0307'], 'token_start': 18631, 'token_end': 18650}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"It was awfully cold, very cold and we stood probably until two or three o'clock in the morning\"\n",
    "fragment_2['label']=\"It was awfully cold, very cold and we stood probably until two or three o'clock in the morning (..)\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22stand%22%5D+%5B%22on%22%5D+%5B%22that%22%5D+%5B%22same%22%5D+%5B%22spot%22%5D+%5B%22the%22%5D+%5B%22entire%22%5D+%5B%22day%22%5D+%5B%5D+%5B%22uh%22%5D+%5B%5D+%5B%22when%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22really%22%5D+%5B%22cold%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'stand on that same spot the entire day , uh , when it was really cold . ', 'right': '', 'complete_match': 'stand on that same spot the entire day , uh , when it was really cold . ', 'testimony_id': 'HVT-137', 'shelfmark': ['Fortunoff HVT-137'], 'token_start': 11321, 'token_end': 11338}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"stand on that same spot the entire day, uh, when it was really cold.\"\n",
    "fragment_3['label']=\"(..) stand on that same spot the entire day, uh, when it was really cold.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Then%22%5D+%5B%22I%22%5D+%5B%22started%22%5D+%5B%22to%22%5D+%5B%22cough%22%5D+%5B%22because%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22very%22%5D+%5B%22cold%22%5D+%5B%22and%22%5D+%5B%22humid%22%5D+%5B%22in%22%5D+%5B%22Auschwitz%22%5D+%5B%222%3A00%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22morning%22%5D+%5B%22when%22%5D+%5B%22you%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22go%22%5D+%5B%22out%22%5D+%5B%22and%22%5D+%5B%22stand%22%5D+%5B%22the%22%5D+%5B%22roll%22%5D+%5B%22calls%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'Then I started to cough because it was very cold and humid in Auschwitz 2:00 in the morning when you had to go out and stand the roll calls . ', 'right': '', 'complete_match': 'Then I started to cough because it was very cold and humid in Auschwitz 2:00 in the morning when you had to go out and stand the roll calls . ', 'testimony_id': 'HVT-43', 'shelfmark': ['Fortunoff HVT-43'], 'token_start': 17090, 'token_end': 17120}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"Then I started to cough because it was very cold and humid in Auschwitz 2:00 in the morning when you had to go out and stand the roll calls.\"\n",
    "fragment_4['label']= \"(..)I started to cough because it was very cold and humid (..) in the morning when you had to go out and stand the roll calls.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22We%22%5D+%5B%22stood%22%5D+%5B%22in%22%5D+%5B%22line%22%5D+%5B%22half%22%5D+%5B%22naked%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22cold%22%5D+%5B%22and%22%5D+%5B%22splashed%22%5D+%5B%22our%22%5D+%5B%22faces%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'We stood in line half naked in the cold and splashed our faces . ', 'right': '', 'complete_match': 'We stood in line half naked in the cold and splashed our faces . ', 'testimony_id': 'irn504816', 'shelfmark': ['USHMM RG-50.030*0322'], 'token_start': 19924, 'token_end': 19938}\n"
     ]
    }
   ],
   "source": [
    "fragment_5 = {}\n",
    "fragment_5['original_sentence'] = \"We stood in line half naked in the cold and splashed our faces.\"\n",
    "fragment_5['label']= \"We stood in line half naked in the cold and splashed our faces.\"\n",
    "indices = find_sentence_id(fragment_5['original_sentence'])\n",
    "fragment_5['start_sentence_index']=indices[0]\n",
    "fragment_5['end_sentence_index']=indices[1]\n",
    "fragment_5['media_offset'] = 0\n",
    "fragment_5['media_index'] = 0\n",
    "fragment_5['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"stand\",\"hot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"stand\"][]{0,25}[lemma=\"hot\"])|([lemma=\"hot\"][]{0,25}[lemma=\"stand\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"in the heat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22at%22%5D+%5B%22least%22%5D+%5B%5D+%5B%22girls%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22stand%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22heat%22%5D+%5B%5D+%5B%22five%22%5D+%5B%22deep%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22stand%22%5D+%5B%22for%22%5D+%5B%22hours%22%5D+%5B%22just%22%5D+%5B%22to%22%5D+%5B%22count%22%5D+%5B%22us%22%5D+%5B%22twice%22%5D+%5B%22a%22%5D+%5B%22day%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'at least 15,000 girls had to stand in the heat , five deep , and stand for hours just to count us twice a day . ', 'right': '', 'complete_match': 'at least 15,000 girls had to stand in the heat , five deep , and stand for hours just to count us twice a day . ', 'testimony_id': 'HVT-102', 'shelfmark': ['Fortunoff HVT-102'], 'token_start': 6533, 'token_end': 6559}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"at least 15,000 girls had to stand in the heat, five deep, and stand for hours just to count us twice a day.\"\n",
    "fragment_1['label']=\"(..)at least 15,000 girls had to stand in the heat,(..) stand for hours just to count us twice a day. \"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22The%22%5D+%5B%22whole%22%5D+%5B%22day%22%5D+%5B%22we%22%5D+%5B%22stood%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22hot%22%5D+%5B%22sun%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'The whole day we stood in the hot sun ', 'right': '', 'complete_match': 'The whole day we stood in the hot sun ', 'testimony_id': 'irn508630', 'shelfmark': ['USHMM RG-50.462*0009'], 'token_start': 4561, 'token_end': 4570}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"The whole day we stood in the hot sun\"\n",
    "fragment_2['label']=\"The whole day we stood in the hot sun (..).\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22then%22%5D+%5B%22they%22%5D+%5B%22let%22%5D+%5B%22us%22%5D+%5B%22stand%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22hot%22%5D+%5B%5D+%5B%22boiling%22%5D+%5B%22sun%22%5D+%5B%22for%22%5D+%5B%22hours%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And then they let us stand in the hot , boiling sun for hours ', 'right': '', 'complete_match': 'And then they let us stand in the hot , boiling sun for hours ', 'testimony_id': 'usc_shoah_935', 'shelfmark': ['USC 935'], 'token_start': 33172, 'token_end': 33186}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"And then they let us stand in the hot, boiling sun for hours\"\n",
    "fragment_3['label']=\"And then they let us stand in the hot, boiling sun for hours (..).\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22it%22%5D+%5B%22was%22%5D+%5B%22one%22%5D+%5B%22of%22%5D+%5B%22those%22%5D+%5B%22real%22%5D+%5B%22hot%22%5D+%5B%22days%22%5D+%5B%22%3B%22%5D+%5B%22and%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%22for%22%5D+%5B%22hours%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'it was one of those real hot days ; and we were standing for hours . ', 'right': '', 'complete_match': 'it was one of those real hot days ; and we were standing for hours . ', 'testimony_id': 'irn504725', 'shelfmark': ['USHMM RG-50.030*0236'], 'token_start': 7309, 'token_end': 7325}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \" it was one of those real hot days; and we were standing for hours.\"\n",
    "fragment_4['label']= \"(..)it was one of those real hot days; and we were standing for hours.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"stand\",\"rain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"stand\"][]{0,25}[lemma=\"rain\"])|([lemma=\"rain\"][]{0,25}[lemma=\"stand\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"in the rain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22you%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%22there%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22rain%22%5D+%5B%22for%22%5D+%5B%22about%22%5D+%5B%22a%22%5D+%5B%22day%22%5D+%5B%22and%22%5D+%5B%22a%22%5D+%5B%22night%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And you were standing there in the rain for about a day and a night ', 'right': '', 'complete_match': 'And you were standing there in the rain for about a day and a night ', 'testimony_id': 'irn504761', 'shelfmark': ['USHMM RG-50.030*0277'], 'token_start': 923, 'token_end': 938}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"And you were standing there in the rain for about a day and a night \"\n",
    "fragment_1['label']=\"And you were standing there in the rain for about a day and a night (..)\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%22all%22%5D+%5B%22day%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22rain%22%5D+%5B%22and%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22evening%22%5D+%5B%22they%22%5D+%5B%22took%22%5D+%5B%22them%22%5D+%5B%22away%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They were standing all day in the rain and in the evening they took them away . ', 'right': '', 'complete_match': 'They were standing all day in the rain and in the evening they took them away . ', 'testimony_id': 'irn515645', 'shelfmark': ['USHMM RG-50.462*0120'], 'token_start': 10155, 'token_end': 10172}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"They were standing all day in the rain and in the evening they took them away.\"\n",
    "fragment_2['label']=\"They were standing all day in the rain and in the evening they took them away.\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22It%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22day%22%5D+%5B%22like%22%5D+%5B%22raining%22%5D+%5B%5D+%5B%22drizzling%22%5D+%5B%5D+%5B%22a%22%5D+%5B%22Thursday%22%5D+%5B%22afternoon%22%5D+%5B%22from%22%5D+%5B%221%3A00%22%5D+%5B%22on%22%5D+%5B%5D+%5B%22There%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%22out%22%5D+%5B%22in%22%5D+%5B%22the%22%5D+%5B%22open%22%5D+%5B%22with%22%5D+%5B%22the%22%5D+%5B%22children%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'It was a day like raining , drizzling , a Thursday afternoon from 1:00 on . There we were standing out in the open with the children . ', 'right': '', 'complete_match': 'It was a day like raining , drizzling , a Thursday afternoon from 1:00 on . There we were standing out in the open with the children . ', 'testimony_id': 'irn515645', 'shelfmark': ['USHMM RG-50.462*0120'], 'token_start': 12168, 'token_end': 12196}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"It was a day like raining, drizzling, a Thursday afternoon from 1:00 on. There we were standing out in the open with the children.\"\n",
    "fragment_3['label']=\"It was a day like raining, drizzling (..). There we were standing out in the open with the children.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22And%22%5D+%5B%22it%22%5D+%5B%22was%22%5D+%5B%22a%22%5D+%5B%22terrible%22%5D+%5B%22rain%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22with%22%5D+%5B%22snow%22%5D+%5B%22mixed%22%5D+%5B%5D+%5B%22And%22%5D+%5B%22there%22%5D+%5B%22we%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%5D+%5B%22five%22%5D+%5B%22of%22%5D+%5B%22us%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'And it was a terrible rain , and with snow mixed . And there we were standing , five of us ', 'right': '', 'complete_match': 'And it was a terrible rain , and with snow mixed . And there we were standing , five of us ', 'testimony_id': 'usc_shoah_27687', 'shelfmark': ['USC 27687'], 'token_start': 14827, 'token_end': 14848}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"And it was a terrible rain, and with snow mixed. And there we were standing, five of us\"\n",
    "fragment_4['label']= \"And it was a terrible rain, and with snow mixed. And there we were standing, five of us (..)\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sick  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [\"sick\",\"stand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([lemma=\"sick\"][]{0,25}[lemma=\"stand\"])|([lemma=\"stand\"][]{0,25}[lemma=\"sick\"])\n"
     ]
    }
   ],
   "source": [
    "query = create_contextual_query(lemmas,context_length=25)\n",
    "print (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_term = \"the sick\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = {}\n",
    "fragments['main_node'] = main_node\n",
    "fragments['mid_node'] = domain_term\n",
    "fragments['fragments'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22They%22%5D+%5B%22shot%22%5D+%5B%22all%22%5D+%5B%22the%22%5D+%5B%22sick%22%5D+%5B%22girls%22%5D+%5B%5D+%5B%22those%22%5D+%5B%22who%22%5D+%5B%22could%22%5D+%5B%22really%22%5D+%5B%22not%22%5D+%5B%22stand%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'They shot all the sick girls , those who could really not stand . ', 'right': '', 'complete_match': 'They shot all the sick girls , those who could really not stand . ', 'testimony_id': 'HVT-99', 'shelfmark': ['Fortunoff HVT-99'], 'token_start': 7807, 'token_end': 7821}\n"
     ]
    }
   ],
   "source": [
    "fragment_1 = {}\n",
    "fragment_1['original_sentence'] = \"They shot all the sick girls, those who could really not stand.\"\n",
    "fragment_1['label']=\"They shot all the sick girls, those who could really not stand.\"\n",
    "indices = find_sentence_id(fragment_1['original_sentence'])\n",
    "fragment_1['start_sentence_index']=indices[0]\n",
    "fragment_1['end_sentence_index']=indices[1]\n",
    "fragment_1['media_offset'] = 0\n",
    "fragment_1['media_index'] = 0\n",
    "fragment_1['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22all%22%5D+%5B%22those%22%5D+%5B%22sick%22%5D+%5B%22people%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%22outside%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22go%22%5D+%5B%22out%22%5D+%5B%5D+%5B%22and%22%5D+%5B%22they%22%5D+%5B%22were%22%5D+%5B%22standing%22%5D+%5B%22outside%22%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'all those sick people they were standing outside , and had to go out , and they were standing outside ', 'right': '', 'complete_match': 'all those sick people they were standing outside , and had to go out , and they were standing outside ', 'testimony_id': 'irn505564', 'shelfmark': ['USHMM RG-50.042*0010'], 'token_start': 4210, 'token_end': 4230}\n"
     ]
    }
   ],
   "source": [
    "fragment_2 = {}\n",
    "fragment_2['original_sentence'] = \"all those sick people they were standing outside, and had to go out, and they were standing outside\"\n",
    "fragment_2['label']=\"all those sick people they were standing outside, and had to go out, and they were standing outside\"\n",
    "indices = find_sentence_id(fragment_2['original_sentence'])\n",
    "fragment_2['start_sentence_index']=indices[0]\n",
    "fragment_2['end_sentence_index']=indices[1]\n",
    "fragment_2['media_offset'] = 0\n",
    "fragment_2['media_index'] = 0\n",
    "fragment_2['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22No%22%5D+%5B%22matter%22%5D+%5B%22how%22%5D+%5B%22sick%22%5D+%5B%22you%22%5D+%5B%22were%22%5D+%5B%5D+%5B%22you%22%5D+%5B%22had%22%5D+%5B%22to%22%5D+%5B%22go%22%5D+%5B%22and%22%5D+%5B%22stand%22%5D+%5B%22out%22%5D+%5B%22on%22%5D+%5B%22appell%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': 'No matter how sick you were , you had to go and stand out on appell . ', 'right': '', 'complete_match': 'No matter how sick you were , you had to go and stand out on appell . ', 'testimony_id': 'usc_shoah_13623', 'shelfmark': ['USC 13623'], 'token_start': 19286, 'token_end': 19303}\n"
     ]
    }
   ],
   "source": [
    "fragment_3 = {}\n",
    "fragment_3['original_sentence'] = \"No matter how sick you were, you had to go and stand out on appell.\"\n",
    "fragment_3['label']=\"No matter how sick you were, you had to go and stand out on appell.\"\n",
    "indices = find_sentence_id(fragment_3['original_sentence'])\n",
    "fragment_3['start_sentence_index']=indices[0]\n",
    "fragment_3['end_sentence_index']=indices[1]\n",
    "fragment_3['media_offset'] = 0\n",
    "fragment_3['media_index'] = 0\n",
    "fragment_3['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:8080/blacklab-server-2.1.0/lts/hits?patt=%5B%22Some%22%5D+%5B%22people%22%5D+%5B%22got%22%5D+%5B%22sick%22%5D+%5B%22just%22%5D+%5B%22standing%22%5D+%5B%22there%22%5D+%5B%22because%22%5D+%5B%22their%22%5D+%5B%22clothing%22%5D+%5B%22was%22%5D+%5B%5D+%5B%22enough%22%5D+%5B%5D&waitfortotal=true&outputformat=json&prettyprint=no&wordsaroundhit=0\n",
      "{'left': '', 'match_word': \"Some people got sick just standing there because their clothing was n't enough . \", 'right': '', 'complete_match': \"Some people got sick just standing there because their clothing was n't enough . \", 'testimony_id': 'usc_shoah_12150', 'shelfmark': ['USC 12150'], 'token_start': 13470, 'token_end': 13484}\n"
     ]
    }
   ],
   "source": [
    "fragment_4 = {}\n",
    "fragment_4['original_sentence'] = \"Some people got sick just standing there because their clothing wasn't enough.\"\n",
    "fragment_4['label']= \"Some people got sick just standing there because their clothing wasn't enough.\"\n",
    "indices = find_sentence_id(fragment_4['original_sentence'])\n",
    "fragment_4['start_sentence_index']=indices[0]\n",
    "fragment_4['end_sentence_index']=indices[1]\n",
    "fragment_4['media_offset'] = 0\n",
    "fragment_4['media_index'] = 0\n",
    "fragment_4['testimony_id'] = indices[2]\n",
    "fragments['fragments'].append(fragment_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_testimonial_fragments(fragments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
